%****************************************************************************
%*********************    SAGA User Manual 5.1   ****************************
%********************* Last update:  October  2004 *************************
%****************************************************************************

\documentclass{saclantc}
%%%%%XS\documentclass{article}
%\documentstyle[saclantc, epsfig]{article}

% from Nelson Martin
     \RequirePackage{hyperref}

   \hypersetup{
     pdfpagemode=UseThumbs,
     colorlinks=true,pdfhighlight=/P,linkbordercolor=1 1 1,
     linkcolor=blue,citecolor=green
   }
%end Nelson Martin
\newcommand{\modespace}[1]{\breve{{#1}}}
\newcommand{\MAP}[1]{\hat{#1}^{\mbox{\tiny\rm MAP}}}
\newcommand{\ML}[1]{\hat{#1}^{\mbox{\tiny\rm ML}}}
\newcommand{\E}{{\sf E}}
\newcommand{\Nobs}{N_{\rm obs}}
\hyphenation{wave-guide wave-guides}

\topmargin  =30 mm % was from SACLANTCEN 12 mm  
\newcommand{\figcap}[2]{   \begin{figure}
      \epsfxsize=14cm \centerline{\epsfbox{figures/#1.eps}}
      \caption{#2 [{\bf #1}]}  \label{#1}  %[{\bf #1}]
\end{figure}}

\title{SAGA User Manual 5.3:\\
An inversion software package\\ 
{\large \today}}
%\large{ Seismo-Acoustic inversion using Genetic Algorithms}}


% SACLANT Undersea Research Centre\\ 19138 La Spezia, Italy\\
% and\\
\author{\center Peter Gerstoft\\
           Marine Physical Laboratory \\
Scripps Institution of Oceanography\\
           University of California at San Diego\\
Email: gerstoft@ucsd.edu}

\date{\today}
%\date{September 20, 1996}
\project{042-4}
\serialno{ and MARINE PHYSICAL LABORATORY} %{SM-333}
\usepackage{epsfig}
\setlength{\unitlength}{1mm}
\tolerance=100000
\director{  J.L.\ Spoelstra}
%\setlength{\parskip}{0.3cm}

%\date{\today}
\begin{document}
\begin{prelims}
~~
\newpage
%%%%%\begin{executive}
{\bf Executive summary:}
The use of full field inversion methods or matched field processing
for target localization has been shown to be effective for
determination of target bearing, range, and depth in deep and shallow water. The performance of
these methods is strongly dependent on accurate information
about the environmental parameters. Previously, the lack of this
knowledge  inhibited the application of these methods in shallow water. 

The objective of this
report is to document a general software package {\sf SAGA} ({\sf S}eismo
{\sf A}coustic inversion using {\sf G}enetic {\sf A}lgorithms) which
has been developed
for assisting in estimating environmental parameters.
The approach taken here is data-independent and therefore the {\sf
SAGA} inversion code has
been applied to many types of data: single and multi
frequency data on a vertical array, coherent and incoherent
transmission loss, reverberation data, reflection coefficients from the
sea bottom, and tropospheric electromagnetic data.


Global
optimization using a directed Monte Carlo (random) search based on genetic
algorithms is used to identify representative set of parameters. 
Genetic algorithms are based on an analogy with
biological evolution, one of the most efficient optimization systems. 
Both the maximum likelihood estimate as well as uncertainty
estimates are provided. The results are presented using a Bayesian
framework. This approach is also applicable to data 
fusion, i.e.\ when combining information from several sensors.

 
%%%%%\begin{abstract}
\newpage

{\bf Abstract:}
The purpose of many experiments is to identify environmental 
parameters which, when
used as input to a forward model, accurately model the observed data.
It is also useful to have some indication of the
uncertainty of the estimated parameters.
{\sf SAGA } is a software package that helps the user
determine the best set of parameters to match a given data set.
At present, the package consist  of nine modules, one for each forward
model.  The forward codes used are: \\
{\sf OAST} (wavenumber integration transmission loss model),\\ 
{\sf OASR} (wavenumber integration reflection coefficients model), \\ 
{\sf SNAP} (normal modes), \\
{\sf SNAPRD} (adiabatic normal modes), \\
{\sf POPP} (normal mode reverberation model), \\
{\sf PROSIM} (broadband adiabatic normal modes),\\
{\sf CPROSIM} (broadband adiabatic normal modes),\\
{\sf ORCA} (broadband adiabatic normal modes),\\
{\sf GAMARAY} (broadband ray theory),\\
{\sf RAMGEO} (Range dependent Parabolic Equation),\\
 and  {\sf TPEM} (tropospheric parabolic equation).\\
Several types of observed data can be used in these inversions:
single or multi-frequency pressure on a vertical array, coherent or incoherent
transmission loss, reflection coefficients, reverberation data, or
tropospheric electromagnetic data.
For any parameter estimation problem the issue of error assessment must
be addressed. In {\sf SAGA} it is addressed by estimating {\it a
posteriori} distributions.

It appears that there has been a natural evolution in search
methods since the search engine for {\sf SAGA} was developed. 
If an update is needed.
the
modular structure of {\sf SAGA} should make it an easy task 
However, often the search engine is a low priority relative to the
other problems the Ocean-Acoustician faces.

The word {\sf SAGA} stems from Icelandic and simply means a story. 
By a saga is usually understood a prosaic long story from the middle
ages. It tends to go on forever.
Scientifically it stands for  
{\sf S}eismo-{\sf A}coustic inversion using {\sf G}enetic {\sf A}lgorithms.

{\bf New features in version 3.0}:
\begin{itemize}
\item Several errors have been corrected in both manual and code.
\item The forward codes {\sf PROSIM} and {\sf TPEM} have been much improved.
\item New objective functions are introduced.
\item It is possible to compute contour plots of Cramer-Rao bounds.
\item {\sf SNAP} does not recompute the modes if searching only for
geometric parameters. For these cases the CPU-time is reduced by about
95 \%.
\item 3D Array localization capability when using {\sf SNAP}.
\item Arrays can be any geometry.
\end{itemize}

{\bf New features in version 4.0}:
\begin{itemize}
\item The forward model {\sf CPROSIM} (broadband adiabatic normal mode) has been included.
 {\sf CPROSIM}  finds the propagating and non-propagating normal modes. Thereby also the near field is accurately calculated.
\item Line plots of sensitivity.
\item for the optimal environment {\sf POST} writes a transfer-function file.
This is done for the forward models {\sf SNAP}, {\sf PROSIM} and {\sf CPROSIM}.
\end{itemize}

{\bf New features in version 4.1}:
\begin{itemize}
\vspace{-0.2cm}
\item The forward model {\sf RAMGEO}  (Range dependent Parabolic
Equation) has been included.
\item A table of all used forward models is stored  to make sure that no model
is computed more than once. For small optimization problems this can
improve performance.
\item All used forward models is written to disk for the post processing.
\item a scatter plot of value of objective function for each parameter
  can be displayed.
\item During the inversion the posteriori analysis  can continuously be
updated. 
\item The {\sf TPEM} forward model has several options for handling
range-dependent trilinear profiles and doing refractivity-from-clutter
inversions.
\end{itemize}

{\bf New features in version 5}:
\begin{itemize}
\vspace{-0.2cm}
\item The forward model {\sf GAMARAY} has been included.
\item The forward model {\sf ORCA90} has been included.
{\sf ORCA90} seems very computationally efficient in real axis mode.
\item Gibbs sampling of the likelihood functions.
\item Enumerative sampling of the likelihood functions.
\item For all forward models it is possible to do a local optimization
using the Powell method.
\item At the end of each run a local search using the Powell method
is carried out.
\item it is possible to use random seeds to initialize the search algorithms.
\item Several options to support the inversion of atmospheric
  refractivity profiles based on clutter return in radar images has
  been implemented.
\end{itemize}
{\bf New features in version 5.3}:
\begin{itemize}
\vspace{-0.2cm}
\item main arrays are now dynamically alocated
\item Fortran 90 is used.
\end{itemize}

\begin{keywords}
genetic algorithms $\circ$ inversion $\circ$ optimization $\circ$ SAGA
\end{keywords} 
%\end{abstract}

\tableofcontents
\end{prelims}


\section{Introduction}

\begin{figure}
\epsfxsize=13cm
\centerline{\epsfbox{figures/SAGA_rot.art}}
\centerline{\epsfbox{figures/SAGA_rot.art}}
\caption{Flow diagram for the {\sf SAGA} code.}
\label{fig:flow}
\end{figure}

\begin{figure}
\epsfysize=3cm
\centerline{\epsfbox{figures/chain2.art}}
\caption{The weakest link determines the outcome of an inversion procedure.}
\label{fig:chain}
\end{figure}

{\sf SAGA}, Fig.\ \ref{fig:flow},  is a computer code for inversion of observed data. 
Its purpose can best be understood by dividing the inversion process into 
five parts:


\begin{itemize}
\item[(I)] Discretization of the environment and discretization 
              or transformation of the data.
\item[(II)] Efficient and accurate forward modeling.
\item[(III)] A suitable objective function.
\item[(IV)] Efficient optimization procedures.
\item[(V)] Uncertainty analysis.
\end{itemize}
Item (I) is concerned with how to collect and discretize a wave field
in order to have the necessary information for the
inversion, and to determine the parameters for which inversion is
feasible.  Item (I) leads to a set of known environmental parameters
and {\it a priori} bounds for the unknown parameters. Based on the
above parameters, a replica field can be computed by a forward
acoustic model, item (II).  The observed data and the replica are then
compared though an objective function, item (III).  Through an
iterative scheme, item (IV), the match between the observed and
computed data is maximized by varying the environmental
parameters. From the best models obtained, it is possible to provide
estimates of the value of the parameters and their uncertainty and
importance, item (V).  The best solution is not very interesting
without a proper statistical analysis of the result.

Complete inversion requires equal attention to all five items, as
illustrated in Fig.~\ref{fig:chain}.  It is also clear that each item
depends on its predecessor. Therefore it is natural that earlier
research has focused on the first two items. The present code is
concerned with the solution of items (III), (IV) and (V).

The forward models, item (II), presently used are:
{\sf SNAP} (normal modes) and
{\sf SNAPRD} (adiabatic normal modes) \cite{snap}, 
{\sf OAST} (wavenumber integration transmission loss model) and 
{\sf OASR} (wavenumber integration reflection coefficients model) 
\cite{hs:saf,hs:saf2},  
{\sf POPP} (normal mode reverberation model) \cite{ellis:asa95}, 
{\sf PROSIM, CPROSIM} (broadband adiabatic normal modes) 
\cite{prosim,levinson:asa95,westwood:asa96},
{\sf RAMGEO} (parabolic equation method) \cite{colins:ram,colins:asa93}
 and  {\sf TPEM} (tropospheric parabolic equation)
\cite{barrios:92,barrios:94}.

The optimization, item (IV), is based mainly on genetic algorithms
(GA) \cite{gerstoft:asa94}, but also on Gauss-Newton (GN), a hybrid
combination of GA and GN as described in \mbox{
\cite{gerstoft:asa94,gerstoft:asa95}} and simulated annealing (SA).
To ensure convergence to the global optimum, we
use several populations in parallel for the genetic algorithms. The
search efficiency can be increased by combining the GA and GN methods.
This task is handled by the optimization module {\sf SAGA}.

Two versions of SA are available: Fast SA (FSA) as
described in \cite{collins:asa92} and Very Fast SA (VFSA) as described in
\cite{ingber:89,ingber:93}.  The simulated annealing routines are provided
so that the user can assess  the estimates obtained using different
optimization methods. The SA methods do not provide an estimate
of {\it a posteriori} distributions. 

Analysis of the solution, item (V), is achieved by
 examining {\em a posteriori} distributions with the post-processor module {\sf POST}.  The solution can also be
 assessed by local methods such as  singular-value
 decomposition \cite{gerstoft:asa94,caiti:ieee94,pg:cop94}, or by plotting
 the ambiguity surface.

From the above description it is clear that inversion is a complex
procedure  and in order to be  successful  many aspects
have to be considered: Forward modeling \cite{jensen}, signal
processing \cite{tolstoy, kay}, optimization and estimation
theory \cite{bard}, global optimization \cite{sen95},
deterministic discrete inversion \cite{menke}, 
deterministic continuous inversion \cite{parker}, and 
stochastic inversion \cite{tarantola}.


\section{Background}

The non-linear inverse problem is stated as an optimization problem:
Find the model vector $\bf m$, or parameter set, that minimizes the
objective function $\phi= f( {\bf p}, {\bf q}( {\bf m}) )$, where
$\bf p$ is the observed data and $\bf q$ is the synthetically
generated data using a given forward model with a set of physical
parameters $\bf m $.
Normally, in genetic algorithms the objective function is
maximized, but here it is  minimized, 
in accordance with the precept of simulated annealing.  
    
Global optimization methods accept that the objective function is
irregular and attempt to find the global minimum, without an
exhaustive search. An advantage of global optimization is that it
requires only the value of the objective function at arbitrary points in
space. The problem can then be solved without further knowledge of
the objective function.  Thus, once the global inversion method has been
tuned, any forward model can be used.
Early solutions to the global problem were attempted using a simple
Monte Carlo method, whereas modern methods use directional searches
such as {\it genetic algorithms} (GA) or {\it simulated annealing}
(SA).
The SA method has been applied to ocean acoustics in 
\cite{collins:asa92,collins:asa91,lindsay:ieee93,dosso:ieee93}.
A comparison of SA and GA from an ocean acoustics viewpoint has been
presented in \cite{gerstoft:ecua98}.

\subsection{Optimization using Genetic Algorithms}
\noindent

Genetic algorithms are  analogous  to biological evolution.
%, one of the most efficient optimization systems.
They have been applied to  seismics
\cite{scales:jcp92,sambrigde:gji92,stoffa:g91,sen:gji92}, and
 ocean acoustics \cite{gerstoft:asa94,jesus:jca96,eliza:ecua3,lotsberg:ecua3,rendas:icassp97}.
The basic principle of  GA is simple: from all possible model
vectors, an initial population of $q $ members is selected. The
fit of each member is computed based on the fit between the
observed data and the computed data.  Then through a set of
evolutionary steps, the initial population evolves in order to become
more fit. An evolutionary step consists of selecting a parental
distribution from the population based on the individual's
fit. The parents are then combined in pairs and operators are
applied to them to form a set of children. Traditionally the crossover
rate and mutation rate operators have been used.  Finally, the
children replace part of the population to increase the match between
observed and synthetic data.

\begin{figure}
\epsfxsize=11cm
\centerline{\epsfbox{figures/figure_1.eps}}
\caption{Binary coding of model parameters.}
\label{fig:CODE}
\end{figure}

The environment is discretized into $M$ parameters in a model vector $\bf m$.
Each parameter $m_j$, $ j=1, \ldots M$, can assume $2^{n_j}$ discrete
values according to  an {\it  a priori} probability distribution (Gaussian,
rectangular or based on {\it a priori } information). Here a
rectangular distribution between a lower and upper bound
 $[m_j^{\min}$, $ m_j^{\max}]$ is used. We have, see Fig.~\ref{fig:CODE}, 
\begin{equation}
 m_{j}=m^{\min}_j +i_j \, \Delta m_j
               \;,  \,\;\;\;i_j=0,\ldots,2^{n_j} -1\;,
\label{eq:disc}
\end{equation} 
where 
\begin{equation}
 \Delta m_j= \frac{m^{\max}_j-m^{\min}_j}{2^{n_j}-1}.
\end{equation}

A major difference between simulated annealing and GA is that GA 
uses $ q$ model vectors at the same time, where $q $ is the
population size, while simulated annealing only uses one. GA consists
essentially of three operators: selection, crossover and mutation.

\underline{Selection:} In order to establish a new population, also
with $q$ members, $f \, q $ parents must be selected, $ 0 < f <1$. The
choice is made with a probability proportional to the fit of its
members. The simplest probability is given by 
\begin{equation} 
p_k =
\frac{1-\phi ({\bf m}_k)}{\sum_{l=1}^q [1-\phi ({\bf m}_l)]}, \;\;
k=1,\ldots q \; .
\label{eq:sel}
\end{equation}
The introduction of a temperature, as in simulated annealing, gives us
the opportunity to stretch the probability and improve the
 algorithm performance \cite{stoffa:g91}. Indeed, at the first
stage of the procedure, by stretching the fit, we avoid to choose
as parents only the members with the better fit, which would otherwise
tend to dominate the population; later in the optimization, this
stretching leads to a better discrimination between models with very
close fit. In order to take into account this new parameter, the
probability is rewritten as
\begin{equation}
p_k = \frac{\exp \left[ -\phi ({\bf m}^k)/T \right]}{\sum_{l=1}^q 
\exp  \left[-\phi ({\bf m}^l)/T \right]}, \;\; k=1,\ldots q\; .
\label{eq:bol}
\end{equation}         
But, as with simulated annealing, the choice of the temperature $T$ is
difficult.  It must be neither too high nor too low.  A good compromise
is a temperature of the same magnitude as the objective function, here
$ T = \min [\phi ( {\bf m}^k ) ]$.  During optimization,
the fit increases and temperature decreases.

\begin{figure}
\epsfxsize=9cm
\centerline{\epsfbox{figures/figure_2.eps}}
\caption{Crossover is a binary exchange of $l$ bits 
between the binary codes for two
model parameters. $l$ is chosen randomly.}
\label{fig:cross}
\end{figure}
\begin{figure}
\epsfxsize=8cm
\centerline{\epsfbox{figures/figure_3.eps}}
\caption{Mutation is a random change of one bit.}
\label{fig:mut}
\end{figure}


\underline{Crossover}
 For each set of parents, each consisting of a model vector, two
 children are constructed, and for each parameter in the model vector,
 each child may either be a direct copy of one parent, with
 probability $1-p_{\rm x}$, or it can be a bit crossover of the two
 parents with crossover probability $p_{\rm x}$, 
 see Fig.\ \ref{fig:cross}.  The
 crossover point is chosen randomly in the interval $[ 1,N-1 ]$, where
 $N$ is the number of bits used in the coding. Different techniques
 are available to perform this crossover of the population, e.g.,
 single point crossover where the entire ``chromosome'' is used once, and
 the multiple point crossover where the chromosome is divided into
 genes related to each parameter on which the crossover is
 applied. Multiple point crossover is used here.

\underline{Mutation:} This is a random change of one bit in the model
vector, with probability $p_m$ in order to better explore the search
space (see Fig. \ref{fig:mut}).
\vspace{0.1in}

It is possible that a run of a GA will approach a local minimum. In
order to increase the probability of finding the global minimum,
several independent populations $ M_{\rm par}$ are started.  This is
also advantageous for collecting statistical information in order to estimate
the probabilities, as shown in the examples in the next section.


In the present implementation there are relatively few GA parameters
which in principle have to be tuned for each application, and the
precise value of each of these seems to be not that important. We
usually only vary $M_{\rm par} $ in order to adjust the execution time
to the available CPU time. Based on our experience, the
following values are recommended:
\begin{itemize}
\item The population size $ q$ should be large enough to allow
%that all binary values exist in the model vectors and
the model vectors to represent several minima, but also small
enough  to allow several iterations to be performed; $q=64 $ seems to be a
good compromise.
\item The reproduction size $f$ should be large enough to allow the
fittest individuals to stay in the population during the iterations; $f$
should be less than 0.9;  $f=0.5$ is recommended.
%\item The temperature $ T$ should be
%chosen so that it follows the best fit in each population, 
%$T= \min \left\{ \phi (\bfm_k) \right\}$.
\item The crossover rate depends on how independent the parameters in
the model vector are. A crossover rate $ p_{\rm x}$ close to 1.0 seems
to be a good choice for independent parameters; for dependent
parameters a lower value, e.g. $ p_{\rm x}=0.8$, is recommended.
\item It has been found that a high mutation rate gives the best
result; $ p_{\rm m}=0.05$ is recommended.
\item The number of forward computations $N_{\rm forw}$ for each population should be
relatively low ($N_{\rm forw}=1000$--5000).
\item The number of parallel populations $N_{\rm pop}$ depends on the
application.  To obtain a reasonable estimate of the inversion
parameters, $N_{\rm pop} = 1$ is sufficient. For computing the
probability distribution it must be larger, e.g.\ $N_{\rm pop} = 50$.
\end{itemize}


\subsection{{\it A posteriori} statistics}
\label{se:post}

Before  measurement, the information about the models is reflected
in the {\it a priori} distribution $ \rho({\bf m})$, and after the experiment,
the information about the models is reflected in the {\it a posteriori}
distribution $\sigma({\bf m})$.  These distributions are related
through the likelihood function ${\cal L}({\bf m})$, which is a measure of the
goodness of fit between the observed data and the data generated using
a physical model and the environment $\bf m$ (Bayes Theorem):
\begin{equation} 
   \sigma({\bf m}) ={\cal L}({\bf m}) \rho({\bf m}) \; .  \label{eq:bayes} 
\end{equation} 

When maximizing  $  \sigma({\bf m}) $  the {\it Maximum A Posteriori} (MAP)
estimate of the parameters is obtained and when maximizing  
${\cal L}({\bf m})$  a {\it Maximum Likelihood} (ML) estimate of the
parameters is obtained.

Due to  multi-dimensionality, the {\it a posteriori} distribution, 
often with $ M > 10$, is not suitable for graphic display, 
and therefore mainly integral properties of this distribution are of interest.
From the {\it a posteriori\/} probability distribution, 
 information will be extracted to describe the solution. 
The following quantities are of interest:
The MAP solution $\MAP{\bf m}$
\begin{equation}
 \MAP{\bf m}  \equiv \arg\max\limits_{{\bf m} \in {\cal M}} \sigma ({\bf m} )~,
 \label{eq:map}
\end{equation}
the expectation $\E_\sigma[{\bf m}]$
\begin{equation}
 \E_\sigma [{\bf m}] \equiv\int\limits_{\cal M} {\bf m} \sigma ({\bf m})\, 
 {\rm d} {\bf m}~, 
 \label{eq:mean}
\end{equation}
where ${\rm d}{\bf m}  = {\rm d} m^1 \ldots {\rm d}m^M$.
The covariance matrix $\mbox{\sf Cov}_\sigma[{\bf m}]$
\begin{equation}
 {\sf Cov}_\sigma [{\bf m}] \equiv  \E_\sigma
 \left\{  [{\bf m} - \mbox\E_\sigma ({\bf m})] 
          [{\bf m} - \mbox\E_\sigma ({\bf m})]^{\rm T} 
 \right\}~,
 \label{eq:cov}
\end{equation}
the 1-D marginal {\it a posteriori} probability densities  $ \sigma^i (m^i)$ 
for parameter $m^i$
\begin{equation}
   \sigma^i (m^i) \equiv \int\sigma({\bf m})
  {\rm d}{m^1}     \ldots {\rm d}{m^{i-1}} \; 
  {\rm d}{m^{i+1}} \ldots {\rm d}{m^{M}}~,
\label{eq:mppd}
\end{equation}
and higher-dimensional marginals are defined similarly to
 Eq.~(\ref{eq:mppd}).
The marginal distributions are the most important in interpreting the
inversion result.

%%%%%%%%%%%
A problem with this approach is the derivation of a likelihood function \cite{gerstoft:asa98}.
The likelihood function depends on the stochastic model for the data,
 an example  is given in Annex \ref{se:like}. 
The standard approach in {\sf SAGA} is to estimate empirically the
likelihood function. 
Knowing that the likelihood function is usually  related to the
objective function $\phi( {\bf m}) $
through an exponential ${\cal L}=\exp \left(-\phi( {\bf m})/\hat{\nu} \right)$ 
\cite{tarantola}, where $\hat{\nu}$ is the estimated noise power, the following
scaling was used:
\begin{equation}\label{eq:GA-scaling}
{\cal L}_{\rm emp}({\bf m})= \exp \left(-[\phi( {\bf m})-\phi( {\bf m}_0)]/ T \right)~,
\end{equation}
where $ \phi $ is any objective function and ${\bf m}_0$ is the estimated
parameter vector corresponding to the optimal value of the objective
function. $T$ is the
``temperature''. Experimentally, it was found that a good value 
for $T$ is the average of the 50 best objective functions obtained
during the optimization, minus the best value of the objective
function. 
It should be noted that this value of $T$ is
not intended to estimate the noise, but rather to produce a
reasonable value with which to  estimate the uncertainties of the parameters.
The advantage of this scheme is that it works irrespective of the stochastic model for the data or likelihood function. 

During the optimization, all obtained samples of the search space are
stored, and used to estimate the {\it a posteriori} probabilities using
importance sampling \cite{gerstoft:asa98}. 

For the $\Nobs$ observations, the {\it a posteriori\/} probability for 
the $k$th model vector is  estimated by 
\begin{equation}
  \hat\sigma({\bf m}_k) = {{{ \cal L}({\bf m}_k) \rho({\bf m}_k)} 
\over{  \sum_{j=1}^{\Nobs}  { \cal L}({\bf m}_j)} \rho({\bf m}_j) }\;.
\label{eq:ppd}
\end{equation}


For the $i$th parameter $m^i$ in the model vector the marginal probability
distribution for obtaining the particular value $\kappa$
can be found by summing  Eq.~(\ref{eq:ppd}):
\begin{equation}
  \hat\sigma^i(\kappa) =
{{ \sum_{k=1}^{\Nobs} { \hat\sigma}({\bf m}_k) \;
\delta(m_k^i \! - \! \kappa)}}\;,
\end{equation}
%\over{  \sum_{j=1}^{\Nobs} { \cal L}({\bf m}_j) }}\;,
where $\delta$ is the delta-function.
In this particular implementation, several independent GA searches are
started in parallel.
It was found that when executing several parallel runs, it is sufficient
to save the last model vectors in a population within each run \cite{gerstoft:asa94}. 

%************************************************************
\section{Cook book for inversion}
\label{se:cook}

%In practice an inversion is a user driven process. 
The following is a check list for doing 
inversions with {\sf SAGA}:

\begin{enumerate}
\item Generate a baseline
environmental model using all available information.
\item Decide on one or two appropriate forward models.
\item Perform a few forward runs based on the  baseline model to 
identify the main propagation characteristics. For the
inexperienced {\sf SAGA} user it is probably advantageous to use a
stand-alone version of the forward model.
\item Decide on type of observed data and {\sf SAGA} data format.
\item Decide on objective function and scaling of observed data and replica.
\item Generate the data synthetically using the following procedure:
\begin{enumerate}
  \item Specify \underline{option {\bf W}} in the input file.
  \item Delete the *.in file.
  \item Run {\sf SAGA}. It will generate a *.obs file containing
	synthetic data based on the
	environment in the *.dat file. It will stop when the data has been
	generated because there is no observed data (*.in file).
  \item Copy this file (*.obs) into the *.in file. {\sf SAGA}
	always reads the observed data from the *.in file. 
\end{enumerate}
\item Make a short {\sf SAGA} run using only a few hundred forward
model calls, and
invert only for a few environmental parameters.
\item Is the forward model sufficiently fast, i.e.\ a runtime about 1
second, or is it necessary to simplify the environment/forward
model. Does it seem to produce reasonable results?
\item Genetic algorithms parallel  evolution in that it is
an indeterminate process. This is, however, impractical and the program
stops when a certain number of forward solutions have been generated. 
The number of forward model runs is the product of the number of
populations, $N_{\rm pop}$, and number of forward model runs in a population,
$N_{\rm forw}$.
Usually from 1,000--40,000 forward model runs are carried out. The
number of
forward runs depends on available CPU-time, the
information content in the data and the number of parameters to be estimated.

\item Generate a larger inversion example with more forward modeling runs
and environmental parameters. 
\item Use the post-processor program, {\sf POST}, to analyze the results.

{\sf POST} displays the best, maximum, and mean parameter
vectors. These are: the parameter vector that gave the best match
between the observed and calculated data; the parameter vector that
corresponds to the maximum of the {\it a posteriori } probability
distribution; and the parameter vector that corresponds to the mean of
the {\it a posteriori } distribution.  

In addition, the normalized
standard deviation for each parameter $i$ is computed, $ \sigma_i/ (F^i_{\rm max} - F^i_{\rm
min}) $. This gives an indication of the spread of a distribution for
each parameter. As a limiting case for a flat distribution, we obtain a
normalized standard deviation of $1/(2\sqrt{3})=0.29$. For a
distribution that is flat in half of the search interval, we obtain
$1/(4\sqrt{6})=0.10$.

\item Plot the results from {\sf POST}. This is best done using MATLAB.
This will show the marginal {\it a posteriori } distributions.
If \underline{option {\bf p}} is specified, 
a plot of the observed  and synthetic data for the best
environment is also shown.
\item Check if some parameters are coupled, i.e.\ depend on each
other. 
This can be investigated
using one of the following approaches:
\begin{enumerate}
  \item Stochastic approach. Plot the 2-D marginal
  {\it a posteriori } distribution between two parameters. The approach
  is similar to when the 1-D {\it a posteriori } distributions are
  plotted. First edit the {\sf SAGA} option line in the *.dat file to include 
  \underline{option {\bf m45}} to compute the 2-D marginal
  {\it a posteriori } distribution between, e.g.,\ parameters 4 and 5, and then
  run {\sf POST}.
  \item Deterministic approach.
  Plot the ambiguity function between two
  parameters. The remaining parameters are kept at their nominal values.
  Edit the {\sf SAGA} option line to include 
  \underline{option {\bf C}}, and then
  run {\sf SAGA}. Note, that it is then not required to run {\sf POST}.
\end{enumerate}
The result of both  approaches is a contour plot. This can be plotted
using {\sf CPLOT}, see Sect.\ \ref{se:graph}.
\item In the event some of the parameters are coupled, the
inversion can be made more efficient by reparameterization
 using shape functions. This is \underline{option {\bf
E}},  see also
the examples in Sect.\ \ref{se:eof}.
\item Are some parameters unimportant?  It is not necessary
to optimize unimportant parameters, or maybe they can be combined with other
parameters to a single significant parameter. In the latter case this
can be accomplished by the use of shape functions. 
This is \underline{option {\bf E}},  see also
the examples in Sect.\ \ref{se:eof}.
\item When the synthetic inversion appears to make sense, it is time to
start on the actual data collected at sea.
\item It is assumed here that good data are available. Better data
result in better and more robust inversions. Some assistance in
transforming the data into {\sf SAGA} format is available from the MATLAB
files.
\item Start observed data inversion with a short run to ensure that
every thing  works well.
\item There is no way to automatically parameterize an environment, 
and repeated trial and error is the suggested approach. In order to check the
robustness of the discretization of the environment, several
environments should be tried out.
\item That's almost it.
If the results look good, congratulations! Otherwise go back to step 1
and try again.
\end{enumerate}


\section{Installing  SAGA}


\subsection{SAGA directory}
The {\sf SAGA} home directory is defined on UNIX systems by the
following command in your .login:
 
\noindent
{\tt setenv SAGADIR  your-SAGA-root-directory}

This could e.g.\ be \$HOME/saga. 
SAGA is able to run on multiple platform mounted under NFS. In order
to do that we have  host and compiler dependent variables,
\$HOSTTYPE that should be setup in your system and \$FORTRAN
that is a variable introduced to identify the Fortran compiler.
For execution of  {\sf SAGA} you must include the scripts and executables in your
search path, i.e. \$SAGADIR/bin. The following line should be
inserted in your .login:

\noindent
{\tt set path = (\$SAGADIR/bin  \$SAGADIR/bin/\$HOSTTYPE-\$FORTRAN \$path)}


In my Linux .login these are defined as (ifc is the Intel Fortran
compiler; it can be downloaded free of charge for academic users)

\begin{tt}
setenv FORTRAN    ifc \\
\end{tt}

In my Sun Solaris HOSTNAME is system defined (to Solaris) and the
Fortran is defined as

\begin{tt}
setenv FORTRAN    solaris
\end{tt}

\subsection{Loading  SAGA files}

For users running UNIX, the whole  directory tree is provided 
in a compressed {\bf tar} file with the name

{\tt saga.tar.Z}

\noindent Place this file in your desired root directory \$HOME and issue the
commands:

{\tt uncompress saga.tar.Z

tar xvf saga.tar}

\noindent which will install the directory tree:

\begin{tabular}{ll}
\$SAGADIR &  {\sf SAGA} root directory \\
\$SAGADIR/src & Source files for {\sf SAGA} \\
\$SAGADIR/src/snap & Source files for {\sf SNAP} range independent  \\
\$SAGADIR/src/snaprd & Source files for {{\sf SNAPRD}} adiabatic modes  \\
\$SAGADIR/src/oases & Source files for {{\sf OASES}} \\
\$SAGADIR/src/popp & Source files for {{\sf POPP}} \\
\$SAGADIR/src/tpem & Source files for {{\sf TPEM}} \\
\$SAGADIR/src/prosim & Source files for {{\sf PROSIM}} \\
\$SAGADIR/src/prosim & Source files for {{\sf CPROSIM}} \\
\$SAGADIR/src/prosim & Source files for {{\sf ORCA90}} \\
\$SAGADIR/src/prosim & Source files for {{\sf GAMA}} \\
\$SAGADIR/src/ramgeo & Source files for {{\sf RAMGEO}} \\
\$SAGADIR/src/obj & Object and library files \\
\$SAGADIR/bin  &  {\sf SAGA} scripts and destination of executables \\
\$SAGADIR/examples & Data for inversion with {\sf SAGA }\\
\$SAGADIR/doc & This document in \LaTeX\, and Postscript format \\
\$SAGADIR/matlab  & Some MATLAB files\\
\$SAGADIR/util  & Some utility programs
\end{tabular}

\subsection{SAGA platforms}
{\sf SAGA} has been compiled on VMS, Digital UNIX, Linux with ABsoft
3.4 Fortran compiler, Linux with Gnu g77-0.58 Fortran compiler (the
compiler does not yet support Fortran structures and thus {\sf TPEM}
was not compiled), Linux with PGI compiler, Linux with the IFC
compiler, SunOS, and SGI-Unix.

\subsection{Building  SAGA}

Set your default directory to \$SAGADIR/src and edit the {\bf
Makefile}. Set the definition of the Fortran compiler and your desired
directories for libraries and executables (typically \$SAGADIR/bin).

You should decide which forward models you would like to compile. This can
easily be selected by commenting them  in the ``all line'' in the {\bf
Makefile}.
Also the Fortran compiler options should be modified in the {\bf
Makefile} in {\tt src} directory. For production runs, it is
advisable to compile with a high level of optimization and without
array checking.

\noindent    After  performing  the changes, compile and link  by issuing the 
command:

    {\tt make all}

\noindent which will generate all {\sf SAGA} modules.

    If  the default parameter settings are too large or too small to run
a given problem, the parameters  may 
be  altered in the parameter include file {\bf comopt.h}. Sometimes,
the parameters
controlling the forward modeling routines should also be
changed. See the 
manuals of the respective forward codes for details. 


\subsection{SAGA example files}

\vspace*{-1.0mm}
The examples are located in the directory
\$SAGADIR/examples. Most of the examples are described later in the text.
A short description of each example follows, the CPU time is for  a
DEC Alpha Station 600-5/266.

\subsubsection{Forward model OAST}

\vspace*{-1.0mm}\noindent
{\bf layer11}: Described in Sect.~\ref{se:layer11}. CPU time: 11~s.

{\bf tellaro\_oast}: For comparison with {\bf tellarosnap}. CPU time: 19~min.
\noindent

{\bf simpleoast} and {\bf simplesnap}: Simple input files to compare
data generated from either {\sf OAST} or {\sf SNAP} and inverted using the 
other model. 
\subsubsection{Forward model OASR}

\vspace*{-1.0mm}\noindent
{\bf rfl}: Described in Sect.~\ref{se:rfl}. CPU time: 15~s.

\subsubsection{Forward model OASTG}

\vspace*{-1.0mm}\noindent
{\bf horiz}: Described in Sect.~\ref{se:horiz}. CPU time: 15~s.

\subsubsection{Forward model SNAP}

\vspace*{-1.0mm}\noindent
{\bf sspmisa}: Described in Sect.~\ref{se:ssp}. 
The example is from the 1993 NRL
workshop \cite{porter:jca94}. CPU time: 8~min.

\noindent
{\bf tellarosnap}: Described in Sect.~\ref{se:tel}. CPU time: 25~min.
\noindent

{\bf genlmisa\_ga}:  The example is from the 1993 NRL
workshop \cite{porter:jca94}. 
CPU time: 8~min.

\noindent
{\bf elba}: Described in \cite{gingras:asa95}, 
it is similar to the {\sf SNAPRD}
example. CPU time: 4~min.

\noindent
{\bf simplesnap} and {\bf simpleoast}: Simple input files to compare
data generated from either {\sf SNAP} or {\sf OAST} and inverted using the 
other model. 

{\bf ys3}: Described in Sect.\ \ref{se:ys3}.
This example is using matched field inversion on
a vertical array based on seven frequencies. The data is from the Yellow
Shark experiment. CPU time: 4~h.

\noindent
{\bf whale}:  Input files to invert  humpback whale song from the 2003
 observations off the East Coast of Australia for both
location and geoacoustic parameter estimation \cite{thode05}. 

\subsubsection{Forward model SNAP3D}

\vspace*{-1.0mm}\noindent
{\bf saga3do}: Described in Sect.~\ref{se:snap3dex}. 
{\bf saga3dx}: Described in Sect.~\ref{se:snap3dex}. 
{\bf saga3dx2}: Described in Sect.~\ref{se:snap3dex}. 
{\bf saga3dx3}: Described in Sect.~\ref{se:snap3dex}. 

\subsubsection{Forward model SNAPRD}
\noindent
{\bf elbard}: Described in Sect.~\ref{se:elbard}. 
 CPU time: 27~min (three frequencies).

{\bf shot05}: Described in Sect.~\ref{se:shot05}. 
 This example is using matched field inversion on
a vertical array based on 25 frequencies.

\noindent
{\bf tl\_malta\_rd}: Described in Sect.\ \ref{se:malta}. 
The data is range-dependent transmission loss at several frequencies and depths from the
Malta experiment. CPU time: 28~h.


\subsubsection{Forward model PROSIM}
\noindent
{\bf waa}: Described in Sect.~\ref{se:waa}. The data is from the 1997 
Matched Field Inversion Workshop. CPU time: 3~h.

\noindent
{\bf mf}: Described in Sect.~\ref{se:mf}. This is an example of using
matched filter technique. 

\subsubsection{Forward model POPP}
\noindent
{\bf revpopp}: Described in Sect.~\ref{se:revpopp}. CPU time: 10~min (one frequency).

\noindent
{\bf rev\_grad3}: Described in Fig.\ \ref{fig:rev}. It uses
reverberation data from six frequencies. CPU time: 12~h.

\subsubsection{Forward model RAMGEO}
\noindent
{\bf tc1horiz}: Horizontal array example \cite{gerstoft03ph}.

\noindent
{\bf tc1v6}: Vertical array example \cite{gerstoft03ph}. Described in Sect.~\ref{se:tc1}

\subsubsection{Forward model GAMA}
\noindent
{\bf map2k}: Horizontal array example.

\subsubsection{Forward model ORCA90}
\noindent
{\bf sdc}: Vertical array example using Gibbs sampling and enumerative
integration.

\subsubsection{Forward model TPEM}
\noindent
{\bf tpem\_ex}: Described in Sect.~\ref{se:tpem-ex}. CPU time: 10~h.

\noindent
{\bf tpem\_rd}: An example of a run with  range dependent terrain profile.

\noindent
{\bf runs\_IEEE96}: This directory contains the runs  used to generate the
figures in Ref.\ \cite{gingras:ieee97}. Note, that because the forward
model has changed since the example was generated they cannot be
reproduced precisely.


%*******************************************************************
\section{SAGA: General features}

The inversion package consists of two main programs, an optimization
program ({\sf SAGA}) and a program that analyzes the samples from the
optimization ({\sf POST}). In addition, there are several matlab scripts
for writing, reading and plotting data.

The saga program can be executed    from matlab 

{\tt $ > >$ runsaga('filename','forward-model')}

This will continuously update the displays for the posteriori analysis
while the inversion is running.

The unix command to run {\sf SAGA} is:

{\tt saga filename  forward-model}

at present, {\tt  forward-model}
can be either {\tt oast, oasr, oastg, snap, snaprd, popp, prosim,
cprosim, orca, gama, ramgeo, tpem}.
The filename should be without extension.

The main program stores information which can be processed by the 
post-processor.  The post-processor computes {\em a posteriori}
 probability densities, 
prepares plots of observed data and of data obtained from the inversion. 
The run command is:

{\tt post filename forward-model}


File names  are  passed  to   {\sf SAGA} and {\sf POST}   via 
environmental variables. In UNIX systems, a typical command  file 
{\bf saga} (in  \$SAGADIR/bin) is (and a similar one for {\bf post}):

\small
\begin{verbatim}
#                          the hash mark invokes the C-shell 
setenv FOR001 $1.dat   # input file
setenv FOR002 $1.in    # observed data input file
setenv FOR003 $1.wei   # weighting of the data 
setenv FOR007 $1.out   # output file
setenv FOR007 $1.pout  # output file from post
setenv FOR009 $1.eof   # shape function file
setenv FOR010 $1.mat   # The best obtained parameters and
                       #  objective function for each population.
setenv FOR011 $1b.mat  # The $1.mat sorted according to fit (POST)
setenv FOR011 $1.m     # plotting parameters used by plotsaga (POST)
setenv FOR019 $1.plp   # plot parameter file
setenv FOR020 $1.plt   # plot data file  
setenv FOR028 $1.cdr   # contour plot parameter file 
setenv FOR029 $1.bdr   # contour plot data file 
setenv FOR030 $1.obs   # synthetic generated from the initial environment
setenv FOR060 $1.ext   # same format as $1.mat, for each improved fit

 if     ($argv[2] == "snap"    ) then
      $SAGADIR/bin/sagasnap                # snap   executable
 elseif ($argv[2] == "snaprd"  ) then
      $SAGADIR/bin/sagasnaprd              # snaprd executable
 elseif ($argv[2] == "oast"    ) then
      $SAGADIR/bin/sagaoast                # oast   executable
 elseif ($argv[2] == "oasr"    ) then
      $SAGADIR/bin/sagaoasr                # oasr   executable
 elseif ($argv[2] == "oastg"   ) then
      $SAGADIR/bin/sagaoastg               # oast gradient executable
 elseif ($argv[2] == "popp"    ) then
      $SAGADIR/bin/sagapopp                # popp   executable
 elseif ($argv[2] == "tpem"    ) then
      $SAGADIR/bin/sagatpem                # tpem   executable
 elseif ($argv[2] == "prosim"  ) then
      $SAGADIR/bin/sagaprosim              # prosim executable
 elseif ($argv[2] == "cprosim" ) then
      $SAGADIR/bin/sagacprosim             # cprosim executable
 elseif ($argv[2] == "ramgeo"  ) then
      $SAGADIR/bin/sagaramgeo              # ramgeo executable
 elseif ($argv[2] == "orca"  ) then
      $SAGADIR/bin/sagaorca              # ramgeo executable
 elseif ($argv[2] == "gama"  ) then
      $SAGADIR/bin/sagagama              # ramgeo executable
 endif
\end{verbatim}
\normalsize

Each time {\sf POST} is executed it updates the files \bf results \rm and
\bf results.m \rm in the current directory.

\subsection{Graphics}  
\label{se:graph}

Standard
output files from {\sf POST} can be plotted using MATLAB. Simply put 
{\tt \$SAGA/MATLAB} in your MATLAB path, for example in the .login file:

{\tt setenv MATLABPATH  \$home/saga/MATLAB} 

start up MATLAB and execute

{\tt $> >$ plotsaga}

When plotting from MATLAB, each {\it a posteriori} distribution is
plotted individually and when  
\underline{option {\bf p}} is specified a plot of the observed data and data
corresponding to the best fit is also provided.

A scatter plot of the objective function for each parameter can be
obtained by executing 

{\tt $> >$ sagascat}

Contour plots (of ambiguity function, 2D marginal PPD, and Cramer-Rao
bounds) can also be obtained using MATLAB:

{\tt $> >$ contsaga}

 {\sf contsaga} uses the data values in the
*.bdr file and some commands in the *.m file; the *.cdr file is
neglected when plotting from MATLAB. 


The files *.m and *.mat from the program can be plotted using MATLAB.

\subsection{Useful scripts}
Some useful UNIX-scripts  are provided in the \$SAGADIR/bin:

\noindent
{\tt zap name}\\
Kills all processes that have {\tt name} in their command-field,
e.g. {\tt zap saga}.

\noindent
{\tt zapnice name}\\
For all processes with {\tt name} in their command-field, the
CPU-priority is reduced by one.

\noindent
{\tt zapmax name}\\
For all processes with {\tt name} in their command-field, the
CPU-priority is reduced to the minimum.


\newpage
%************************************************************************
\section{SAGA: The input file}
The structure of the input file is given in Table \ref{tab:saga}; the file must
have the extension *.dat.

\begin{table}
\begin{center}
\small
\begin{tabular}{|l|l|}
\hline \hline
Input parameter & Description \\
\hline \hline

\multicolumn{2}{|l|}{{\bf Block I: TITLE}~~~~~~~~~~~(1 line)}  \\ \hline
TITLE & Title of run  \\
\hline
\multicolumn{2}{|l|}{{\bf Block II: OPTIONS}~~~~~~~~(1 line)} \\ \hline
A B C $\cdots$ & Output and computational options, see Sect.\ \ref{se:sagaopt}   \\
\hline
\multicolumn{2}{|l|}{{\bf Block III: GA- PARAMETERS}~~~~~~~~(2 lines)}  \\ \hline
niter q npop ...& niter: Forward modeling runs for one
population  \\
 	& q: Population size \\
 	& npop: Number of parallel populations  \\
        & ...: Some options require more parameters  
          ({\tt t0},...)\\
px pu pm& px:  Crossover rate (typically 0.8) \\
        & pu:  Update rate (typically 0.5)    \\
        & pm:  Mutation rate (typically 0.05) \\
\hline
\multicolumn{2}{|l|}{{\bf Block IV: FORWARD MODEL PARAMETER}~~~~~(many lines)} \\ \hline
.       & This block correspond to the forward model in the   \\
.        &  same format as given in the users manual for each  \\
.        & forward model. See  Sect.\ \ref{se:forw}    \\
.	 &  \\ 
\hline
\multicolumn{2}{|l|}{{\bf Block V: OPTIMIZATION
                                  PARAMETER}~~~~~~(nparm+1 lines)}\\ \hline
nparm  & nparm: Number of parameters  to optimize    \\ 
parm index Fmin Fmax Ndiscr &  parm: Pointer to 
physical parameter (see  Sect.\ \ref{se:forw}) \\
.     &index: Addresses a specific variable within a vector\\
.    &(for {\sf SNAPRD}, {\sf PROSIM} and {\sf TPEM}: {\tt index} represents \\
.     &  two variables {\tt index}, {\tt index2}, see Sect.\ \ref{se:forw})\\
.    & Fmin: Lower bound for the search parameter\\
.    & Fmax: Upper bound for the search parameter \\
.    & Ndiscr:	Number of discrete values of the parameter\\
\hline
\end{tabular}
\end{center}
\caption{ {\sf SAGA} input file structure.
 \label{tab:saga} }
\end{table} 


\subsection{SAGA options}
\label{se:sagaopt}
The following options are supported by  {\sf SAGA}. Each option should be
separated by a blank space. The pointer ({\tt iopt}) is
used internally in the program; 
it is of use only to the programmer.

\noindent FORWARD MODEL \\
(the forward model is specified at execution time; 
the following flags are set automatically):

\vspace{-0.6cm}
\begin{itemize}
    \item[] (iopt(30)=1) {\sf SNAP} is used.
\vspace{-0.3cm}
    \item[] (iopt(30)=2) {\sf SNAPRD} is used.
\vspace{-0.3cm}
    \item[] (iopt(30)=3) {\sf OAST} is used.
\vspace{-0.3cm}
    \item[] (iopt(30)=4) {\sf OASR} is used.
\vspace{-0.3cm}
    \item[] (iopt(30)=5) {\sf POPP} is used.
\vspace{-0.3cm}
    \item[] (iopt(30)=6) {\sf TPEM} is used.
\vspace{-0.3cm}
    \item[] (iopt(30)=7) {\sf PROSIM} is used.
\vspace{-0.3cm}
    \item[] (iopt(30)=8) {\sf CPROSIM} is used.
\vspace{-0.3cm}
    \item[] (iopt(30)=9) {\sf RAMGEO} is used.
\vspace{-0.3cm}
    \item[] (iopt(30)=10) {\sf GAMA} is used.
\vspace{-0.3cm}
    \item[] (iopt(30)=11) {\sf ORCA} is used.
%\vspace{-0.3cm}
    \item[] (iopt(12)=1) 3 indexes are used for 
  pointing to the optimization parameters (used in {\sf SNAPRD}, {\sf
  TPEM}, {\sf PROSIM}, {\sf CPROSIM}, {\sf GAMA},{\sf ORCA}, {\sf RAMGEO} ).
\vspace{-0.3cm}
    \item[] (iopt(12)=0) 2 indexes are used for 
  pointing to the optimization parameters (used in {\sf SNAP}, {\sf OASR}, {\sf OAST}, {\sf POPP}).
\end{itemize}
\noindent INVERSION DOMAIN \\
(default {\bf r})

\vspace{-0.6cm}
\begin{itemize}
    \item[{\bf w}] (iopt(1)=1) (for {\sf OAST}) inversion in wavenumber--depth domain.
\vspace{-0.3cm}
    \item[{\bf r}] (iopt(1)=2) (for {\sf OAST}) inversion in range--depth domain.
\vspace{-0.3cm}
    \item[ ] (iopt(1)=3) (for {\sf OASR}, automatic) inversion in
angle domain.
\vspace{-0.3cm}
    \item[ ] (iopt(1)=4) (for {\sf POPP}, automatic) inversion in time
domain.
\end{itemize}

\noindent OBSERVED DATA FORMAT\\
(See also Sect.~\ref{se:data})\\
{\it (Should {\bf always} be specified)}:

\vspace{-0.6cm}
\begin{itemize}
    \item[{\bf d}] (iopt(2)=1)   reading data (subroutine {\tt readdat2}).
This is the most general format, which allows for reading complex-valued or real-valued data as a function of frequency, depth and range.
For the format of the *.in file see Sect.\ \ref{se:opt_d}.
\vspace{-0.3cm}
    \item[{\bf D}] (iopt(2)=2)   reading  data (subroutine {\tt readdata}).
This is only for data given as a function of range. The range block in
the forward model should then contain {\tt Rmin} and {\tt Rmax} in one line.
For the format of the *.in file see Sect.\ \ref{se:opt_D}.
\vspace{-0.3cm}
    \item[{\bf e}] (iopt(2)=3)   reading complex pressure vector on a
      {\it vertical}
array (subroutine {\tt read\_HP}). This option also requires
\underline{option {\bf f}} or \underline{option {\bf F}} 
for objective function.
For the format of the *.in file, see Sect.\ \ref{se:opt_e}.
\vspace{-0.3cm}
    \item[{\bf T}] (iopt(2)=3)   reading complex pressure vector on a
      {\it horizontal}
array (subroutine {\tt read\_HP}). This option also requires
\underline{option {\bf k}} for objective function.
Note, that the {\tt snap3d} is rotating a vertical array and therefore
   \underline{option {\bf e}} should always be used.
For the format of the *.in file see Sect.\ \ref{se:opt_T}.
\vspace{-0.3cm}
    \item[{\bf c}] (iopt(13)=1)   reading covariance matrix 
(subroutine {\tt read\_cov}).
For the format of the *.in file see Sect.\ \ref{se:opt_c}.
\vspace{-0.3cm}
    \item[{\bf W}] (iopt(21)=1) writing calculated data using
the baseline model to the *.obs file.
  The format is determined by the input \underline{option {\bf d, D, c, e}}.
The *.obs file can then be copied to the *.in  file and used as `observed'
data. Even when the input file does not exist and the program aborts,
the *.obs file  is written, and the *.obs file can then be copied to the *.in file.
\vspace{-0.3cm}
    \item[{\bf z}] (iopt(11)=1)
 Adds noise to the covariance matrix (\underline{option {\bf c}})
before it is written to the *.obs file.  
It is only added 
   in the diagonal and with a specific SNR.  The SNR is specified in dB
   and is given as the last  parameter 
in the second line with GA-parameters, after the
   mutation rate {\tt pm}.


\end{itemize}
	
\noindent SCALING OF COVARIANCE MATRIX\\
(default is no scaling)
\vspace{-0.6cm}
\begin{itemize}
    \item[{\bf b}] (iopt(20)=1)   the 
covariance matrix is normalized by dividing it by the sum of the
 diagonal. The maximum obtainable 
 Bartlett power is slightly less than one (depending on the noise in the data).
\vspace{-0.3cm}
    \item[{\bf B}] (iopt(20)=2)   the 
covariance matrix is normalized by the largest eigenvalue of 
the covariance matrix. Thereby, the maximum obtainable  Bartlett power is one.
\end{itemize}

\noindent TRANSFORMATION OF CALCULATED DATA\\
(default is no transformation)
\vspace{-0.6cm}
\begin{itemize}
    \item[{\bf s}] (iopt(3)=1, itrans(1)=1)  weighting replica  with $\sqrt{r}$. 
The observed data should be weighted before running {\sf SAGA}. 
This option should only be used for transmission loss data.
In this way the transmission loss is corrected for geometrical spreading.
\vspace{-0.3cm}

    \item[{\bf R}] (iopt(3)=2, itrans(2)=3)  weighting replica with $1/ \sqrt{r}$.
The observed data should be weighted before running the program. Should only
be used for transmission loss data.
 This places more
emphasis on matching the closer range of the transmission losses.
\vspace{-0.3cm}
%\vspace{-0.76cm}
    \item[{\bf l}] (iopt(3)=1, itrans(3)=2) inversion  with  dB scaled observed
and calculated data. The  observed data should be expressed as $-20 \log p $.
\vspace{-0.3cm}
    \item[{\bf l2}] (iopt(3)=12, itrans(3)=12) inversion  with  dB scaled observed
and calculated data. The  observed data should be expressed in
    physical units, not in dB.
\vspace{-0.3cm}
    \item[{\bf G}] (iopt(3)=5, iopt(25)=1, itrans(5)=5) using only the magnitude of
observed and calculated data.
\vspace{-0.3cm}
    \item[{\bf h}] (iopt(27)=1)     observed and calculated
data are normalized to unity. This works only for a local method; for the
global method it is defined through the objective function. 
\vspace{-0.3cm}
    \item[{\bf M}] (iopt(3)=44, itrans(4)=44) both data and replica are 
weighted with the values read from the *.wei data file
(see Sect.\ \ref{se:opt_M}).
\vspace{-0.3cm}
    \item[{\bf M1}] (iopt(3)=40, itrans(4)=40) only  data are 
weighted with the values read from the *.wei data file
(see Sect.\ \ref{se:opt_M}).
\vspace{-0.3cm}
    \item[{\bf M2}] (iopt(3)=04, itrans(4)=04) only replica are 
weighted with the values read from the *.wei data file (see Sect.\ \ref{se:opt_M}).
\end{itemize}


\noindent OBJECTIVE FUNCTION\\
(See also Sect.~\ref{se:obj})\\
{\it (Should {\bf always} be specified)}

Objective function that works with data formats \underline{option {\bf
D, d, e, T}}
\vspace{-0.6cm}
\begin{itemize}
    \item[{\bf N}] (iopt(5)=0), Eq.\ (\ref{eq:obj1}), objective function is computed based on 
  the sum of the  squared error between the magnitude of the observed and
calculated data, using complex-valued data (if available).
This matches only the shape of one curve using all frequency, range and
depth information.
\vspace{-0.3cm}
    \item[{\bf n}] (iopt(5)=1), Eqs.\ (\ref{eq:obj2}, \ref{eq:objn}),  objective function is computed based on 
  the sum of the  squared error between the magnitude of the observed and
calculated data as a function of range.
This matches only the shape of a curve. 
There are as many curves as frequencies and depths.
\vspace{-0.3cm}
    \item[{\bf X}] (iopt(5)=3),  Eqs.\ (\ref{eq:obj2}, \ref{eq:objX}),  objective function is computed
based on 
   the sum of the  squared error between the magnitude of the observed and calculated data.
    This matches both the shape and the offset of a curve.
There are as many curves as frequencies and depths.
\end{itemize}

Objective function that works with data format \underline{option {\bf
e, d, T}}
(complex-valued data). The standard is to use \underline{option {\bf e
}} for vertical array. 
Except for {\sf SNAP} where horizontal arrays are obtained by
rotating a vertical array, horizontal array data is read in using the
underline{option {\bf T }}
\vspace{-0.6cm}
\begin{itemize}
    \item[{\bf f}] (iopt(5)=4), Eq.\ (\ref{eq:objf}), incoherent addition of Bartlett power
across frequencies using pressure vector on an array(s).
This array is summed over the depth of the array, but for {\sf SNAP3D }, the array can be arbitrarily oriented. 
At least two phones required.
Each frequency component  is weighted according to the power in the
received signal.
\vspace{-0.3cm}
    \item[{\bf f1}] (iopt(5)=4, isubopt(5)=1), Eq.\ (\ref{eq:objf1}). Similar to option {\bf f}, but in the summation of the objective function, 
each frequency component has the same weight.  Both replica and data
vector are normalized to one.
 \vspace{-0.3cm}
    \item[{\bf k}] (iopt(5)=7), Eq.\ (\ref{eq:objf}), incoherent addition of Bartlett power
across frequencies using pressure vector on an horizontal array(s).
This array is summed over the range of the  array,
At least two phones required.
Each frequency component is weighted according to the power in the
received signal.
 \vspace{-0.3cm}
    \item[{\bf k1}] (iopt(5)=7), Eq.\ (\ref{eq:objf}). Similar to option {\bf k}, but in the summation of the objective function 
each frequency component has the same weight.
 \vspace{-0.3cm}
    \item[{\bf F}] (iopt(5)=5), Eq.\ (\ref{eq:objF}),   broadband matched filter.
Incoherent addition of Bartlett power
across phones using pressure vector for several frequencies.
At least two frequencies required.
This option works best in combination with {\sf PROSIM} or {\sf CPROSIM}.
When combining several phones each phones has the same weighting, regardless of the received energy on the phone.
\vspace{-0.3cm}
    \item[{\bf j}] (iopt(5)=6), Eq.\ (\ref{eq:objj}), this objective function compares the
    relative phase
and magnitude of the observed and calculated pressure vector. Used in Ref 
\cite{gerstoft:ieee00}.
\vspace{+0.3cm}
\end{itemize}

Objective function that works with data format \underline{option {\bf c}}
(covariance matrix).
\vspace{-0.6cm}
\begin{itemize}
 \item[{\bf c}] (iopt(13)=1), Eq.\ (\ref{eq:bart}), 
        the objective function is the Bartlett power.
         By default the Bartlett power for each frequency is summed.
\vspace{-0.3cm}
    \item[{\bf O}] (iopt(18)=1),  Eq.\ (\ref{eq:bart2}),  
           the Bartlett power for each frequency is multiplied together.
\end{itemize}

Objective function is modified, this is independent of  data format.
\vspace{-0.6cm}
\begin{itemize}
    \item[{\bf L}] (iopt(9)=1)    regularization, see Annex
\ref{se:reg}. This
option  has influence on the computation of  the objective function in
{\sf SAGA}. The objective function then consists of two parts, the
standard one measuring the fit of the data, and one
measuring the deviation from the baseline model. For this option
we must first specify for which parameters the {\it a
priori} information should be included. In Block IV, Table
\ref{tab:saga}, after {\tt Ndiscr}  a positive number indicates 
{\it a priori} information and a negative indicates none.
\vspace{-0.3cm}
    \item[{\bf q}] (iopt(23)=1)    {\it a priori} information, 
see Annex \ref{se:reg}. This
option does not affect the computation of the objective function in
{\sf SAGA}, but only the computation in {\sf POST}. For this option,
we must first specify for which parameters  the {\it a
priori} information should be included. In Block V, Table
\ref{tab:saga}, after {\tt Ndiscr},  a positive number indicates 
{\it a priori} information, and a negative indicates none.
The {\it a priori } information used for each parameter
 is a triangular distribution
with maximum at the baseline value and zero at the bounds.
    \item[{\bf V}] (iopt(31)=1)    In calculating the objective function, the code is not stopped in case of an unphysical response function where all data is zero. This should only be used to circumvent problems in the forward code.
\end{itemize}

\noindent OPTIMIZATION\\
(default is to use genetic algorithms)

\vspace{-0.6cm}
\begin{itemize}
    \item[{\bf E}] (iopt(17)=1) shape functions are used to describe the environmental
input. A shape function file must be supplied (see Sect.\ \ref{se:eof}). 
\vspace{-0.3cm}
    \item[{\bf x}] (iopt(24)=1) the baseline model in the input is included
as an initial member of the first {\tt t0} populations in the GA optimization.  
\vspace{-0.3cm}
    \item[{\bf a}] (iopt(4)=1) using simulated annealing for the optimization.
The version is adapted from a code by Mike Collins. {\tt niter} is the
number of
Metropolis steps, the number of forward models is then {\tt niter*nparm}.
Two additional parameters should be specified in the first line of the
GA parameter block:
{\tt t0}
is starting temperature (often 1) and {\tt t1} indicating that quenching 
is used after iteration
{\tt t1}. {\tt Ndiscr} determines the maximum allowed jump (often 
{\tt Ndiscr = 1}).  
There is no post-processing when using simulated annealing, only the best model
is displayed.
\vspace{-0.3cm}
    \item[{\bf v}] (iopt(4)=3) 
using very fast simulated annealing (VFSA) for the optimization.
The version is adapted from a code by M.~Sen, and based on the paper by
Ingber \cite{ingber:93}. It seems to be faster than the simulated annealing version
described above. VFSA offers great flexibility in selecting
optimization control
parameters, but here only the initial temperature can be varied.
 {\tt niter} is the number of
Metropolis steps, the number of forward models is then {\tt
niter*nparm}.
One additional parameters should be specified in the first line of the
GA-parameter block:
{\tt t0}
is the starting temperature (often 1). 
There is no post-processing when using simulated annealing, only the best model
is displayed.
\vspace{-0.3cm}
    \item[{\bf g}] (iopt(4)=2)  using the Powell method  for the optimization.
The Powell method is very useful as it does not require any
computations of gradients. {Gauss--Newton
      can also be used, but  at present it is only available using the analytic derivatives {\sf OASTG}}.
The starting point for the local search is
the baseline model given in the input.
The stop criteria is that the improvement for each parameter is less than
$0.2 (F{\rm max}-F{\rm min}) /N{\rm discr}$.
\vspace{-0.3cm}
    \item[{\bf H}] (iopt(16)=1) the hybrid optimization scheme is used.
{ At present only available using the analytic derivatives {\sf OASTG}}.
A forward modeling call consists then of 5 Gauss--Newton steps,
 see \cite{gerstoft:asa95}.
\vspace{-0.3cm}
    \item[{\bf Z}] (iopt(29)=1) Single point crossover. In SAGA, the default is to do multiple point crossover (one crossover for each parameter), thus the value of every parameter may be changed in one forward model call. The single point crossover only changes one parameter per forward model call.
\vspace{-0.3cm}
    \item[{\bf y}] (iopt(33)=1) Gray  coding \cite{heitkoetter} of the binary numbers. 
Gray code represents each number in the sequence of integers
$[0,...,2^{N-1}]$as a binary string of length $N$ in an order such
that adjacent integers have Gray code representations that differ only
by one bit positions. Marching through the integer sequence therefore requires flipping just one bit at a time. Some researches have found that Gray code representation works better than binary representation. 
\vspace{-0.3cm}
    \item[{\bf ?}] (iopt(34)=1) A true random number is used instead
 of 
using  the same random
    number when starting the random number generator.
\end{itemize}

\noindent LIKELIHOOD INTEGRATION {\sf SAGA} \\
The default is to estimate the posterior probabilities based on the
models sampled during a GA run (this is done by {\sf POST}). That
approach is very efficient and gives a good indication of the
posterior probabilities. It is quite empirical, biased and not very
precise.
For details on the likelihood integration see Chapter {\bf XXX}.

The likelihood integration module is invoked by using
\underline{Option {\bf S}}, and on a new line below the GA parameters,
the user must specify
\\
\\
\begin{tt}
nu   e\_{stop} e\_{rot} k\_{grow}
\end{tt}

{\tt nu} is the error in Eq. (XXX). \\
 {\tt e\_stop} is the stop criteria (recommended value: 0.1) \\
{\tt e\_rot} is the  criteria for accuracy of the matrix, before rotating 
(recommended value: 0.1)\\
{\tt  k\_{grow}} is the factor used in  Eq. (XXX).

The output from the Gibbs sampling is written to the binary files
{\it filenm.gs1}
and  {\it filenm.gs2}. These can be read and plotted with
{\it plotgibbs.m}
(it also uses {\it read\_gs\_bin.m}). The enumerative integration is
  written to the binary file {\it enum.mat} and can be read and plotted with
{\it plotenum.m}
(it also uses {\it read\_enum\_bin.m}).

\vspace{-0.6cm}
\begin{itemize}
    \item[{\bf S} or {\bf S0} ] (iopt(4)=1, isubopt(4)=1) Gibbs sampling. 
   During
    optimization, all parameters are changed simultaneously. {\tt
   niter} iterations is carried out and convergence is then tested.
   If the  
    \item[{\bf S1}] (iopt(4)=1, isubopt(4)=0) Gibbs sampling.   During
    optimization, one parameter at a time is changed. Otherwise the
    same as option {\bf S}.
\item[{\bf Sx1}]   (isubopt(35)=1) Using an adaptive adjustment of the
  search interval, based on Eq. (xxx).
\item[{\bf S2}] (iopt(4)=1, isubopt(4)=2) Enumerative integration.\\
\end{itemize}
    
\noindent PLOTS FROM {\sf POST} \\
(default is to plot the {\it a posteriori} probability distribution on a
 scale corresponding to the search interval using the default weighting. 
 A good data check is obtained by plotting the data as well as the
best model using \underline{option {\bf p}}.
 A table of best fit, mean and most
likely value for each parameter is given in the output.)

\vspace{-0.6cm}
\begin{itemize}
    \item[{\bf p}] (iopt(10)=1) a line plot of the data (full line)
 and the calculated
data (dashed line) using the best found model. For a covariance matrix
as input data, 
\underline{option {\bf c}}, we estimate the pressure vector 
as the first eigenvector of the covariance matrix. 
For a vertical array the power across the array is only plotted, but
the phase and Bartlett power can also be plotted.
 \vspace{-0.3cm}
   \item[{\bf p2}] (iopt(10)=2) For the covariance matrix option
\underline{option {\bf c}}, both magnitude and phase are plotted (two plots per frequency).

\vspace{-0.3cm}
   \item[{\bf p3}] (iopt(10)=3) For covariance matrix option \underline{option {\bf c}} (iopt(10=3) For covariance matrix (opt c) both magnitude and phase and
   'Bartlett power' is plotted (three plots per frequency). The
   precise definition of 'Bartlett power' is in \cite{gerstoft:asa96}

\vspace{-0.3cm}
    \item[{\bf A}] (iopt(19)=1) the starting model is superimposed on the
{\it a posteriori } probability plot.
\vspace{-0.3cm}
    \item[{\bf i}] (iopt(14)=1) plotting the {\it a posteriori}
 probability distributions in physical
units, instead of plotting them all on a dimensionless scale from 0 to
1.
\vspace{-0.3cm}
    \item[{\bf I}] (iopt(14)=0) plotting the {\it a posteriori}
 probability distributions  on a dimensionless scale from 0 to 1.
This creates  one plot of the distributions.
\vspace{-0.3cm}
    \item[{\bf m13}] (iopt(16=1) computes the 2-D marginal {\it a
posteriori} density distribution between two parameters, here
parameters 1 and 3. Both
parameters have to be one digit, i.e.\ less than 10. 
The plot is normalized so that the maximum is one.
Usually a nice plot is obtained by using the scale 0--0.1.
It can be  plotted using {\sf CPLOT}.
\vspace{-0.3cm}
    \item[{\bf u}] (iopt(28)=2) the  {\it a posteriori} probability
distribution is produced using a uniform weighting of all the observed
model vectors. This causes a flatter distribution.
\vspace{-0.3cm}
    \item[{\bf Pj}] (iopt(28)=1) maximum likelihood based
post-processing of the {\it a posteriori} probability distribution. 
    It is based on Monte Carlo integration of the likelihood
function.  $j$ indicates the number of modes used in the likelihood
function; if it is not specified then  $j=5$. 
This requires the use of \underline{option {\bf c}
or  {\bf f}} as choice of objective function.
\end{itemize}

\noindent PLOTS FROM  {\sf SAGA}: \\
For these options, no global optimization is carried out and it is not necessary to run {\sc POST}. 

\vspace{-0.6cm}
\begin{itemize}
    \item[{\bf C}] (iopt(8)=1) contour plot of the objective function
versus first and second parameter given in the inversion. The first
search parameter specifies the $x$-axis and the second the
$y$-axis. The discretization along each axis is specified by {\tt
Ndiscr}. The maximum discretization in each direction is 200.
It can be  plotted using the matlab program {\sf contsaga}.
The objective function is expressed in dB relative to the minimum of
the objective function, $10 { \rm log10} (\Phi/\Phi_0)$, which will
then have a maximum value of 0~dB. The dynamic scale will be 5~dB. 
 \vspace{-0.3cm}    \item[{\bf C1}] (iopt(8)=2) 
Same as \underline{option {\bf C}}, except that the objective functions
 is not scaled relative to the maximum of ambiguity function.  $-10 { \rm log10} (\Phi)$ is plotted.
 \vspace{-0.3cm}    \item[{\bf C2}] (iopt(8)=3) 
Same as \underline{option {\bf C}}, except one minus the objective function
 is plotted, and the plot is not scaled. $-10 { \rm log10} (1-\Phi)$ is plotted.
This is the recommended approach when using a conventional processor.
 \vspace{-0.3cm}    \item[{\bf C3}] (iopt(8)=4) 
Same as \underline{option {\bf C}}, except one minus the objective function
 is plotted, and the plot is not scaled. $-10 { \rm log10} (1/N*\sum_{i} (trC_i)-\Phi)$ is plotted.

\vspace{-0.3cm} \item[{\bf U}] (iopt(22)=1) Uncertainty for a {\bf
    local method}. 
 Based on analytic computed gradients. The Cramer-Rao bounds for a
   stochastic signal  is computed. As a function of the first two
   unknown parameters the standard deviation of the diagonal entries in
   the Cramer-Rao matrix is plotted for all unknown parameters. It
   requires that {\tt oastg} is used, with option \underline{option {\bf g}}.
\vspace{-0.3cm} \item[{\bf K}] (iopt(32)=1) Line plot of objective function. 
Using the reference environment as a baseline  a line plot of the
sensitivity for each optimization parameter specified in the input
file  is computed using the bounds and discretization as given in the
input file. The plot is given on a dB-scale with the maximum for each
parameter being normalized to 0 dB. The plot shows the variation of
$-10 log10 (\phi)$, where $\phi$ is the objective function.The plot is obtained using MATLAB on the {\it filename.m}-file. 
\vspace{-0.3cm} \item[{\bf K1}] (iopt(32)=2) Similar to option {\bf K}, but 
the maximum for each parameter is not normalized. $-10 { \rm log10} (\Phi)$ is plotted.
 \vspace{-0.3cm}    \item[{\bf K2}] (iopt(32)=3) 
Same as \underline{option {\bf K}}, except one minus the objective function
 is plotted, and the plot is not scaled. $10 { \rm log10} (1-\Phi)$ is plotted.
\end{itemize}

\noindent MISCELLANEOUS:

\vspace{-0.6cm}
\begin{itemize}
    \item[{\bf Q}] (iopt(6)=1) debugging. This  option writes  lots of extra 
information for the first couple of iterations. 
\end{itemize}

\include{letter}

\newpage


\section{Format of the observed data}
\label{se:data}

The data file (*.in) contains information about the observed
data. Even for synthetic data, this is the standard mode to pass
observations to the {\sf SAGA} program.  Data can be written out from the
program by using \underline{option {\bf W}}.  The program supports four formats ({\bf
c}, {\bf d}, {\bf D} and {\bf e}) which are described below.  For
other inversion purposes they might have to be modified.

For each of these files, a ``{\bf !}'' as the first character of a line
means a comment.  No blank lines!


The order of the data in the *.in file 
should always be the same as the specified in the *.dat file. For
example often the receiver depths in the *.dat can be specified from
the top or the bottom of the array, it should then be ordered
similarly in the *.in file.

\subsection{Covariance matrix file}
\label{se:opt_c}
The   covariance matrix file stores  the covariance matrix calculated from
the pressure on a vertical array for a single frequency. The program gives a 
warning if the first line does not contain the string ``Covariance matrix''.
The format of the file is:

\small
\begin{verbatim}
loop over freq                    ! in increasing order
     loop over range            ! ranges as appearing in input file
      read(2,*)dummy-title
      read(2,*)dummy-freq 
      read(2,*)dummy-ndep
      do idep=1,ndep
         READ(2,*)receiver_depth                  !rd
      enddo
      do idep1=1,ndep                            ! Row
         do idep=1,ndep                          ! Column
             READ(3,*)jdum,idum,cov(idep1,idep,ibart)    
                                                 ! idum, jdum is not used 
         enddo
      enddo
   enddo
enddo
\end{verbatim}
\normalsize

In this file, the covariance matrix for several frequencies can be stored,
not all covariance matrices need to be read in. The program only
stores  the ones corresponding to the frequencies to be used in the inversion.
The covariance matrices should be given in the same order as the 
frequencies in the input file.

If the first or last receiver depth does not correspond to the
depth in the input file, a warning is issued.

\subsection{General data input (option d)}
\label{se:opt_d}
This is a  general data file for passing data to the  {\sf SAGA} program 
(using
subroutine {\tt readdat2}). 
The format is (data can be  either real-valued or complex-valued):

\small
\begin{verbatim}
loop over freq                    ! in increasing order
   loop over depth
      loop over ranges
         read(2,*)ifreq idepth,irange,data           
      enddo
   enddo
enddo
\end{verbatim}
\normalsize

where {\tt ranges} can mean either number of
 ranges or wavenumbers. The counters {\it ifreq idepth, irange} is not used when reading the data. There is no check if the correct frequencies, depths or ranges are read.

\subsection{Range data input (option D)}
\label{se:opt_D}
This is for reading in pressure-data as a function of range 
(using subroutine {\tt readdata}). 
Only points in the
range {\tt Rmin} to {\tt Rmax} are used.   {\tt Rmin} and {\tt Rmax} are 
given in the input file, units is meters.
The format is (data must be real-valued):
\small
\begin{verbatim}
reads to End_Of_File:
do i=1,10000
    read(2,*) rng,  (press(i,j),j=1,ncurv)
enddo
\end{verbatim}
\normalsize
where {\tt [1...ncurv]}  consists of an
outer loop  over frequency and an inner loop over depth.

%*****************
\subsection{Vertical array data (option e)}
\label{se:opt_e}
The   vertical array file stores  
the pressure on a vertical array for several  frequencies 
(using subroutine {\tt read\-HP}).
The format of the file is similar to the 
covariance matrix format except for the inner do-loop.
 The program gives a 
warning if the first line does not contain the string ``Hydrophone vectors''.
The format is:

\small
\begin{verbatim} 
loop over range         ! as appearing in input file
   loop over freq                    ! in increasing order
      read(2,*)dummy-title
      read(2,*)dummy-freq 
      read(2,*)dummy-ndep
      do idep=1,ndep
         READ(2,*)receiver_depth                  !rd
      enddo
      do idep=1,ndep
         READ(2,*)idum,pres(idep,ibart) ! complex-valued pressure
      enddo
   enddo
enddo
\end{verbatim}
\normalsize
 
In this file, the pressure vector for several frequencies can be stored,
not all vectors need to be read in.  The program only
stores  the ones corresponding to the frequencies to be used in the
inversion.

There is no check when reading the ranges. 

If the first or last receiver depth does not correspond to the
depth in the input file, a warning is issued.
\subsection{Horizontal array data (option T)}
\label{se:opt_T}
The   vertical array file stores  
the pressure on a vertical array for several  frequencies 
(using subroutine {\tt read\-HA}).
The format of the file is similar to the 
covariance matrix format except for the inner do-loop.
% The program gives a 
% warning if the first line does not contain the string ``Hydrophone vectors''.
The format is:

\small
\begin{verbatim} 
loop over depth         ! as appearing in input file
   loop over freq                    ! in increasing order
      read(2,*)dummy-title
      read(2,*)dummy-freq 
      read(2,*)dummy-ndep
      do iran=1,nrange
         READ(2,*)receiver_depth                  !rd
      enddo
      do iran=1,nrange
         READ(2,*)idum,pres(iran,ibart) ! complex-valued pressure
      enddo
   enddo
enddo
\end{verbatim}
\normalsize
 
In this file, the pressure vector for several frequencies can be stored,
not all vectors need to be read in.  The program only
stores  the ones corresponding to the frequencies to be used in the
inversion.

There is no check when reading the ranges. 

If the first or last receiver depth does not correspond to the
depth in the input file a warning is issued.

%If more receiver depths are specified in the *.in file, then those
%specified in the input file (*.dat) will be used. Clearly it is required
%that all the depths requested in the *.dat file are available in the
%*.in file.

\subsection{Weighting file (option M)}
\label{se:opt_M}

The filename is *.wei.
The purpose of this is to weight the data according to {\it a priori}
knowledge by a user-specified function, instead of those supplied by the
program ($1/\sqrt{r}$, $\sqrt{r}$, $-20 \log{p}$).
The use of a simple function is recommended.
The format is similar to  \underline{option {\bf e}}

\small
\begin{verbatim} 
loop over range         ! as appearing in input file
   loop over freq                    ! in increasing order
      read(2,*)dummy-title
      read(2,*)dummy-freq 
      read(2,*)dummy-ndep
      do idep=1,ndep
         READ(2,*)receiver_depth                  !rd
      enddo
      do idep=1,ndep
         READ(2,*)idum,weight(idep,ibart) ! complex-valued weight
      enddo
   enddo
enddo
\end{verbatim}
\normalsize


%**************************************************
\section{The  objective function}
\label{se:obj}
The family of objective functions used here are mostly based
on Gaussian errors. They are discussed in detail in
Ref \cite{mecklennbrauker2000}.

It is  important to use the correct Fourier transform pair when
transforming observed data from time to  frequency domain. If the
wrong sign convention is used the inversion will be meaningless. We
are using the  following transform pair:
\begin{eqnarray}
p(\omega )=
\frac{1}{2 \pi}\int_{-\infty}^{\infty} P(t){\rm e}^{-i\omega t} \, {\rm d}t \; ,\\
P(t)=
\int_{-\infty}^{\infty} p(\omega ) {\rm e}^{i \omega t} \, {\rm d} \omega \; .
\end{eqnarray}
This corresponds to {\sc MATLAB}'s $p(\omega )= \mbox{ fft} (P(t))$. 

One of the most important tasks in carrying out an inversion by means
of optimization is to define a proper objective function. Here we have
selected some of the most common. 

Let $p$ and $q$ be the observed and calculated data, respectively.
They are complex matrices and contain a number of frequencies ($N_{\rm
freq}$), depths ($N_{\rm dep}$) and ranges or wavenumbers ($N_{\rm x}$).


\subsection{Transformation of data}
Before the objective function is calculated it is possible to transform
the calculated data to another form that might be more suitable
for a particular inversion. The objective function will then be applied
directly on the transformed data.

For \underline{option {\bf G}} the magnitude of both the computed and
observed data is taken
\begin{eqnarray}
p_{ijk}= |p_{ijk} | , \;\;\;\;
q_{ijk}= |q_{ijk} | \\
\qquad \mbox{for}\qquad  
i=1,\ldots , N_{\rm freq} \; , \;\;\; j=1,\ldots ,N_{\rm dep} \; , \;\;\;
j=1,\ldots ,N_{\rm x}
\end{eqnarray}

For \underline{option {\bf l}}, only the computed 
 data are transformed to a dB scale. The observed data are assumed
to be already on a dB scale.
\begin{eqnarray}
p_{ijk}= -20 \log |p_{ijk} | ,\;\;\;\;
q_{ijk}= -20 \log |q_{ijk} |\;\;\;\; \\
\qquad \mbox{for}\qquad  
i=1,\ldots , N_{\rm freq} \; , \;\;\; j=1,\ldots ,N_{\rm dep} \; , \;\;\;
j=1,\ldots ,N_{\rm x}
\end{eqnarray}

\subsection{Direct observations}

The most general objective function is \underline{option N}.
$\widehat{p}$ and $\widehat{q}$ are the data normalized to 
unity\footnote{$^{\rm *} $ is the conjugate operator.}:
\begin{equation}
\phi= \left|1- \sum^{N _{\rm freq}}_{i=1} \sum^{N _{\rm dep}}_{j=1} \sum^{N_{ \rm x}}_{k=1}
\widehat{p}_{ijk}^{\rm *} \widehat{q}_{ijk}\right|\; .
\label{eq:obj1}
\end{equation}
This corresponds to the mean squared error.


\underline{Option {\bf f}}
is the incoherent sum of the Bartlett power for each frequency. 
Both observed and computed data  are based on 
vectors and not  the usual correlation matrix: 
\begin{equation}
 \phi_{\rm f}= \frac{1}{N_{\rm x}{N _{\rm freq}}}
  \sum^{N_{\rm x}}_{k=1} \sum^{N _{\rm freq}}_{i=1} \left[
   \sum^{N _{\rm dep}}_{j=1} |{p}_{ijk}|^2 -
{{|\sum^{N _{\rm dep}}_{j=1} {p}_{ijk}^{\rm *} {q}_{ijk}|^2}
      \over {
             \sum^{N _{\rm dep}}_{j=1} |{q}_{ijk}|^2}}\right]
  \; .
\label{eq:objf}
\end{equation}
This objective function weights each frequency component according to
the received signal. Under simplifying assumptions this is the maximum
likelihood objective function, see Appendix A.

 \underline{Option {\bf f1}}
is the incoherent sum of the Bartlett power for each frequency. But
each frequency component has the same weight in the objective
function. This works best if it is known that the source signal is
nearly flat.
Both observed and computed data  are based on 
vectors and not  the usual correlation matrix: 
\begin{equation}
 \phi_{\rm f1}= 1- \frac{1}{N_{\rm x}{N _{\rm freq}}}
  \sum^{N_{\rm x}}_{k=1} \sum^{N _{\rm freq}}_{i=1} 
{{|\sum^{N _{\rm dep}}_{j=1} {p}_{ijk}^{\rm *} {q}_{ijk}|^2}
      \over {\sum^{N _{\rm dep}}_{j=1} |{p}_{ijk}|^2
             \sum^{N _{\rm dep}}_{j=1} |{q}_{ijk}|^2}}
  \; .
\label{eq:objf1}
\end{equation}
This objective function weights each frequency component identically.

\underline{Option {\bf F}}  is a matched-filter. We sum
incoherently over depth and range, but coherently over frequency.
\begin{equation}
 \phi_{\rm F}= 1- \frac{1}{N_{\rm x}{N _{\rm freq}}}
  \sum^{Nx}_{k=1} \sum^{N _{\rm dep}}_{j=1} 
{{|\sum^{N _{\rm freq}}_{i=1} {p}_{ijk}^{\rm T}{q}_{ijk}|^2}
      \over {\sum^{N_{ \rm freq}}_{i=1} |{p}_{ijk}|^2
             \sum^{N _{\rm freq}}_{i=1} |{q}_{ijk}|^2}}
  \; .
\label{eq:objF}
\end{equation}
Classical matched filter is done in the time domain by correlating the
observed time series and the synthetic time series. The above expression in the frequency domain is similar to
classical matched filtering. 

\underline{Option {\bf j}}

Here, we assume that the magnitude $|S_l |$ of the
source signal is  known, but the phase of the source signal is unknown. 
Both observed and computed data  are based on 
vectors and not  the usual correlation matrix: 
\begin{equation}
 \phi_{\rm j}= \frac{1}{N_{\rm x}{N _{\rm freq}}}
  \sum^{N_{\rm x}}_{k=1} \sum^{N _{\rm freq}}_{i=1} \left[
            \sum^{N _{\rm dep}}_{j=1} |{p}_{ijk}|^2 
   +|S_i|^2 \sum^{N _{\rm dep}}_{j=1} |{q}_{ijk}|^2
 -2|S_i {|\sum^{N _{\rm dep}}_{j=1} {p}_{ijk}^{\rm *} {q}_{ijk}|}
      \right]
  \; .
\label{eq:objj}
\end{equation}
This objective function weights each frequency component according to
the received signal.



For  \underline{option {\bf n} and {\bf X}}, we use only  the magnitude of the
observations:
\begin{equation}
\phi_{\rm nX}=  \sum^{N _{\rm freq}}_{i=1} 
          \sum^{N_{\rm dep}}_{j=1} \sum^{N_{\rm x}}_{k=1}
             (|p_{ijk}|- A_{ij}|q_{ijk}|)^2\;.
\label{eq:obj2}
\end{equation}
For  \underline{option {\bf n}}, we correct for the offset of the curve
\begin{equation}
A^2_{{\rm n}{ij}} = \frac{\sum^{N_{\rm x}}_{k=1} |p_{ijk}|^2}
       { \sum^{N _{\rm x}}_{k=1}|q_{ijk}|^2} 
\label{eq:objn}
\end{equation}
and for \underline{ option {\bf X}} there is no offset correction,
\begin{equation}
A_{\rm X}= 1 \; .
\label{eq:objX}
\end{equation}
This should be used if the data is well calibrated, so that the
absolute levels of the transmission loss are known.

\subsection{Covariance matrix}

For  \underline{option {\bf c}}, we use the Bartlett power. 
For a vector of pressure
observations at frequency $i$, at range $k$, on a vertical array $p_{ij}$ ($j=1, N{\rm dep}$),
the covariance matrix for a given frequency and range is constructed,
${R_{jl,ik}}={ {p}_{ijk}}{ {p}_{ilk}}^{\rm T}$.  
%
For observed data, the covariance matrix is based on the ensample average
of the estimated  covariance matrix formed for each time snapshot.
Some help in the construction of this covariance matrix 
is available in the MATLAB
directory. The MATLAB routines also writes the covariance matrix out
in {\sf SAGA} format.
This matrix is read from the *.in file.
$q_{ij}$ ($j=1, N{\rm dep}$) is a vector of calculated pressure on
the vertical array.

%\begin{equation}
%\phi= 1- \frac{1}{Nfreq}
%\left( \sum^{Nfreq}_{i=1}|
%\sum^{N \rm dep}_{j=1}
%\sum^{N \rm dep}_{k=1}{ \widehat{q}_{ij}}^{\rm T}{C}_{ijk}\widehat{q}_{ik}| \right) \; .

\begin{figure}
\epsfxsize=16.cm
%\epsfysize=15.cm
\centerline{\epsfbox{figures/covplot.eps}}
%\centerline{\epsfbox[18   179   548   602]{Postscripts/covplotb.eps}}
\caption{Analysis of a received signal. This is used for selecting
 the frequencies and for quality control of the data. First the
 cross-correlation matrix is formed for several bins in a selected frequency
 interval. 
Based on the first eigenvalue of the cross-correlation matrix at each bin 
(a) the frequency with the highest power is selected [marked with a cross], 
the corresponding magnitude (b) and phase
 (c) of the this correlation matrix is plotted. 
All the eigenvalues for this
 cross-correlation matrix (d) is then plotted; the estimated noise floor (solid line) is from
 a source-free section of the time series. The SNR is seen to be about 14~dB. 
 Based on the cross-correlation matrix, magnitude (e) and phase (f) of the
 first eigenvector is plotted. 
Figure \ref{covplot}e can be used for detecting unusual gain for a hydrophone and
 Fig.\ \ref{covplot}f can be used to detect a $180^\circ$ phase shift of the signal on a receiver.}
\label{covplot}
\end{figure}

Figure \ref{covplot} illustrates the features of the cross-correlation matrix
at 400~Hz, with the receiving array at a range of about 1~km away 
from the source, for an experiment in the Strait of Singapore \cite{purnima98e}. 
At this frequency, the signal-to-noise ratio is
approximately 14~dB.  At a bin width of 1.45~Hz, most of the energy is
contained within that band, and the adjacent bins have much smaller
levels.

\
%\label{eq:bart}
%\end{equation}
 \begin{equation}
\phi_{\rm c}=
 \sum^{N _{\rm freq}}_{i=1} 
 \sum^{N _{\rm x   }}_{k=1}
 \sum^{N _{\rm dep }}_{j=1}
\left[
R_{jj,ik}-      q_{ijk}^* 
 \sum^{N _{\rm dep }}_{l=1} R_{jl,ik} q_{ilk} \right]~.
 \label{eq:bart}
\end{equation}
It can be shown that the above formula is a maximum likelihood
estimate if the noise is assumed Gaussian with known or constant
mean, see e.g.\ \cite{gerstoft:asa98}. If the noise is unknown and
frequency-dependent, then 
 \underline{option {\bf O}} provides a maximum likelihood
estimate; it is obtained by replacing the summation in the above formula with a
product, 
\begin{equation}
\phi_{\rm c}=
\prod^{N_{\rm freq}}_{i=1} 
\prod^{N_{\rm    x}}_{k=1}
\sum^ {N_{\rm dep }}_{j=1}
\left[
R_{jj,ik}-      q_{ijk}^* \sum^{N _{\rm dep}}_{l=1} R_{jl,ik} q_{ilk} \right]~.
\label{eq:bart2}
\end{equation}
This corresponds to summing the logarithmic powers (dB). From a
practical point of view, no significant difference has yet been
found between the two objective functions, Eqs.\ (\ref{eq:bart}) and 
 (\ref{eq:bart2}).

\subsection{Cramer-Rao bound}
In order to assess the performance of the different estimation
procedures to find a set of parameters $\bf m$,
the covariance matrix of the estimation errors as expressed
by the Cramer Rao lower Bound (CRLB) is used, see e.g.\ 
Ref.\ \cite{ottersten, baggeroer:asa89}.
For an unbiased estimate $\hat{\bf m}$ of a real parameter vector
${\bf m}_0$, based on observations ${\bf p}$, the Cramer-Rao lower bound
on the estimation error covariance is given by 
\begin{equation}
{\bf C}^{\rm CR}=
{\rm E} \left[ (\hat{\bf m}-{\bf m}_0)(\hat{\bf m}-{\bf m}_0)^{\rm T}  \right]
={\bf F}^{-1}
\end{equation}
where the Fisher information matrix ${\bf F}$ is given by
\[
{\bf F}= 
{\rm E}\left[ \frac{\partial^2 \mbox{log} {\cal L}( {\bf p} |{\bf m}) }
                   {\partial {\bf m} \partial {\bf m}} \right]
\]
where $\cal L$ is the likelihood function.

The  CRLB provides a performance
ceiling beyond which an optimal estimation procedure cannot exceed,
thus for an estimated set of parameters $\hat{\bf m}$, 
\begin{equation}
{\rm E}\left[ {\hat{m}_i- \bar{m}_i} \right] \ge \sigma_i \equiv \sqrt{C_{ii}^{\rm CR}}
\end{equation}
where $\bar{m}_i$ is the true parameter, and $ \sigma_i $ is the minimum 
variance for each parameter $m_i$.

This variance depends on the FIM for that parameter and the off
diagonal for the remaining parameters. Thus if additional parameters are
included in the search and they are coupled to the present parameter,
 then the variance might
change significantly. 
Thus increasing the number of  parameters can lead to a large error.

Coupling between parameters tend to make the inversion problem more
difficult; it is then preferable to design an approach and use a
parameterization such that coupling is minimized.
The coupling between the parameters can be studied by an eigenvalue
decomposition of the covariance matrix.
The eigenvector shows how a problem should be discretized so that the
parameters become uncoupled. One problem with such an approach is
that the eigenvectors change as a function of parameter values.


It assumed that source can be described as 
 a Gaussian stochastic process. For further
discussion of derivation of the bounds, see Refs.\ \cite{ottersten, baggeroer:asa89}.
For a stochastic signal the Fisher information matrix 
\begin{equation}
{\bf F}_{ij}^{\rm sto} = \sum_{\omega} \sum_{ \rm p,v,h} \mbox{tr}\left[
     {\bf R}^{-1}(\bar{\bf m}) 
                     \frac{\partial{\bf R}(\bar{\bf m})}{\partial m_i} 
     {\bf R}^{-1}(\bar{\bf m}) 
                     \frac{\partial{\bf R}(\bar{\bf m})}{\partial m_j} 
\right]~.
\label{eq:crb-sto}
\end{equation}
Thus the Fisher information matrix is based on the assumed
correlation matrix and its derivative at a given true point $\bar{\bf m}$. It is thus a local method.
For analytic comparison of different estimators this formula is often
expanded using particular assumptions about the signal. For our purpose
this is not necessary as it is in its most general form and is ready
for numerical work.
For computing the 
 derivative of the correlation matrix ${\bf R}$, the linear model 
   is assumed 
\begin{equation}
{\bf R} (\omega) = \E \left[{{\bf y}{\bf y}^\dagger}  \right] = 
\E \left[ {S^2} \right]{\bf q} {\bf q}^\dagger + {\bf C}_{\rm n}(\omega)~,
\label{eq:cor}
\end{equation}
where ${\bf C}_{\rm n}(\omega)$ is the noise covariance matrix, which
is assumed independent of the model parameters $\bf m$.
The derivative is then obtained,
\begin{eqnarray}
\frac{\partial{\bf R}}{\partial {m}_i} &=& \E\left[ {S^2} \right]   
\left[         
\frac{\partial{\bf q}}{\partial {m}_i} {\bf q}^\dagger({\bf m})
+{\bf q}({\bf m}) \frac{\partial{\bf q}^\dagger}{\partial { m}_i}\right]
\end{eqnarray}
In the computations, it is assumed that $\E\left[ {S^2} \right]=1$. The
derivatives of the field are computed using analytic gradients
\cite{gerstoft:asa95}  



%***************************************************************
\section{Shape functions}
\label{se:eof}

\begin{table}
\begin{center}
\small
\begin{tabular}{|l|l|}
\hline \hline
Input parameter & Description \\
\hline \hline
\multicolumn{2}{|l|}{{\bf Block I: DIMENSIONS}~~~~~~(1 line)}  \\ \hline
 Neof  Neofvar Nblock & Neof: Number of shape functions \\
                      & Neofvar: Number of points to specify shape function\\
 & Nblock: Number of blocks to specify shape functions \\ \hline
\multicolumn{2}{|l|}{{\bf Block II: PARAMETERS } ({\tt Neofvar} lines) }\\ \hline
 parm index	      & Repeated Neofvar times.\\
                &  parm: Pointer to physical parameter. For key see
Sect.\ \ref{se:forw}. \\
.     &index: Addresses a specific variable in a vector\\ 
.     &\quad (for {\sf SNAPRD}, {\sf PROSIM},  {\sf CPROSIM},  {\sf
  RAMGEO} and \\ 
. & \quad{\sf TPEM},     {\tt index} refers to 2 variables, {\tt index} and {\tt index2})\\
\hline
\multicolumn{2}{|l|}{{\bf Block III--Nblock+IV: SHAPE FUNCTIONS}~~~ } \\ \hline
 NeofBlock NeofvarBlock & \\
 a1 a2 ... aNeofBlock   & The coefficients -- repeated NeofvarBlock times\\
 ... & \\
\hline
\multicolumn{2}{|l|}{{\bf Block Nblock+V: starting amplitudes}~~~(1 line)}  \\ \hline
$\mu_1$    $\mu_2$ $\mu_3$ .... &  $\mu_i$ is the starting amplitude for the
 shape function $i$ \\
\hline
\end{tabular}
\end{center}
\caption{Shape function  file structure.
 \label{tab:EOF} }
\end{table} 

Here regularization is introduced via shape functions. These can be 
seen as a coordinate transformation $h_{ij}$ between the input
parameters $m_i$ required for the forward modeling
program, and a more efficient set of parameters $\mu_j$:
\begin{equation}
 {m_i}= \sum_j^{M_{\rm s}} {\bf h}_{ij} \mu_j,
\label{eq:shp}
\end{equation}
where $ { h}_{ij}$ is the $j$th shape function or basis function,
$\mu_j$ is the coefficient
associated with this shape function, and $M_{\rm s}$ is the number of shape functions
used. The advantages of shape functions are:
\begin{itemize}
\item They constrain the solution to a certain class of 
expected profiles.
\item They describe the variation of the parameters with 
fewer coefficients, and in so doing, reduce the number of unknowns. This can
also constrain the solution to be more physically correct. For example,
by linking the sound speed in the sediment together, we can
describe them by a smoother function and, furthermore, reduce the number of unknowns. 
\item They link correlated  parameters, resulting in  better search 
performance.
\end{itemize}

Regularization using shape functions may 
decrease the correlation between parameters, and this improves the inversion
results. This was done in \cite{gerstoft:jca94} where we 
inverted for the slope 
and the offset of the water sound speed, instead of
inverting for  the absolute sound speed at discrete points. 

For each of these files, a ``{\bf !}'' as the first character of a line  means
a comment--- There should be no blank lines.
The format is given in Table  \ref{tab:EOF}.
The starting values of the shape function coefficients are given because we do not
use the actual values in the forward-model-input block for the parameters
described by shape functions.



\subsubsection{Example of a shape function file}
This example is based on the  input file in Sect.\ \ref{se:ssp},
with {\sf SNAP} as the forward model. An \underline{option {\bf E}} is then included in the option line of
the input file. The example uses the same pointers as in {\sf SNAP}, see Sect.\
\ref{se:snappoint}.

Instead of the two sound speed points at the top and
bottom of the water column (pointers 2-1 and 2-2),
we will describe the water sound speed profile
using two shape functions.
The first shape function (11-1) is constant
over depth, and the second shape
function (11-2) describes the decrease in sound speed at the bottom.
Hereby we have obtained a more efficient
parameter set as the gradient is  more important than the absolute offset.
We will also reduce the number of free parameters in the bottom by
binding the lower sediment speed (3-2) to the basement speed (12-1) using
one shape function (11-3). In terms of coordinate
mapping, Eq.\ (\ref{eq:shp}), we express this as



\begin{equation}
\left[ \begin{array}{c} \mbox{2-1} \\  \mbox{2-2} \\ 
           \mbox{3-2} \\   \mbox{12-1} \end{array} \right]
=
\left[ \begin{array}{ccc} 1 & 0 & 0\\ 1 & -1 & 0\\
                                 0 & 0 & 1\\ 0 & 0 & 1\end{array} \right]
\left[ \begin{array}{c}\mbox{11-1} \\ \mbox{11-2} \\ \mbox{11-3} \end{array} \right].
\end{equation}
Because it consists of two sub-matrices, we  describe 
the mapping matrix using two blocks, {\tt Nblock}=2. The
use of sub-matrices is especially useful for large problems.

\clearpage
\small
\begin{verbatim}
!Shape function example for sspmis
3 4 2                         ! Neof Neofvar Nblock
2 1                           ! upper speed in water
2 2                           ! Lower speed in water
3 2                           ! lower sediment speed
12 1                          ! basement speed
! The first block describe the water profile
2    2                        ! the size of first sub-matrix
1    0
1   -1
! The second block describe the bottom profile
1  2                          ! the size of second sub-matrix
1
1
1500 20 1750                  ! starting amplitudes
\end{verbatim}
\normalsize

Also the optimization parameter block of the input file must be changed:
\small
\begin{verbatim}
5                             ! nparm
11 1    1497.5 1502.5  51     ! upper sound-speed point
11 2     15    25     101     ! gradient of sound speed
11 3    1600   1800    51     ! basement speed
 9 1    5000   10000   51     ! source range
 8 1    0.01    100    51     ! source depth 

\end{verbatim}
\normalsize

%********************************************************************
\section{Output files}
The *.out is the default output file.  For each execution of {\sf
POST} a summary of the estimated
parameters is also added to the files   {\bf results} and  {\bf results.m}
in the current directory. With minor modifications the {\bf results.m}
can be used with MATLAB to analyze the convergence of different
inversion approaches.

The plot files (*.plt, *.plp, *.bdr and *.cdr) use the standard SACLANTCEN
plotting programs, but as described in Sect.\ \ref{se:graph}, they are
better processed with MATLAB.

\subsection{The *.mat, *b.mat and *.ext files}

All three files  use the same format:
\small
\begin{verbatim}  
 do i=1,q
      write(10,*)i,ipop,fit(i),(model(jn,i),jn=1,nparm)
 enddo
\end{verbatim}
\normalsize
where the variable {\tt model} contains an integer representation of
the model vector for each individual {\tt i}.
In total, there are {\tt q} model vectors.
It is quite easy to read these files into MATLAB and plot the results.

{\bf *.mat}: The file is written by  {\sf SAGA}. 
Each time a new forward model has been ran,  the binary values
corresponding to each 
model vector are  written out 
to the  *.mat file.    
There will be as many models as forward modeling runs.

{\bf *.ext}: The file is written by  {\sf SAGA}.  
Each time a new forward model has been ran  it is 
written out using the physical dimensions. 

{\bf *b.mat}: The file is written by {\sf POST}. 
It contains a sorted list of  all the individuals used in
the post-processing. 


%***************************************************
\section{Sampling the fields}

This is under development! and currently works only for {\sf SNAP} and
{\sf RAMGEO}

The purpose of this module is to make dense computations of the field
(typically about 1 million fields are computed) at a set of receivers for several discrete values of the model
parameters $\bf m$. The fields can then be read into matlab for further
processing.  

\subsection{Running the program}
For an example,  see the files in {\tt examples/resampsnap}.
The steps in running this example are:
\begin{itemize}
\item Generate a list of $\bf m$-vectors (these are easily generated in
  MATLAB), and write them to the ASCII {\tt fort.81}-file (one for each
  line).
The file can also be produced by running the enumerative integration  
\underline{option {\bf S2}}  combined with  the debugging
  \underline{option {\bf Q}}. 
\item Run the resampling program 
 
\begin{tt}
resa filename forward-model
\end{tt}

This writes the transfer function out to the binary {\tt fort.34}-file.
Note that the output is typically done on a grid of receivers in both
range and depth. The frequencies and the spacing of the receivers are
mostly hard-coded in the Fortran code. 
\item Read the transfer functions into {\sc MATLAB}. This is typically done
  using a {\sc MATLAB} script as {\tt rereadtrf.m} for {\sc snap} and  {\tt
  rereadramgeo.m} for {\sc ramgeo}.
\item Once all the computed fields are read into matlab it is very easy
  to use them for your own processing.
\end{itemize}


%*************************************************************************
%\input{forward.tex}
\newpage
\section{Forward models and examples}  
\label{se:forw}
A short description of the forward models that are currently
incorporated into the {\sf SAGA } program is given. This description
requires familiarity with the particular forward code, which
is strongly coupled to the program  to ensure computational
efficiency.

As each forward model is a subroutine, it has some limitations relative
to the stand-alone version. Firstly, it reflects the forward model at the
time of porting. Secondly, the input subroutine is usually rewritten
and therefore some options available in the original model might not
be available in the {\sf SAGA} version.

\subsection{Forward model: OAST }
\label{se:oast}
The forward model for  {\sf OAST} \rm follows 
{\it nearly} the format of the {\sf SAFARI}
manual \cite{hs:saf}. 
We use the format described in the upgrade notes \cite{hs:saf2}.
But it is based mainly on {\sf OASES} Version 1.2.
The source-receiver range can be read in 
using two formats. See the input examples.

In the transmission loss module of {\sf OASES} the complex pressure is found
by using the fast field approximation and then doing a Fourier transform
from wavenumber domain to range domain.
This has the disadvantage that the pressure is only computed at
discrete intervals with a spacing of about one wavelength which causes
an inaccurate determination of the phase. Therefore in
{\sf SAGA}
 full integration similar to that in the {\sf OASES} pulse module is
used.

It is difficult to determine the correct wavenumber
sampling when using several frequencies and when the environment is
changing during the optimization. Therefore  automatic
sampling has been introduced for the transmission loss module
 based on automatic sampling for the pulse program in {\sf OASES} 2.0. 
Similarly to {\sf OASES} it is activated by specifying a 
negative number of wavenumber samples.
The minimum and maximum horizontal phase speeds ({\tt Cmin} and {\tt
Cmax}) 
that should be used in the sampling are still important. 
The  method used is  based on the supplied {\tt Cmin} and {\tt
Cmax}; it computes the minimum and maximum wavenumbers  for the
maximum frequency. For all frequencies the integrand is sampled in the
range of these two wavenumbers. The number of required samples at each
frequency can then be determined from geometric considerations.


It is possible to use more than one physical quantity in one
inversion. Thus any combination of pressure, vertical velocity and
horizontal velocity can be used. The velocities are normalized with 
$\rho_{ \rm ref} c_{ \rm ref}$  in order to have
same dimensions and magnitude as the pressure ($\rho_{ \rm ref}=
1000$ kg/m$^3$ and $c_{ \rm ref}=1500$ m/s.
Specify N  (pressure), V (vertical velocity) and/or
H (horizontal velocity) in the oases option line. SAGA always works
with the physical quantities in the above order.
At the moment, when more physical  quantities is observed the frequencies has to be
specified in multiples of number of field type.




\subsubsection{Change in input format}
\begin{itemize}
\item Frequency line: The {\sf OASES} standard is to specify: \\
{\tt Fmin Fmax Nfreq}.\\
Hereby {\tt  Nfreq} frequencies are used from {\tt Fmin} to {\tt Fmax}.
 If {\tt Nfreq} is negative then $\mid$ {\tt Nfreq} $\mid$ frequencies are
read individually in the next line:\\
{\tt Fdum Fdum -Nfreq} \\
{\tt freq(1) freq(2) ... freq(Nfreq) }
\item Receiver line: The {\sf OASES} standard is to specify: \\
{\tt RDmin RDmax Nrd}.\\
Hereby {\tt  Nrd} receiver depths are used from {\tt RDmin} to {\tt RDmax}.
 If {\tt Nrd} is negative then $\mid$ {\tt Nrd} $\mid$ receivers are 
read individually in the next line:\\
{\tt Rdum Rdum -Nrd} \\
{\tt rd(1) rd(2) ... rd(Nrd) }
\item For \underline{options {\bf d}, {\bf f} and {\bf c}} the {\it
range format} lines are:\\
{\tt no\_of\_ranges}\\
{\tt range(1), ... range(no\_of\_ranges)}\\
hence each used range must be specified. For \underline{option {\bf D}}
the format is:\\
{\tt R\_min R\_max}\\
thus only ranges between {\tt R\_min} and {\tt R\_max} are used in the
input file.
\item If the shear speed is $- $999.999 then the layer is an acoustic
 gradient layer. The top sound speed corresponds to the P sound speed
in the 
layer and the bottom sound speed to the P sound speed in the layer
below. 
\end{itemize}

\subsubsection{Additional OAST options}
\begin{itemize}
 \item[\bf i]  Incoherent averaging of transmission loss.  At range
$r$ it is found  by averaging the
transmission loss in range from $r-0.116r$ to $ r+0.116r$ as described
in Ref.\ \cite{harrison:asa95}.
 \item[\bf t] Tilt of receiver array.  It is measured
as the horizontal deviation at the last receiver measured in
meters. When this option is specified, it is the fourth parameter in
the receiver-depth line of the input file.  It works only for
a single range.  

A horizontal array can be simulated using this option. First specify
the minimum and maximum receiver depth of the array. The tilt
is relative to the full length of the array. The source-receiver distance
is the distance between the source and the first receiver. By
specifying a horizontal array in this way, the same options as for a
vertical array can be used.
\end{itemize}

\subsubsection {Pointers in OAST}
 \label{se:oastp}
The pointers {\tt parm} and {\tt index} are used to map between the optimization variable and the
environmental parameter to be optimized. The first pointer  {\tt parm}
points to the
type of parameter and the second {\tt index} identifies the actual
parameter within that parameter type.
For some parameters {\tt index} is not important (source depth).  
The pointer {\tt parm} can take the following values:
\begin{itemize}
    \item[\bf 1] Depth of layer {\tt index}. It should be between the depth of
layer \tt index-1 \rm and {\tt index+1}.
\vspace{-0.3cm}
    \item[\bf 2] P-speed of layer {\tt index}.
\vspace{-0.3cm}
    \item[\bf 3] S-speed of layer {\tt index}.
\vspace{-0.3cm}
    \item[\bf 4] P-attenuation of layer {\tt index}.
\vspace{-0.3cm}
    \item[\bf 5] S-attenuation of layer {\tt index}.
\vspace{-0.3cm}
    \item[\bf 6] Density of layer {\tt index}.
\vspace{-0.3cm}
    \item[\bf 7] Thickness  of layer {\tt index}. The thickness of one layer is changed by opening up the
corresponding layer and keeping all other thicknesses constant; i.e. the depth
below the corresponding layer will  change.
\vspace{-0.3cm}
    \item[\bf 8] Source depth.
\vspace{-0.3cm}
    \item[\bf 9] Source-receiver range.
\vspace{-0.3cm}
    \item[\bf 11] Shape function coefficient; {\tt index} points to the shape 
function number.
\end{itemize}

\subsubsection{OAST example. File: {\bf layer11}}
\label{se:layer11}
This example has been used in a published paper \cite{gerstoft:asa94}.
The options (line two in the input below) 
specify that we are using wavenumber domain  \underline{option {\bf w}}, 
reading data using format \underline{option {\bf d}}, writing out the data from the starting model to the *.obs
file \underline{option {\bf W}}, we are only matching the magnitude of
the observations  \underline{option {\bf G}},  using objective
function \underline{option {\bf N}},  plotting 
the measured data and the best inverted results \underline{option {\bf
p}}, and the baseline environment are superimposed on the {\it a
posteriori} distribution plot \underline{option {\bf A}}.
\small
\begin{verbatim}
11 layers- example used in GA-paper.
w W d G N p A                          ! Options
1000 32   1                      ! niter, q, npop
0.8 0.5 0.05                     !px, pu, pm
N J I T                          ! OASES options
100 100 1  0                     ! Fmin Fmax Nfreq
13                               ! Number of layers
0      0   0  0   0   0          ! First layer is vacuum
0   1500   0  0   0   1  
50  1600   0 0.1 0.2 1.6 
60  1600   0 0.1 0.2 1.6 
70  1600   0 0.1 0.2 1.6 
80  1600   0 0.1 0.2 1.6 
90  1600   0 0.1 0.2 1.6 
100 1800   0 0.1 0.2 2.0 
110 1800   0 0.1 0.2 2.0 
120 1800   0 0.1 0.2 2.0 
130 1800   0 0.1 0.2 2.0 
140 1800   0 0.1 0.2 2.0 
150 2200   0 0.1 0.2 2.2 
50                               ! source depth
50 50 1                          ! first, last, number of receivers
1400 3000                        ! Cmin, cmax
64 1 64                          ! wavenumbers

1                                ! The Range information is dummy
1300                             ! For wave number inversion

11                               ! nparm q
2 3  1500 2300 128            ! P-speed, lay 3           
2 4  1500 2300 128            ! P-speed, lay 4           
2 5  1500 2300 128            ! P-speed, lay 5           
2 6  1500 2300 128            ! P-speed, lay 6           
2 7  1500 2300 128            ! P-speed, lay 7           
2 8  1500 2300 128            ! P-speed, lay 8           
2 9  1500 2300 128            ! P-speed, lay 9           
2 10 1500 2300 128            ! P-speed, lay 10           
2 11 1500 2300 128            ! P-speed, lay 11           
2 12 1500 2300 128            ! P-speed, lay 12           
2 13 1500 2300 128            ! P-speed, lay 13           
\end{verbatim}
\normalsize

First the observed data should be generated. This is done by first
deleting the *.in file. Then run {\sf SAGA} using the command:

{\tt saga layer11 oast}

It will write the observed data
to the *.obs file. This file is then copied to the *.in file.
Now, run {\sf SAGA} again. The output of {\sf SAGA} is the following:

\small
\begin{verbatim}
   best of all energy  3.2385509E-02
  best-of all      deviation  
   1  1588.1          -11.8
   2  1903.1          303.1
   3  1638.5           38.5
   4  1915.7          315.7
   5  1991.3          391.3
   6  2161.4          361.4
   7  1966.1          166.1
   8  2287.4          487.4
   9  2066.9          266.9
  10  2060.6          260.6
  11  2041.7         -158.2
 \end{verbatim}
\normalsize

It is seen that in the first layer, which is the most important one,
the sound speed is estimated quite well. Here only one
population was used and this  is not  a sufficiently large sample for  statistics of the
estimates. We therefore increase the number of populations to 
50 and run {\sf SAGA} again.
When {\sf SAGA} has finished, the post-processor is executed:

{\tt post layer11 oast} 

The result of the run is then
\small
\begin{verbatim}
  best fit (best, ppd, mean)  1.6866000E-03  2.7032106E-03  3.2024365E-02

                             best-of all  most likely    mean   std-dev
  1 P sound speed (m/s)   3      1594.4     1594.4     1600.0     0.011
  2 P sound speed (m/s)   4      1607.0     1607.0     1607.0     0.019
  3 P sound speed (m/s)   5      1588.1     1581.8     1616.0     0.044
  4 P sound speed (m/s)   6      1619.6     1619.6     1652.1     0.057
  5 P sound speed (m/s)   7      1607.0     1600.7     1766.6     0.188
  6 P sound speed (m/s)   8      1814.9     1814.9     1782.2     0.144
  7 P sound speed (m/s)   9      1751.9     1751.9     1788.6     0.157
  8 P sound speed (m/s)  10      1733.0     1777.1     1764.1     0.154
  9 P sound speed (m/s)  11      1537.7     1613.3     1770.1     0.281
 10 P sound speed (m/s)  12      2048.0     1947.2     1937.9     0.195
 11 P sound speed (m/s)  13      2073.2     2098.4     1971.1     0.325
\end{verbatim}
\normalsize
The first line [best fit...]
 indicates the best value of the objective function 
 obtained using the best, most likely and mean model vector. The
value of the model vector then follows for each of the estimates. The
output is explained in Sect.\ \ref{se:cook}.

From these results it is observed that for the first four layers we have 
quite good results. The normalized standard deviation is small.
For the lower layers, the sound speeds are not so well
determined, the standard deviation
is also quite high. It is natural that the sound speeds in the lower
layers are less well determined, as they have less influence on wave
propagation in water.

Next, the results are plotted using MATLAB:

$>>$ {\tt plotsaga}\\
SAGA filename ? {\tt layer11} 

The {\it a posteriori} distributions for this case are shown in Fig.\
\ref{fig:layer11_ppd}. When the distributions cluster around a
certain value, it is an indication that a parameter is well determined.
The above plot was produced by weighting each model vector according
to its fit, as better fits are more likely to represent the true
solution, see Sect.\ \ref{se:post}.
Alternatively, we could use a uniform weighting of the sampled model
vectors, Fig.~\ \ref{fig:layer11_uni}. This can be done by entering
\underline{option {\bf u}} in the {\sf SAGA} option line. The
distributions now become  flatter and less centered around the
true values. 
%

The best obtained fit is shown in Fig.~\ \ref{fig:layer11_fit}.

Using the information in the {\bf layer11b.mat} file it is also
possible to construct a plot of the most likely model vector. An
example of that is given in Fig.\ 7 of Ref.\ \cite{gerstoft:asa94}. It
is also possible to plot the correlation between two parameters as
presented in Fig.~\ 8 of Ref.\ \cite{gerstoft:asa94}. 

\begin{figure}
\epsfxsize=12cm
\centerline{\epsfbox{figures/layer11_ppd.art}}
\caption{The {\it a posteriori} distributions for {\bf layer11}.
The baseline environment that generated the data is shown in red. }
\label{fig:layer11_ppd}
\end{figure}

\begin{figure}
\epsfxsize=12cm
\centerline{\epsfbox{figures/layer11_uni.art}}
\caption{The uniform {\it a posteriori} distributions for {\bf layer11}.
This represent a histogram of the model vectors obtained from the inversion.
The baseline environment that generated the data is shown in red. }
\label{fig:layer11_uni}
\end{figure}

\begin{figure}
\epsfxsize=12cm
\centerline{\epsfbox{figures/layer11_fit.eps}}
\caption{The fit in wavenumber space  for {\bf layer11}. The green line is the observed data, and the
blue line is the computed data with  the best set of parameters.} 
\label{fig:layer11_fit}
\end{figure}

\subsubsection{OAST example. File: {\bf tellaro\_oast}}
\label{se:tellaro-oast}
This example shows an inversion for observed transmission loss data. 
The measured data was taken at the Tellaro site, in the Gulf of La
Spezia.  The input file for
this run was used in Refs.\ \cite{gerstoft:asa95,lambert}, for further
details see these papers. 
This inversion using { {\sf OASES}} is similar to 
the example with { {\sf SNAP}} in Sect. \ref{se:tel}.
For this type of long range propagation {\sf SNAP} is preferable, both
because 
the CPU-time is less and because this code is easier to use. 
The additional information about shear and attenuation that can be 
obtained using {\sf OASES} is not important in the present
example.


\subsection{Forward model: OASR }
{\sf OASR} is the reflection coefficient module of  {\sf SAFARI}.
The forward model for \sf OASR \rm follows 
the format of the {\sf SAFARI} manual \cite{hs:saf,hs:saf2}. 

Some numerical codes model the bottom using 
the   reflection  loss as a function
of angle of incidence, whereas others use the physical
sound speed profile in the bottom. The {\sf SAGA-OASR} module can be
used to estimate a physical bottom from  a given 
reflection  loss curve.

\subsubsection{Pointers in OASR}
The pointers are the same as for {\sf OAST}, see Sect.\ \ref{se:oastp}, 
except that the pointers to source and receiver geometry are not used.

\subsubsection{OASR example. File: {\bf rfl}}
\label{se:rfl}
This synthetic example demonstrates the use of the {\sf OASR} module.
From the option line it is seen that
the data is read using format \underline{option {\bf d}}, 
the calculated data from the starting 
model is written to the *.obs file \underline{option {\bf W}}, using
objective function \underline{option {\bf N}}, and 
the observed and calculated data are then plotted with \underline{option {\bf p}}.

\small
\begin{verbatim}
 Refection coefficient.
d W N p                                 ! options
1000 32  2                              ! niter, q, npop
0.8 0.5 0.05                            ! px, pu, pm
       
3
0   1500    0  0   0   1  0
0   2000    0 0.1 0.2 1.6 0
30  2500    0 0.1 0.2 1.6 0
50 100 2                                ! frequencies: Fmin Fmax Nfreq
0 90 100                                ! angle

2 					! nparm 
2 2 1500 3093.75 999
2 3 1500 3093.75 999
\end{verbatim}
\normalsize

The result of the inversion is quite good, as shown by the output from
{\sf SAGA}:

\small
\begin{verbatim}
   best of all energy  7.1087794E-07
  best-of all      deviation  
   1  1999.843           -0.157
   2  2499.687           -0.313
\end{verbatim}
\normalsize

Both sound speeds in the bottom are well determined.
In this case there are so few variables that it does not seem necessary
to display the {\it a posteriori} probability distributions.


\subsection{Forward model: OASTG }
This version should only be used if gradients
 of the parameter vector are used in the
optimization \cite{gerstoft:asa95}.
 {At present it
works with only one frequency}. It is more complicated to use than the
standard {\sf OAST} module. 

This forward model is based on {\sf OAST}. The input file and the
pointers are therefore identical to the ones described in Sect.~\ref{se:oast}.
If gradients are not used it has the same functionality as {\sf OAST},
but it uses  more dynamic memory.

The program works with ``exact''  derivatives from {\sf OASES} with  acoustic layers, thus all 
optimization parameters should be in acoustic layers. The other 
layers can be of any type (e.g.\ elastic).

This program has great potential for problems that require
computation of gradients, as for example Cramer-Rao bounds. 
When gradients are computed based on a finite difference approach
there are generally large errors involved in the computation, as
opposed to the present exact approach. 

%The program works with normalized derivatives $ \frac{\partial p}{\partial
%\theta} \theta $.

\subsubsection{OASTG example. File: {\bf horiz}}
\label{se:horiz}
This illustrates the computation of the Cramer-Rao bound for a horizontal
array \cite{gerstoft:ica98}. The horizontal array is 150 m long and the source is at 10 m
depth and 1000 m range. The  water column is  50 m deep with a sound
speed of 1500 m/s and the sediment speed is 1600 m/s. 
Noise  with a SNR=10 db is added to the covariance matrix,
 \underline{option {\bf z}} in the SAGA option line.
 Gradients,  \underline{option {\bf g}} and covariance matrix 
\underline{option {\bf c}} are used.
The ambiguity function, Fig.\ \ref{fig:horiz}a shows that the source 
coordinates are hard to
find, the maximum of the ambiguity surface is 0 db and the dynamic
range is 1.5 dB.
Figure \ref{fig:horiz}b and \ref{fig:horiz}c show
 the resolution as estimated from the Cramer-Rao
bound, based on Eq.~(\ref{eq:crb-sto}). The resolution is the square
root of the diagonal entries in the Cramer-Rao covariance matrix.
It is seen from the figure that the horizontal source range is less
well  resolved than the depth.



\begin{figure}
\epsfxsize=12cm
\centerline{\epsfbox{figures/hori_10db2.eps}}
\caption{ The resolution when estimating the main wave guide
parameters for the {\bf horiz} case.
The pressure on a   horizontal array with 20 phones and a length of 150
m  is used.
a) ambiguity function,
b) source range resolution in [m],
c) source depth resolution in [m].
}
\label{fig:horiz}
\end{figure}


\subsection{Forward model: SNAP}

If the wave propagation is long-range, it is practical to model the
wavefield using normal modes. This is much faster than the more precise
method of wavenumber integration.

Both practice and theory have shown that good results can be obtained using a range-independent environment even in a range-dependent environment. 
Though some of the parameter will be offset if a range independent model is used in a range dependent environment \cite{gerstoft:asa96}.

The main part of the input follows the description in the {\sf SNAP} manual
\cite{snap}. The wave attenuation in 
water should be specified (in the water-depth line of the input file). 
If this attenuation is zero, the default attenuation
is used, as in the original {\sf SNAP} model.

The frequencies that are used in {\sf SNAP} 
are specified by either:

{\tt
Nfreq  Nmodes~~~~~~~~~~~~~~~     ! \\
freq(1) freq(2)... freq(Nfreq)\\
}
or \\
{\tt
-1  Nmodes\\
Dfreq Fmin Fmax\\
}

For the optimal environment a transfer function is generated. 
When computing transfer functions with the optimal environment
it is possible to change the frequency sampling (the \_last) 
for the broadband frequency input mode as follows:
{\tt
-1  Nmodes\\
Dfreq Fmin Fmax  Dfreq\_last Fmin\_last Fmax\_last\\
}
The transfer function is written in {\sf OASES} format (file *.trf) and can then be read by the  {\sf OASES} postprocessor or similar.


\subsubsection{Change in input format}
\begin{itemize}

\item Receiver line: The {\sf SNAP} standard is to specify: \\
{\tt RDmin RDmax Nrd}.\\
Hereby {\tt  Nrd} receiver depths are used from {\tt RDmin} to {\tt RDmax}.
 If {\tt Nrd} is negative then $\mid$ {\tt Nrd} $\mid$ receivers are 
read individually in the next line:\\
{\tt Rdum Rdum -Nrd} \\
{\tt rd(1) rd(2) ... rd(Nrd) }
\item For \underline{options {\bf d}, {\bf f} and {\bf c}}, the {\it
range format} lines are:\\
{\tt no\_of\_ranges}\\
{\tt range(1), ... range(no\_of\_ranges)}\\
hence, each used range must be specified.\\
If {\tt no\_of\_ranges} are negative then the format is \\
{\tt  no\_of\_ranges}\\
{\tt R\_min R\_max}\\
This will create {\tt no\_of\_ranges} equidistantly spaced ranges between {\tt R\_min} and {\tt R\_max}.
 
For \underline{option {\bf D}},
the format is:\\
{\tt R\_min R\_max}\\
thus only ranges between {\tt R\_min} and {\tt R\_max} are used in the
input file. 
\end{itemize}

\subsubsection{Options in SNAP}
In the input file,  an option line is introduced for {\sf SNAP}. 
Currently, there are only two options:
\begin{itemize}
 \item[\bf i]     Incoherent addition of modes.
 \item[\bf t] Tilt of receiver array (both {\sf SNAP} and {\sf SNAPRD}). 
It is measured
as the horizontal deviation at the last receiver, measured in
meters. When this option is specified, it is the fourth parameter in
the receiver-depth line of the input file.  

A horizontal array can be simulated using this option. First specify
the minimum and maximum receiver depth of the array. The tilt
is relative to the full length of the array. The source-receiver distance
is the distance between the source and the first receiver. By
specifying a horizontal array in this way, the same options as for a
vertical array can be used.
with multiple sources it is not possible to perturb the source depth.

\item {\bf m} Multiple sources.
It is assumed that all sources have unit strength. The sources are on a
vertical array.  The response of all sources in summed for each
receiver. With multiple sources it is not possible to perturb the source depth.


For option {\bf m},  the source line in the input file should
contain:

{\tt
sd sdlow  nsrd          ! upper lower and number of sources.
}

If nsrd is negative then |nsrd| individual source depths are read in the next
input line.

\item{\bf M} Multiple source. The input file should be similar to the {\bf
m} option. In addition, also the complex source spectrum should be
supplied in the *.sou file. It has the same format as the "vertical
array data" input file described in Sect.\ \ref{se:opt_e}.

\item{\bf h} Bathymetry approximation done by stretching the modes.
This option works only when all the other parameters are geometric and  
it is then possible to avoid recomputing the modes. The modes are computed for the reference environment and for subsequent changes in bathymetry the mode shapes are stretched according to the relative change in bathymetry. 
 
\item{\bf s} Scaling factor on the pressure for each frequency. This
  could be used to change the weighting for each frequency used in,
  for example, a transmission loss inversion. This is specially useful, if the source spectrum is not well known. 
For each frequency, the default scaling factor is default 0 dB. 
 \underline{Option \bf n} should then be used.
\item{\bf T} multi-static modeling. From the source the signal is transmitted to a perfect echo-repeater and from there the signal is then sent to the receivers.
The depth of the echo-repeater {\tt ed} and source-repeater range {\tt er} to the receiver must be specified in a line between the source-line and receiver-line.\\
{\tt
sd      ~~~~~~~~~~~~~~~~~~      ! source depth\\
ed er       ~~~~~~~~~~~~~~~       ! echo-repeater depth and range\\
}
 The input file {\tt multsamp} (in the examples directory) is an example of how to use this option.

\item{\bf p} Mean grain size inversion. Instead of of inverting for
sound speeds, densities and attenuation we just invert for the mean
grain size in the sediment all sound speed, densities and attenuation
are computed using the Hamilton-Bachman relations\cite{hamilton80,bachman89}

\item{\bf d} Each receiver on a VA can have its own range offset. This
  option has been used with the {\it insta array} \cite{thode05}. In
  that application, the elements were only loosely coupled together. In
  addition, there were a time drift between each element in the
  array. To first
  order this time offset can be treated as a range offset. The
  source-receiver range must be specified as normal and the additional
  offset is specified after the receiver depth line. The following
  example is from File {\bf whale.dat}:\\
 
{\tt
~~~~$\vdots$\\
td 	!snap options \\
~~~~$\vdots$ \\
  7.32  21.03 -4   0.0000~~~~~  !Classical receiver depth line \\
  0.0000   0.0000   0.0000   0.0000~~~~ ! individual offset for each phone\\
  7.32   ~~~~~~~~~~~~~~~~~~~ ! because of the ndep=-4 each receiver depth
  is specified\\
 12.80  ~~~~~~~~~~~~~~~~~~~ !each receiver depth is specified\\
 15.15 \\
 21.03 \\
1\\
2000.00 ~~~~~~~~~~~~~~~~~~~ !The common range for each receiver\\
~~~~$\vdots$
}
\item{\bf D} Each receiver on a VA can have its own time offset. This
  option has been used with the {\it insta array}
  \cite{thode05}. Theis option follows the same structure as
  \underline{option d} above. It is in principle possible to invert
  for both range and time offset at the same time (but, the parameters
  are often coupled so it should be done with care). In this case The
  range-offsets should be specified on line below receiver-depth line and then on the next line
  time-offsets.
\end{itemize}


\subsubsection{Pointers in SNAP}
\label{se:snappoint}

The pointer {\tt parm} is used to map between the optimization variable and the
environmental parameter to be optimized. The second parameter, {\tt index}, points to the
layer; for some parameters {\tt index} is not important (source depth).  
The pointer {\tt parm} can take the following values:
\begin{itemize}
    \item[\bf 1]  Water depth. The depth is changed by moving the last 
point in the water.
\vspace{-0.3cm}
    \item[\bf 2] Sound speed in water; {\tt index} refers to the actual point.
\vspace{-0.3cm}
    \item[\bf 3] Sound speed in sediment; {\tt index} refers to the actual point.
\vspace{-0.3cm}
    \item[\bf 4] Attenuation. Depending on the value of  {\tt index},
       it refers to the following attenuation: {\tt index} = 0(water),
1(sediment), 2(bottom), 3(shear bottom).
\vspace{-0.3cm}
    \item[\bf 5]  Surface roughness, {\tt index} = 1(ocean surface), 2(bottom surface).
\vspace{-0.3cm}
    \item[\bf 6] Sediment density.
\vspace{-0.3cm}
    \item[\bf 8] Source depth.
\vspace{-0.3cm}
    \item[\bf 9] Source-receiver range.
\vspace{-0.3cm}
    \item[\bf 11] Shape-function coefficient; {\tt index} points to the number.
\vspace{-0.3cm}
    \item[\bf 12] Bottom P-speed.
\vspace{-0.3cm}
    \item[\bf 13] Bottom S-speed. The shear in
{\sf SNAP} should have a low value ($<$ 500 m/s), otherwise
    the perturbation correction is not valid.
\vspace{-0.3cm}
     \item[\bf 14] Bottom density.
\vspace{-0.3cm}
    \item[\bf 15]  First receiver depth. The spacing is constant, 
    thus it is a vertical translation.
\vspace{-0.3cm}
    \item[\bf 16]  Depth of speed point  in water;
               {\tt index} refers to the actual point.
\vspace{-0.3cm}
    \item[\bf 17] Sediment thickness. The thickness is changed by moving the last 
point in the sediment. 
\vspace{-0.3cm}
    \item[\bf 18]  Depth of speed point  in sediment;
               {\tt index} refers to the actual point.
\vspace{-0.3cm}
    \item[\bf 19] Tilt. {\sf SNAP} option {\bf t} must be specified.
%\vspace{-0.3cm}
%    \item[\bf 20] reading sound speed profiles into {\sf SNAP} ( file:
%soundspeed.obs) {\tt Fmin and Fmax} defines the sound speed variables.
\vspace{-0.3cm}
    \item[\bf 21] Array shape. See the {\sc SNAP3D}, Section .~\ref{se:snap3d}.
\vspace{-0.3cm}
    \item[\bf 22] Source strength. Used For SNAP-option {\bf s}. {\it index} refers to each frequency. 
\vspace{-0.3cm}
    \item[\bf 23] Depth of echo-repeater ({\it index=1}) and source echo-repeater range ({\it index=2}). {\sf SNAP} option {\bf T} must be specified.
 \item[\bf 24] Mean grain size
 \item[\bf 25] Range to each receiver on a vertical array is
 specified. {\it index} refers to each receiver.  {\sf SNAP} option {\bf d} must be specified.
 \item[\bf 26] time offset for each receiver on a vertical array is
 specified. {\it index} refers to each receiver.  {\sf SNAP} option {\bf D} must be specified.
\end{itemize}

\begin{figure}
\epsfxsize=12cm
\centerline{\epsfbox{figures/sspmis.ps}}
\caption{The environment for the {\bf sspmisa} case.
The source coordinates are (9.3~km, 78~m), with an SNR of 40 dB.} 
\label{fig:sspmis}
\end{figure}

\subsubsection{SNAP example. File: {\bf sspmisa}}
\label{se:ssp} This example is from the 1993  Matched Field Workshop
\cite{porter:jca94}, and has been used in a published paper 
\cite{gerstoft:jca94}.
The environment is shown in Fig. \ref{fig:sspmis}.
The observed data are based on a synthetic  data set from a normal mode
code using a 250 Hz source in shallow water. The data are received on
the 20 hydrophones spanning the whole water column. 
White Gaussian noise   was added to the data vectors to obtain a
SNR = 40~dB \cite{porter:jca94}. 
Only four parameters are unknown in this case; the source range and
depth and the ocean sound speed at the top and the bottom.
 Each of the parameters can take 51 discrete values.

The options in the input data file indicate that we are using a
covariance matrix, \underline{option {\bf c}}, and that this
matrix is scaled to a maximum Bartlett power of one, \underline{option
{\bf b}}. We plot the
variation of power across the array, \underline{option {\bf p}}. 
\underline{Option {\bf t}} in the {\sf SNAP}-option
line indicates that the
array can be tilted; the fourth parameter in the receiver line defines
the initial tilt.  We use GA with 10 populations,
each with 1000 individuals; 10,000 forward models are used in total.

\small
\begin{verbatim}
 sspmis_a   from the matched field workshop 93
c b  p                        ! options
1000  32  10                  ! niter, q,  npop
0.8 0.5 0.05                  ! px, pu, pm
t                             ! snap options
1  100                        ! No of freq, max modes 
250.                          ! freq
100  0  0  0                  ! wd scat(1) scat(2) beta
  0 1499.4  
  100 1481.6 
100 1.8 0.2                   ! Sediment depth density and attenuation
  0 1600                      
  100 1750
1.8 0.2 1750                  ! bottom density, attenuation and sound speed
0   0                         ! bottom shear attenuation and sound speed

78                            ! source depth
5 100 20 0                    ! first & last receiver, # receivers, tilt

1                             ! number of ranges
9300                          ! receiver range

4                             ! nparm 
2 1    1497.5 1502.5 51       ! upper sound speed point
2 2    1477.5 1482.5 51       ! lower sound speed point
9 1    5000   10000  51       ! source range
8 1    0.01    100   51       ! source depth 
\end{verbatim}
\normalsize

After running {\sf SAGA} and {\sf POST}, we obtain the results: 


\small
\begin{verbatim}
best fit (best, ppd, mean)  3.4361999E-04  2.1212101E-03  5.5390596E-04
                                best-of all  most likely     mean   std-dev
1 Top Water sound speed (m/s)    1  1499.7      1498.6     1499.12    0.117
2 Bottom Water sound speed (m/s) 2  1481.9      1480.8     1481.33    0.116
3 Source range (m)               1  9300.0      9300.0     9300.0     0.000
4 Source depth (m)               1    78.0        78.0       78.0     0.000
\end{verbatim}
\normalsize
The first line [best fit...]
 indicates the  value of the objective function that
is obtained using the best, most likely and mean model vector. The
value of the model vector then follows for each of the estimates. The
output is explained in Sect.\ \ref{se:cook}.

It is seen that the source coordinates are perfectly determined. The
sound speeds are also quite well determined, but the normalized
standard deviation is much larger. The same can be concluded from 
plotting the 1-D marginal {\it a posteriori} distributions (Fig.\ 
\ref{fig:sspmisa_ppd}). By examining the 2-D 
marginal {\it a posteriori} distributions (Fig.\ 
\ref{fig:sspmisa_2ppd}), this can be explained.
The reason for the poor resolution of the parameters is due to a
strong correlation between the ocean sound speed at the top and at the bottom.
The  2-D marginal {\it a posteriori} distribution was produced by introducing
\underline{option {\bf m12}} 
on the option-line in the *.dat file, and then running
{\sf POST}. The contour plot has been plotted using {\sf CPLOT}, see
Sect.~\ref{se:graph}.

The correlation of the two sound speeds can also be seen by fixing the
source coordinates and then plotting a contour of the variation in
the objective function for the two sound speeds, see Fig.\
\ref{fig:sspmisa_amb}. The ambiguity plot has been produced by putting
\underline{option {\bf C}} in the option-line in the *.dat file;
the number of discrete points for the two parameters has been changed
to 40.  It is then necessary to re-run {\sf SAGA}, as this is seen as a 2-D
exhaustive search. The contour plot has been plotted using {\sf CPLOT}, see
Sect.~\ref{se:graph}.

\begin{figure}
\epsfxsize=12cm
\centerline{\epsfbox{figures/sspmisa_ppd.art}}
\caption{The 1-D {\it a posteriori} distributions for the {\bf sspmisa} case.
The red line indicates the true value.}
\label{fig:sspmisa_ppd}
\end{figure}
\begin{figure}
\epsfxsize=12cm
\centerline{\epsfbox{figures/sspmisa_2ppd.art}}
\caption{The 2-D marginal {\it a posteriori}  distribution between the
upper and lower ocean sound speed for the {\bf sspmisa} case.
It is based on the same data as Fig.\ \protect\ref{fig:sspmisa_ppd}.
The marginal 1-D distribution for each parameter is displayed 
on  the top and to the right.
By re-parameterizing the sound speed as  slope and mean, a better
resolution is obtained.}
\label{fig:sspmisa_2ppd}
\end{figure}
\begin{figure}
\epsfxsize=12cm
\centerline{\epsfbox{figures/sspmisa_amb.eps}}
\caption{Ambiguity surface for the {\bf sspmisa} case.}
\label{fig:sspmisa_amb}
\end{figure}

\subsubsection{SNAP example. File: {\bf tellaro\_snap}}
\label{se:tel}
This example shows an inversion for transmission loss data 
as described in Refs. \cite{gerstoft:asa95,lambert}. 
The input has been simplified relative to the examples in
\cite{gerstoft:asa95,lambert}. 
The options in the input file show that we are reading data using the range format,
\underline{option {\bf D}}. We are using 
only the magnitude of the pressure, and the data is weighted with
$1/\sqrt{r}$ to put more importance on the shorter ranges, 
\underline{option {\bf R}}.
The objective function is based on least squares, \underline{option {\bf n}}.
We are plotting  the observed  data, and  the synthetic data which best
matches the observed data,   \underline{option {\bf p}}.
 
\small
\begin{verbatim}
tellaro-data
D n R p                ! options 
3000 64 15              ! niter, q, npop
0.8 0.5 0.05            ! px, pu, pm
                        ! option
1                       ! No of freq
330.                    ! the freq
15.0 0.  0. 1e-8        ! water-depth, roughness surf & bottom, small att.
  0   1523           
 15   1523  
24.0   1.7 0.25         ! sediment-depth, density, cp-attenuation 
  0.  2000.             ! sediment sound speed
  3.  2000.             ! sediment sound speed
  9.  2000.             ! sediment sound speed
 24.  2000.             ! sediment sound speed
1.7 .25 2000
0. 0.                   ! No shear

7                       ! source depth
5. 5. 1                 ! NRD  RD(1:NRD)
270 1400                ! for option D: Rmin, Rmax 

6                       ! nparm         
3 1 1480  1580 128      ! sediment speed 1
3 2 1480  1580 128      ! sediment speed 2
3 3 1480  1580 128      ! sediment speed 3
3 1 1480  1580 128      ! sediment speed 4
8 1 6.0   8.0  128      ! source depth
4 1 0.    0.5  128      ! attenuation in sediment
 \end{verbatim}
\normalsize

\subsubsection{SNAP example. File: {\bf ys3}}
\label{se:ys3}
This example was used in the analysis of the Yellow Shark experimental
data \cite{hermand:ieee96}. The source signal was transmitting 7
frequencies simultaneously in the band from 200--800 Hz. First the
covariance matrix was estimated by averaging over several time
snapshots using a multiple window technique 
\cite{thompson:icassp94,meckl:icassp95}, as implemented in
the MATLAB files. 
In the example the data at all frequencies are used simultaneously,
but single frequencies could also be used. 
For results and discussion, see Ref.~\cite{hermand:ieee96}.

%\subsubsection{SNAP example. File: elba}

%The example is from the inversion of the North Elba data
%\cite{gerstoft:asa96}. This range independent example should be
%compared with the range dependent example described in
% detail in Sect.\ \ref{se:elbard}.


\subsection{Forward model: SNAPRD }
 \label{se:snaprd}
The range-dependent version of {\sf SNAP} allows for a more realistic
description of the ocean environment. However, the inversion
problem becomes more complicated. Both the CPU-time
 and the number of parameters required to describe the problem 
increase linearly with the number of range sectors. 

The main part of the input follows the description in the {\sf SNAP} manual
\cite{snap}. The wave attenuation in 
water should be specified (in the water-depth line of the input file). 
If this attenuation is zero, the default attenuation
is used, as in the original {\sf SNAP} model.

\subsubsection{Options in SNAPRD}
For {\sf SNAPRD} the receiver depths and ranges should be sampled equidistantly.
In the input file  an option line is introduced for {\sf SNAPRD}. 
Currently, there is only one option:
\begin{itemize}
 \item[\bf i]     Incoherent addition of modes.
 \item[\bf t]     Tilt measured as the horizontal
deviation at the last receiver measured in meters. 
When this option is specified, it is the fourth parameter in
the receiver-depth line of the input file. 
It works only for one range.

A horizontal array can be simulated using this option. First specify
the minimum and maximum receiver depth of the array. The tilt
is relative to the full length of the array. The source-receiver distance
is the distance between the source and the first receiver. By
specifying a horizontal array in this way, the same options as for a
vertical array can be used.
\end{itemize}

\subsubsection{Pointers in SNAPRD}
Due to the increased dimensionality of the problem, we need 3 pointers to specify
which parameter we are inverting. The two first pointers {\tt parm} and
{\tt index} are the same as in
{\sf SNAP}, while the third pointer {\tt index2} indicates the range sector.

\subsubsection{SNAPRD example. File: {\bf elbard}}
\label{se:elbard}
This example is based on the data described in 
\cite{gingras:asa95,gerstoft:asa96}. Here we
invert using a  range-dependent environment. The sound speed profile in the water
is determined from an XBT at both the source and the receiver range. We use shape
functions \underline{option {\bf E}} to produce a single range independent
bottom and to describe the bottom sound speed more efficiently.
The sound speed profile is modeled using the sound speed at the bottom
interface and subsequent sound speed points are modeled using the
increase in sound speed from the previous point.

We are using observations at
3 frequencies, and adding them incoherently. The data is in
covariance format, \underline{option {\bf c}}, and the
covariance matrix was estimated by averaging over several time
snapshots, using a multiple window technique \cite{thompson:icassp94,meckl:icassp95} as implemented in
the MATLAB files. 
We are plotting the
variation of power across the array for each frequency,
 \underline{option {\bf p}}. The input file is:


\footnotesize
\begin{verbatim}
 North elba
 E c p                   ! options 
  2000  32  10           ! niter, q, npop
  0.8 0.5 0.05           ! px, pu, pm
                         ! snap options
 3 100                   ! No of freq,  max_no_modes
164.795 169.92   175.048                     
2                        ! Number of sectors
6                        ! Sector length in km
 129.9,0.,0.,0           ! water depth scatt(1),scatt(2),beta(0)
    0.     1525.5
   56.8    1526.4
   65.1    1523.1
   68.9    1520.6
   71.3    1517.2
   75.6    1512.1
   76.8    1510.9
   79.9    1510.1
  100.4    1508.4
  129.9    1508.3
 10 1.75 0.13            ! sediment thickness, r1, beta(1)
    0      1520.
    5      1580.
   10      1600
 1.8, 0.15, 1600.        ! bottom r2 beta(2),c2
 0.,0.                   ! bottom shear beta(3) c2s

6                        ! sector length  SECTOR 2
 127.1,0.,0.,0           ! water depth scatt(1),scatt(2),beta(0)
    0.0    1525.5
   56.4    1526.3
   60.1    1525.8
   66.6    1522.1
   70.6    1517.7
   77.9    1510.3
   86.1    1509.1
  101.1    1508.3
  127.1    1508.3
 10 1.75 0.13            ! sediment thickness, r1, beta(1)
    0      1520.
    5      1580.
   10      1600
 1.8, 0.15, 1600.        ! bottom r2 beta(2),c2
 0.,0.                   ! bottom shear beta(3) c2s

 80                      ! source depth
 112.7 18.7 48 1         ! rec depth
 1                       ! number of ranges
 5600                    ! receiver range

 7                       ! nparm                 
 9 1 1 5300 5900   128   ! source range         
 8 1 1   70   85   128   ! source depth           
 1 1 1  127  132   128   ! water depth
 1 1 2  127  132   128   ! water depth
11 1 1 1510 1560   128   ! sound speed sed 
11 2 1   0   100   128   ! sound speed sed
11 3 1   0   100   128   ! sound speed bot
\end{verbatim}
\normalsize

\clearpage
The shape function file is:
\small
\begin{verbatim}
! shape function file for the North Elba range dependent case
3 8  1             ! No. of shape functions, No. of points, No of blocks
3 1  1             ! sound speed sed
3 1  2             ! sound speed sed
3 2  1             ! sound speed sed
3 2  2             ! sound speed sed
3 3  1             ! sound speed sed
3 3  2             ! sound speed sed
12 1 1             ! sound speed basement
12 1 2             ! sound speed basement
! Block 1: coupling of sed 1
3 8 
1 0 0  
1 0 0  
1 1 0  
1 1 0  
1 1 1  
1 1 1  
1 1 1  
1 1 1  
1520 20 30         ! starting values
\end{verbatim}
\normalsize
For results and discussion, see  Refs.\ \cite{gingras:asa95,gerstoft:asa96}.


\subsubsection{SNAPRD  example. File: {\bf shot05}}
\label{se:shot05}
This example is based on the shot data described in 
\cite{haralabus:96,haralabus:ecua3}. Here we
invert using a  range-dependent environment. The sound speed profile in the water
is determined from an XBT at both the source and the receiver range.

The stability of the parameter
estimate depends on the time-frequency variability of the energy distribution
in the received data. 
To demonstrate this variability, the array-averaged spectrogram 
is calculated for a 256 ms time window which slides
over the time domain with a 10 ms increment (Fig.~\ref{fig:fig}).   
It can be seen that the energy content remains at the same
level for only a short period (from 250 to 450 ms) 
corresponding to the high energy segment of the signal. 
Parameter estimates based on this time
segment are expected to be very stable, and it is used here to estimate
the covariance matrix for the frequencies used.

The data is processed using two objective functions,  the default 
multi-frequency objective function, 
\underline{option {\bf c}} (unnormalized), and one where the covariance
matrix for each frequency is normalized by dividing with the sum of
the diagonal, \underline{option {\bf b}} (normalized).
A result of this inversion for the source coordinates 
using either of the objective functions 
is seen in Fig.~\ref{fig:fig9} as a function of the number of
frequencies in the inversion. The
normalized-version results have unpredictable behavior, especially
in the case of source depth, where the estimate does not converge at
all.
 The unnormalized objective function seems preferable, and is standard
for {\sf SAGA}. This plot can easily be reconstructed using the {\bf
results.m} file. For further details, see 
\cite{haralabus:96,haralabus:ecua3}.

\begin{figure}
\epsfxsize=14cm
\centerline{\epsfbox{figures/pg3.eps}}
\caption{\label{fig:fig} Array-averaged spectrogram for the {\bf
shot05} case. }
\end{figure}

\begin{figure}
\epsfxsize=12cm
\centerline{\epsfbox{figures/source.art}}
\caption{\label{fig:fig9} Parameter estimates for source range (a) and
source depth (b) for the {\bf shot05} case. Solid lines indicate the baseline
model values. Lines designated with crosses represent the estimates
of the normalized objective function.
Lines designated with circles indicate the estimates of the unnormalized
objective function.}
\end{figure} 


\subsubsection{SNAPRD example. File: {\bf tl\_malta\_rd}}
\label{se:malta}

This example relates to data taken during  
the Winter Sun experiment. We are inverting coherent transmission loss
at four depths and four frequencies, over ranges from 200 m to 17 km; the data
are given using the data format \underline{option {\bf D}}. We are
matching both the shape and the offset of the 16 curves,
\underline{option {\bf X}}. As the final result of the inversion is
presented as
transmission loss curves plotted in dB,
 we are inverting the transmission loss
measured in dB, \underline{option {\bf l}}, rather than using pressure
magnitude.
The bottom was slightly range dependent and therefore it was modeled
with adiabatic modes with a new sector each 2 or 3 km. There is not
enough information in the data to give an independent estimate of the
bottom for each sector, therefore all bottoms were coupled together to
find one representative bottom; this coupling of the parameters is
done by using shape functions, \underline{option {\bf E}}.

Results of the inversion are shown in Fig.~15.
\begin{figure}
\epsfxsize=13.5cm
\centerline{\epsfbox{figures/tl_malta_rd_fit.eps}}
\caption{Transmission loss for the {\bf tl\_malta\_rd} case. The observed data
(green line) and the modeled data (blue line) with the best found 
environment is plotted.  The plot in each column represents frequencies  299, 399, 599,
998 Hz and 
each row from the top,  hydrophone depths 121, 101, 81 and  61  m.}
\label{fig:malta_fit}
\end{figure}
%***********************************************

\subsection{Forward model: PROSIM }

{\sf PROSIM} \cite{prosim} is a broadband adiabatic normal mode program that is based on
the {\sf ORCA} program \cite{levinson:asa95,westwood:asa96}. 
In order to increase  robustness and efficiency,
the search for eigenvalues is limited to the real wavenumber axis.
Attenuation is accounted for using the same approximations as in {\sf SNAP}.
Shear and surface roughness is not yet included in the model.
{\sf PROSIM} is very fast for broadband normal mode calculations as it
interpolates eigenvalues and mode functions as  a function of frequency.
However, if an error is detected in tracing  the eigenvalues, a
classical normal mode single frequency solution is used.

The main part of the input follows the description in the {\sf SNAP} manual
\cite{snap}. The frequencies that are used in {\sf PROSIM} 
are specified by either:

{\tt
Nfreq  0~~~~~~~~~~~~~~~     ! the  ``0'' is not read\\
freq(1) freq(2)... freq(Nfreq)\\
}
or \\
{\tt
-1   $\Delta t$~~~~~~~~~~~~~~~     ! the  $\Delta t$ is only read for
option {\bf F} \\
Dfreq Fmin Fmax\\
}

For \underline{option {\bf F}}, an unknown starting time has been introduced. This
is due to the fact that we often do not know the absolute time, or that
the frequency spacing is too large to obtain the full signal arrival time.


%\begin{itemize}
% \item[\bf i]     incoherent addition of modes. (only SNAP)
%\end{itemize}
\clearpage
\subsubsection{Options in PROSIM}
In the input file an option line is introduced for {\sf PROSIM}:
\begin{itemize}
 \item[\bf p]     Positive gradient. Both sound speed and density in
sediment and subbottom must increase as a function of depth.
If, during optimization of an environment, negative gradients are found, the
forward model will not be executed.
 \item[\bf t] Tilt of the vertical receiver array. 
It is measured
as the horizontal deviation at the last receiver measured in
meters. When this option is specified, it is the fourth parameter in
the receiver-depth line of the input file.
   \item[\bf T] Two-way propagation. The transfer function from source to receiver is squared.

\end{itemize}


\subsubsection{Pointers in PROSIM}
\label{se:prosimpoint}
Due to the increased dimensionality of the problem, we need 3 pointers to specify
which parameter we are inverting for. The two first pointers {\tt parm} and
{\tt index} are nearly the same as in
{\sf SNAP}, while the third pointer {\tt index2} points to the range sector.

The pointer {\tt parm} is used to map between the optimization variable and the
environmental parameter to be optimized. The second parameter, {\tt index}, points to the
layer; for some parameters {\tt index} is not used (e.g.\ source depth).  
The pointer {\tt parm} can take the following values:
\begin{itemize}
    \item[\bf 1]  Water depth. The depth is changed by moving the last 
point in the water.
\vspace{-0.3cm}
    \item[\bf 2] Sound speed in water; {\tt index} refers to the actual point.
\vspace{-0.3cm}
    \item[\bf 3] Sound speed in sediment; {\tt index} refers to the actual point.
\vspace{-0.3cm}
    \item[\bf 4] Attenuation. Depending on the value of  {\tt index}
       it refers to the following attenuation: {\tt index} =
1(sediment), 2(bottom).
\vspace{-0.3cm}
%    \item[\bf 5]  Surface roughness, {\tt index}=1(water surface), 2=(bottom surface)
%\vspace{-0.3cm}
    \item[\bf 6] Sediment density.
\vspace{-0.3cm}
    \item[\bf 8] Source depth.
\vspace{-0.3cm}
    \item[\bf 9] Source-receiver range.
\vspace{-0.3cm}
    \item[\bf 11] Shape-function coefficient; {\tt index} points to the number.
\vspace{-0.3cm}
    \item[\bf 12] Bottom P-speed.
%\vspace{-0.3cm}
%    \item[\bf 13] Bottom S-speed. The shear in
%prosim should have a low value (about $<$ 500 m/s) otherwise
%    the perturbation correction is not valid.
\vspace{-0.3cm}
     \item[\bf 14] Bottom density.
\vspace{-0.3cm}
    \item[\bf 15]  First receiver depth. The spacing is constant, 
    thus it is a vertical translation.
\vspace{-0.3cm}
    \item[\bf 16]  Depth of speed point  in water;
               {\tt index} refers to the actual point.
\vspace{-0.3cm}
    \item[\bf 17] Sediment thickness. The thickness is changed by moving the last 
point in the sediment. 
\vspace{-0.3cm}
  \item[\bf 18]  Depth of speed point  in sediment;
               {\tt index} refers to the actual point.
\vspace{-0.3cm}
    \item[\bf 19] Tilt. {\sf PROSIM} option {\bf t} must be specified.
\vspace{-0.3cm}
    \item[\bf 20] Time delay $\Delta T$. 
\end{itemize}

\subsubsection{PROSIM example. File: {\bf waa}}

\label{se:waa} 
This example is from the Matched Field Workshop,
Vancouver, 1997 \cite{chapman}.
The options indicate that we are using a pressure vector, 
\underline{option {\bf e}}. 
The Bartlett power is added incoherently across frequencies, 
\underline{option {\bf f}}.  
We use data from 25 to 500 Hz with a spacing of 5 Hz, a total of 96
frequencies are used. For most other normal mode codes the CPU
requirement for so many frequencies is so large that it is not
practical to carry out an inversion.
For the observed data and the replica with best estimated environment,
the variation of power across the array is plotted, \underline{option {\bf p}}.
We use GA with 20 populations,
each with 1000 individuals; 20,000 forward models are used in total.

\small
\begin{verbatim}
 waa.dat, 96 frequencies all phones.
f e p                   ! options 
 1000 32 20            ! niter, q, npop
  0.8 0.5 0.05         ! px, pu, pm
p                      ! prosim option
 -1    0               ! number of frequencies
5 25  500              ! frequencies, Df, Fmin, Fmax
1                      ! number of sectors
 1 00  00              ! dum, phase speed (00 = all), dum

100     0    0  10. 0.   !depth, dum, dum, range, dum
   0.  1480.     
  100  1460.
50     1.500 -0.23       ! sediment
   0.  1550
  50   1700 
2.00 -0.23  1800.0       ! bottom
   0  0                  ! not used

20                       ! source depth
1 99.9999 100            ! rec depth
1                        ! number of ranges
5000.                    ! receiver range

 9                       ! nparm                 
 9  1  1 5000 5400 128   ! source range         
 8  1  1   10   30 128   ! source depth           
 1  1  1  100  120 128   ! water depth
 17 1  1   10   50 128   ! sediment thickness
 3  1  1 1500 1600 128   ! sound speed sed 
 3  2  1 1550 1750 128   ! sound speed sed 
 12 1  1 1600 1800 128   ! sound speed sed
 6  1  1 1.40 1.85 128   ! density in sediment
 14 1 1 1.600 2.00 128   ! density in half space
\end{verbatim}
\normalsize

The {\it a posteriori} distributions for this case are shown in Fig.\
\ref{fig:waa_ppd}. When the distributions cluster around a
certain value, it is an indication that a parameter is well determined.
%
The best obtained fit is shown in Fig.\ \ref{fig:waa_fit}.

\begin{figure}
\epsfxsize=10cm
\centerline{\epsfbox{figures/waa_ppd.art}}
\caption{The {\it a posteriori} distributions for the {\bf waa} case. }
\label{fig:waa_ppd}
\end{figure}


\begin{figure}
\epsfxsize=13cm
\centerline{\epsfbox{figures/waa_fit.eps}}
\caption{Magnitude of the field for the {\bf waa} case at every fifth of 96
frequencies. 
The observed data (green line), and the
computed data (blue line) with  the best set of parameters at every
fifth frequency, i.e.\ from 25 Hz to 200 Hz in steps of 5~Hz. 
%We only show every
%fifth frequency because it is hard to display the match at all 96
%frequencies.
} 
\label{fig:waa_fit}
\end{figure}



\subsubsection{PROSIM example, file: {\bf mf}}
\label{se:mf}
This example is based on the {\bf waa} case from the Matched Field Workshop,
Vancouver, 1997 \cite{chapman,siderius:97}. 
The input file is nearly the same as in the previous example. 
Only one phone at a depth of 50 m and a range of 5 km 
is used, but  data from frequencies from 25--200 Hz
with a spacing of 1 Hz are used coherently. In the option line, 
\underline{option {\bf F}} is introduced in stead of \underline{option {\bf f}}.

The best obtained fit is plotted both in the frequency domain
(Fig.~\ref{fig:mf_freq}) and in the time domain (Fig.~\ref{fig:mf_time}).
The transmission loss plot is produced directly from {\sf SAGA},
whereas the time series first requires an IFFT of the data.
It should be noted that in the matched field approach used here, only
the relative phase across all frequencies is determined.  In order to
plot the comparison of the time series the  average phase difference between
the observed and computed data was
determined. The time series have been convolved with a Ricker
wavelet with a center frequency of 80 Hz. Finally, due to the coarse
frequency sampling, the absolute arrival time cannot be determined.

\begin{figure}
\epsfxsize=10cm
\centerline{\epsfbox{figures/waa_lf_freq.eps}}
\caption{The transmission loss for the {\bf mf} case. The green line is
the observed data and the blue line the modeled data with the best
environment.
The agreement is quite good.} 
\label{fig:mf_freq}
\end{figure}
\begin{figure}
\epsfxsize=10cm
\centerline{\epsfbox{figures/waa_lf_time.eps}}
\caption{The time series for the {\bf mf} case. The observed data, the modeled
data and the difference between the two time series are plotted.} 
\label{fig:mf_time}
\end{figure}

\subsection{Forward model: CPROSIM }
Similarly to {\sc PROSIM} the {\sc CPROSIM}  
is based on
the {\sf ORCA} program \cite{levinson:asa95,westwood:asa96}. 
In order to produce a correct field also at close ranges, the
non-propagating eigenvalues are found in the complex plane.

The input structure and the options are similar to {\sc PROSIM}.

\subsection{Forward model: POPP }

The normal mode program {\sf POPP} is used together with the reverberation 
model as described in Ref.\ \cite{ellis:asa95}.
The backscattering is estimated using Lambert's law  with a power coefficient.
The data should be expressed in dB and the matching is done in the dB domain.
For an example of using this module, see Ref. \cite{ellis:ecua3} and
Fig.\ \ref{fig:rev}.

\subsubsection{Pointers in POPP}
\label{se:popppoint}

The pointer {\tt parm} is used to map between the optimization variable and the
environmental parameter to be optimized. The second parameter, {\tt index}, points to the
layer; for some parameters {\tt index} is not important (e.g. source depth).  
The pointer {\tt parm} can take the following values:
\begin{itemize}
    \item[\bf 1]  Water depth. The depth is changed by moving the last 
point in the water.
\vspace{-0.3cm}
    \item[\bf 2] Sound speed in water; {\tt index} refers to the actual point.
\vspace{-0.3cm}
    \item[\bf 3] Sound speed in sediment; 
    {\tt index} refers to the actual layer.
\vspace{-0.3cm}
    \item[\bf 4] Attenuation in sediment; 
    {\tt index} refers to the actual layer. 
\vspace{-0.3cm}
    \item[\bf 5]  Thickness of each layer in sediment; 
    {\tt index} refers to the actual layer.
\vspace{-0.3cm}
    \item[\bf 6] Density in sediment;
    {\tt index} refers to the actual layer.
\vspace{-0.3cm}
    \item[\bf 8] Source depth.
\vspace{-0.3cm}
    \item[\bf 9] Source-receiver range
\vspace{-0.3cm}
    \item[\bf 11] Shape-function coefficient; {\tt index} points to the number.
\vspace{-0.3cm}
    \item[\bf 15]  Receiver depth.
\vspace{-0.3cm}
    \item[\bf 16]  Depth of speed point  in water;
               {\tt index} refers to the actual point.
\vspace{-0.3cm}
    \item[\bf 17] Lambert scattering strength.
\vspace{-0.3cm}
    \item[\bf 18]  Power in Lambert's law.  
\end{itemize}

\begin{figure}
\epsfxsize=14cm
\centerline{\epsfbox{figures/rev.eps}}
\caption{Inversion of reverberation data from several shots
({\bf File: popp\_grad3}). The green dash-dotted line shows
the estimated noise level in the data, the red area indicates the
variation of the five used shots, 
the black thin full line is the average signal level
of the shots. This is here computed as the first eigenvector of the
covariance matrix, where the covariance matrix is constructed as an
ensemble average of several shots. The thick blue 
dashed line shows the synthetic data
generated from the best estimated model.}
\label{fig:rev}
\end{figure}

\subsubsection{POPP example. File: {\bf revpopp}}
\label{se:revpopp}
This example is based on reverberation data from the North Elba site.
There is not very much information in the data, thus we are mainly 
inverting for the Lambert scattering strength and the sound speed of the
bottom half space. 
The options indicate that  we are reading observed data using
 \underline{option {\bf d}}, 
matching the absolute level, \underline{option {\bf X}}, and we are plotting the observed data and the 
best fitting model, \underline{option {\bf p}}. 
We use GA with 1 population with 1000 individuals; 1000 forward models are
used in total.
The ambient noise level is determined from the data.
\small
\begin{verbatim}
 Elba reverberation data
 d X p                     ! options

 1  64  1                  ! niter, q, npop
 0.8 0.5 0.05              ! px, pu, pm

 130.   1.0   0.           ! water depth, density, attenuation
     0.   1521.
    36.   1519.
    38.   1514.
    50.   1511.
   130.   1508.
 -1.    -1.                !  no more water points
  0.   0.                  !  shear values not implemented
 -1. 1.8  1600.  0.09      ! sed thknss, dens, speed, att (-1= last lay)
  0.   0.                  ! roughness surface, bottom
  2   398   630.           ! Nfreq, freq
  1   60.                  ! Nsd sd
  1   60.                  ! Nrd rd
 -1   -1                   ! No. of comp. layers, modes (-1 = default)
2                          ! isb (1=surf, 2=bott)
  1                        ! tau0
198.8 197                       ! source level 1...Nfreq
-30   -30                        ! lambert coefficient 1...Nfreq
76    76                          ! ambient noise level  1...Nfreq

10.03067 30  0.1706666     ! tmin, tmax, tinc

 6                         ! nparm
 8  1  50   70    128      ! source depth
 3  1  1520 1620  128      ! vel sed 1
 1  1  120. 140.  128      ! water depth
 15 1   50. 70.  128       ! recvr depth
 17 1   -50 -20  128       ! lambert DMU for first frequency
 17 2   -50 -20  128       ! lambert DMU for second frequency
\end{verbatim}
\normalsize

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%GAMA%%%%%%%%%%%%%%%
\subsection{Forward model: GAMA }
\label{se:gama}

{\sf GAMA} \cite{westwood:asa87,westwood:asa87b}   is developed by
Evan Westwood and this version of GAMA has been ported into SAGA by
Peter Nielsen.

{\sf GAMA} is a broadband propagation model that uses ray theory to
predict the acoustic field in a range-invariant, layered bottom ocean
environments. 

\subsubsection{Options in GAMA}
In the input file an option line is introduced for {\sf RAMGEO}:
There is currently no options for ramgeo.
\begin{itemize}
 \item[\bf p]     Positive gradient. Both sound speed and density in
 \item[\bf t]     Tilt of a vertical array
 \item[\bf T]     Tilt of a horizontal array
 \item[\bf h]     Envelope of impulse response
\end{itemize}


\subsubsection{Pointers in GAMA}
\label{se:gamaopoint}
Due to the increased dimensionality of the problem we need 3 pointers to specify
which parameter we are inverting for. The third pointer {\tt index2} points to the range sector.

The pointer {\tt parm} is used to map between the optimization variable and the
environmental parameter to be optimized. The second parameter, {\tt index}, points to the
layer; for some parameters {\tt index} is not used (e.g.\ source depth).  
The pointer {\tt parm} can take the following values:

\begin{itemize}
    \item[\bf 1]  Water depth. The depth is changed by moving the last 
point in the water.
\vspace{-0.3cm}
    \item[\bf 2] Sound speed in water; {\tt index} refers to the actual point.
\vspace{-0.3cm}
    \item[\bf 3] Sound speed in sediment; {\tt index} refers to the actual point.
\vspace{-0.3cm}
    \item[\bf 4] Attenuation. Depending on the value of  {\tt index}
       it refers to the following attenuation: {\tt index} =
1(sediment), 2(bottom).
\vspace{-0.3cm}
    \item[\bf 6] Sediment density.
\vspace{-0.3cm}
    \item[\bf 8] Source depth.
\vspace{-0.3cm}
    \item[\bf 9] Source-receiver range.
\vspace{-0.3cm}
    \item[\bf 11] Shape-function coefficient; {\tt index} points to the number.
\vspace{-0.3cm}
    \item[\bf 12] Bottom P-speed.
\vspace{-0.3cm}
    \item[\bf 13] Bottom S-speed. The shear in
prosim should have a low value (about $<$ 500 m/s) otherwise
    the perturbation correction is not valid.
\vspace{-0.3cm}
     \item[\bf 14] Bottom density.
\vspace{-0.3cm}
    \item[\bf 15]  First receiver depth. The spacing is constant, 
    thus it is a vertical translation.
\vspace{-0.3cm}
    \item[\bf 16]  Depth of speed point  in water;
               {\tt index} refers to the actual point.
\vspace{-0.3cm}
    \item[\bf 17] Sediment thickness. The thickness is changed by moving the last 
point in the sediment. 
\vspace{-0.3cm}
  \item[\bf 18]  Depth of speed point  in sediment;
               {\tt index} refers to the actual point.
\vspace{-0.3cm}
    \item[\bf 19] Tilt for a vertical array. {\sf GAMA} option {\bf t} must be specified.
\vspace{-0.3cm}
    \item[\bf 20] Time delay $\Delta T$. 
\vspace{-0.3cm}
    \item[\bf 21] Tilt for a horizontal array. {\sf GAMA} option {\bf T} must be specified.
\vspace{-0.3cm}
    \item[\bf 22] BLUB parameter 1.
\vspace{-0.3cm}
    \item[\bf 23] BLUB parameter 2.
\vspace{-0.3cm}
    \item[\bf 24] drtemp.
\end{itemize}

\subsubsection{GAMA example. File: {\bf map2k\_phla2000067091700}}

\label{se:map2k} 
This example is from the MAPEX2K sea trial,
The options indicate that we are using a pressure vector, 
\underline{option {\bf e}}. 
The Broadband matched filter is used as objective function
\underline{option {\bf F}}.  
We use data from 240 Hz to 760 Hz in steps of  10 Hz.
For the observed data and the replica with best estimated environment,
the variation of power across the array is plotted, \underline{option {\bf p}}.
For describing the environment we use shape functions \underline{option {\bf E}}.
We use GA with 10 populations,
each with 1000 individuals; 10,000 forward models are used in total.

\small
\begin{verbatim}
MAPEX2K data on horizontal array! comments
W F E e p
1000 32 10
0.8 0.5 0.05
T                      ! Gama options
-1 0                   ! frequencies
10.000 240.000 760.000 ! 10 Hz bandfrequencies

1 1
1 0 0
130.3000  0.0  0.0 20.0  0.0  ! bathymetry
0.0000 1508.6530
5.2000 1508.6530
69.6000 1509.9090
101.7000 1512.000
130.3000 1512.3000
4.3000 1.5000 0.4000
0.0000 1559.0000
4.3000 1559.0000
1.8000 0.4000 1637.0000
0.0000 0.0000

55.0000                           ! source depth
50.0000 50.0000 1.0000 0.0000     ! rec depths
-128.0000
300.0000 554.0000

10                          ! nparm 
11 1 1 1450 1700 128    ! upper velocity point (1st layer)
11 2 1    0  250 128    ! velocity inc (2nd layer )
11 3 1    0    1 128   ! attenuation
11 4 1 1.05  2.5 128   ! density
17 1 1  0.1   20 128   ! thickness sediment layer 
9  1 1  305  307 128   ! source range  
8  1 1   55   57 128   ! source depth     
1  1 1  129  131 128   ! water depth
15 1 1   54   57 128  ! receiver depth
21 1 1   -2    2 128  ! horizontal tilt
\end{verbatim}
\normalsize

%%%%%%%%%%%%%%%% ORCA%%%%%%%%%%%%%%%%%%
\subsection{Forward model: ORCA }

{\sf ORCA90} \cite{levinson:asa95,westwood:asa96}  is developed by
Evan Westwood and is here used in a subroutine version supplied by Dag
Tollefsen \cite{tollefsen02} based on ORCA v3.0 \cite{westwood03}. 
Note that this version can only run in range-independent
two-dimensional waveguide with a layered fluid-solid seabed, a single
multi-frequency source and a linear vertical or horizontal acoustic array \cite{tollefsen02}.
In the real axis version it is
considerably faster than {\sf PROSIM } or {\sf SNAP }.


\subsubsection{Options in ORCA}
In the input file an option line is introduced for {\sf ORCA}:
There is currently no options for ramgeo.
\begin{itemize}
 \item[\bf H]  Horizontal array
 \item[\bf V]  Vertical array
 \item[\bf t]  Tilt (straight-line) of Vertical Array
 \item[\bf C]  Using ORCA complex root finder
 \item[\bf p]   Allow only positive velocity gradients

\end{itemize}


\subsubsection{Pointers in ORCA}
\label{se:orcaopoint}
Due to the increased dimensionality of the problem we need 3 pointers to specify
which parameter we are inverting for. The third pointer {\tt index2} points to the range sector.

The pointer {\tt parm} is used to map between the optimization variable and the
environmental parameter to be optimized. The second parameter, {\tt index}, points to the
layer; for some parameters {\tt index} and {\tt index2}  is not used (e.g.\ source depth).  
The pointer {\tt parm} can take the following values:
\begin{itemize}
   \item[\bf 1]  Water depth. The depth is changed by moving the last 
point in the water.
\vspace{-0.3cm}
    \item[\bf 2] Sound speed in sediment; {\tt index} refers to the
    actual layer. {\tt index2} points to top (1) or bottom (2) of
    layer,  {\tt index2}$=0$ points to both top and bottom, i.e a
    constant sound speed layer.
\vspace{-0.3cm}
    \item[\bf 3] shear Sound speed in sediment; {\tt index} refers to the
    actual layer. {\tt index2} points to top (1) or bottom (2) of
    layer,  {\tt index2}$=0$ points to both top and bottom, i.e a
    constant sound speed layer.
\vspace{-0.3cm}
    \item[\bf 4] Attenuation in sediment; {\tt index} refers to the
    actual layer. {\tt index2} points to top (1) or bottom (2) of
    layer,  {\tt index2}$=0$ points to both top and bottom, i.e a
    constant sound speed layer.
    \item[\bf 5] Attenuation in sediment; {\tt index} refers to the
    actual layer. {\tt index2} points to top (1) or bottom (2) of
    layer,  {\tt index2}$=0$ points to both top and bottom, i.e a
    constant sound speed layer.
    \item[\bf 6] Attenuation in sediment; {\tt index} refers to the
    actual layer. {\tt index2} points to top (1) or bottom (2) of
    layer,  {\tt index2}$=0$ points to both top and bottom, i.e a
    constant sound speed layer.
    \item[\bf 7] Layer Thickness; {\tt index} refers to the
    actual layer. 
\vspace{-0.3cm}
    \item[\bf 8] Source depth.
\vspace{-0.3cm}
    \item[\bf 9] Source-receiver range
\vspace{-0.3cm}
    \item[\bf 11] Shape-function coefficient; {\tt index} points to the number.
\vspace{-0.3cm}
    \item[\bf 15]  Receiver depth.
\vspace{-0.3cm}
    \item[\bf 19] Tilt. {\sf ORCA} option {\bf t} must be specified.

\vspace{-0.3cm}
    \item[\bf 20] Ocean sound speed. {\tt index} points to the sound
    speed point.
\end{itemize}

\subsubsection{ORCA example. File: {\bf sdc}}

\label{se:sdc} 
This example is from the Matched Field Workshop,
Vancouver, 1997 \cite{chapman}.
The options indicate that we are using a covariance matrix, 
\underline{option {\bf c}} normalized with the trace
\underline{option {\bf b}}. We use data from at only 100 Hz. We are using enumerative integration to
look at the posterior distributions \underline{option {\bf S2}}.
After  2000 forward models the convergence is tested and an error
between the marginal distributions less
than 0.1 terminates the run.

\small
\begin{verbatim}
 sdc.dat test case  orca
S2 c  b   z              ! options 
2000  32  10             ! niter, q ,npop
0.8 0.5 0.05  20         ! px,pu,pm
0.00833 0.1 0.1 2        ! nu   e_stop e_rot k_grow0.033 
V                        ! orca90 options
1                        ! number of frequencies
100                      ! frequencies

 2                       ! number of SSP points
    0.0000 1480.00    
  100      1460.00
 1                       ! number of bottom layers
30.6873 1530.44,1604.15 0,0 1.5008,1.5008 -0.23,-0.23 0,0
1689.0 0.0 1.70064 -0.23 0.0

    20                   ! source depth
  5 99.9999 20           ! rec depth
 1                       ! number of ranges
 1                       ! receiver range (km)

4                        ! nparm                 
7  1  1  10   50    30   ! sediment thickness
2  1  1  1500 1600   30  ! sound speed sed  
2  1  2  1550 1750   30  ! sound speed sed 
2  2  0 1600  1800  30   ! sound speed sed
6  1  1 1.400 1.850 20   !density in sediment
14 1 1 1.600 2.000 128   !density in half space
\end{verbatim}
\normalsize
\begin{figure}
\epsfxsize=14cm
\centerline{\epsfbox{figures/sdc20dborca.eps}}
\caption{A posteriori distribution of the sediment thickness, sound
  speed (top and bottom of sediment layer and bottom layer) from the
  sdc case in \cite{chapman}. The the diagonal shows the marginal
  distribution. and the off-diagonal the 2D marginal distributions. }
\label{fig:sdc20orca}
\end{figure}



%%%%%%%%%%%%%%%%%%%%%RAMGEO%%%%%%%%%%%%%%%%%%
\subsection{Forward model: RAMGEO }
\label{se:ramgeo}

{\sf RAMGEO} \cite{colins:ram,colins:asa93}  is developed by Mike
Collins.
The ``GEO'' version  of RAM handles multiple sediment layers that 
     parallel the bathymetry. This is efficient for geoacoustic inversions.


For {\sf RAMGEO} the CPU time depends on the discretization in depth
($dz$), range ($dr$) and Pad\'{e} order ($\phi$) and well as the maximum
depth and range point. ($CPUtime \propto (\frac{1}{dz})^2 (\frac{1}{dx
\phi})^{0.8}$). In order to get a reasonable low CPU time it is important to
have good values of these parameters.

It is necessary to run convergence test to assure that the solution
has converged. With {\sf SAGA } this can
easily be done running {\sf SAGA } with just one forward model and then
by copying the obs-file to the in-file. Then change the
discretization and observe the  fitness between the two models.
This fitness-value should be below the noise floor of the data.


\subsubsection{Options in RAMGEO}
In the input file an option line is introduced for {\sf RAMGEO}:
There is currently no options for ramgeo.
%\begin{itemize}
% \item[\bf p]     Positive gradient. Both sound speed and density in
%\end{itemize}


\subsubsection{Pointers in RAMGEO}
\label{se:ramgeopoint}
Due to the increased dimensionality of the problem we need 3 pointers to specify
which parameter we are inverting for. The third pointer {\tt index2} points to the range sector.

The pointer {\tt parm} is used to map between the optimization variable and the
environmental parameter to be optimized. The second parameter, {\tt index}, points to the
layer; for some parameters {\tt index} is not used (e.g.\ source depth).  
The pointer {\tt parm} can take the following values:
\begin{itemize}
   \item[\bf 1]  ocean sound speed , {\tt index} points to depth and index2 points to range.
   \item[\bf 2]  bottom sound speed,{\tt index} points to depth and index2
   points to range.
   \item[\bf 3]  bottom density, {\tt index} points to depth and {\tt index2} points to
   range.
   \item[\bf 4]  bottom attenuation, {\tt index}  points to depth and {\tt index2}
   points to range.
   \item[\bf 5]  ocean sound speed {\it depth}, {\tt index} points to depth and index2 points to range.
   \item[\bf 6]  bottom sound speed {\it depth}, {\tt index} points to depth and index2
   points to range.
   \item[\bf 7]  bottom density {\it depth},  {\tt index} points to depth and {\tt index2} points to
   range.
   \item[\bf 10]  bottom attenuation {\it depth}, {\tt index} points to depth and {\tt index2}
   points to range.

   \item[\bf 8]   source depth ({\tt zs}).
   \item[\bf 9]   source range ({\tt rmax}).
   \item[\bf 11]  shape functions  index points to shape function.
   \item[\bf 12]  bathymetry {\tt index} points to point.
   \item[\bf 13]  bathymetry range point,  {\tt index} points to point .
point. 
\end{itemize}

\subsubsection{RAMGEO example. File: {\bf tc1v1}}
\label{se:tc1} 
This example is from the Inversion Techniques Workshop,
 2001 and described further in Ref \cite{gerstoft03ph}. % \cite{chapman}.
The options indicate that we are using a pressure vector, 
\underline{option {\bf e}}. 
The Bartlett power is added incoherently across frequencies, 
\underline{option {\bf f}}.  
We use data from only 300 Hz.
For the observed data and the replica with best estimated environment,
the variation of power across the array is plotted, \underline{option {\bf p}}.
For describing the environment we use shape functions \underline{option {\bf E}}.
We use GA with 10 populations,
each with 1000 individuals; 10,000 forward models are used in total.

\small
\begin{verbatim}
Inversion Workshop, Test Case 1 RAM Input File
E e f1 p                ! options
1000  32  10            ! niter, q ,npop
0.8 0.5 0.05            ! px,pu,pm
                        ! ram options

1                       ! #freq, 
 300                    ! freq
 20                     ! ZS
500 500.0 0
 5                      ! RMAX DR NDR
300.0  0.1  10		! ZMAX DZ NDZ
20 80                   ! rdmin,rdmax
1488.6 5 1 0.0          ! C0 NPADE NS RS

     0.0        90.0
  5000.0       150.0
-1  -1
   0.     1495.0
 160.     1488.6
-1   -1
   .00    1535.
  3.00    1541.4
  3.00    1541.4
 10.00    1556.4
 10.00    1556.4
 35.00    1610.
 35.10    1800.
-1   -1
  .000          1.550
  34.900        1.590
  35.100        1.950
-1   -1
   .0       0.123
 35.0       0.032
 35.0       0.036
100.0       0.036
150.0      10
300       100
   -1   -1
   -1   -1

13                           ! nparm 
11  1  1  1500 1600 128      ! upper velocity point (1st layer)
11  2  1  1    150  128      ! velocity inc (2nd layer )
11  3  1  1    150  128      ! velocity inc (3rd layer )
11  4  1  10   400  128      ! velocity inc (half space layer )
11  5  1  2    10   128      ! thickness first  layer 
11  6  1  2    20   128      ! thickness second layer 
11  7  1  2    30   128      ! thickness third  layer 
11  8  1  1.2  1.8  128      ! upper density
3   3  1  1.6  2.4  128      ! lower density
11  9  1  0.01 0.5  128      ! upper attenuation
11  10 1  0.01 0.2  128      ! lower attenuation
12  1  1   89  91   128      ! Bathymetry  point (r=0)
12  2  1  149  151  128      ! Bathymetry  point (r=5km)
\end{verbatim}
\normalsize
\begin{figure}
\epsfxsize=15cm
\centerline{\epsfbox{figures/tc1v1lay.eps}}
\caption{Inversion of vertical array data from the 2001 Geoacoustic
inversion workshop ({\bf File: tc1v1lay}). A contour plot for the best
matching field (top).
Comparison of observed TL and TL from the best model at 200Hz (top
middle).  
The match of the data and modeled field on the vertical array
for frequency used in the inversion. 
 (bottom left)
The obtained parameters and their normalized standard deviation
(bottom left). The obtained velocity profile (bottom middle). The
{\it a posteriori} distributions (bottom right). A contour plot for the best matching field
(top).
Comparison of observed TL and TL from the best model at 200Hz (top
middle).  }
\label{fig:tc1v1lay}
\end{figure}


\subsection{Forward model: TPEM }

The Terrain Parabolic Equation Model ({\sf TPEM}) calculates the
  electromagnetic field in height and range for electromagnetic
  propagation in the troposphere.  It allows for range-dependent
  refractivity environments and variable terrain.  {\sf TPEM} is based on
  a source code originally developed by Fred Tappert from
  the University of Miami, for propagation over a smooth surface.  It
  is a pure PE model based on the split-step Fourier method and is
  described in \cite{barrios:92,barrios:94} (Email: barrios@nosc.mil).
A good general description of electromagnetic field propagation in the
troposphere is given in \cite{agard94}.
The version used in {\sf SAGA} is based on {\sf TPEM} 1.0 originally 
developed for a PC.

For a parabolic equation method it is required that the
solution converge for smaller step sizes in range
and depth. The size of these steps depend on the particular
environment and the terrain profile. Based on a few environments we
have empirically found the following step sizes to be adequate:
About
$\lambda/3$ in depth, and in range either $10 \lambda$ for range-dependent or $200 \lambda$ for range-independent
environments. For range-dependent environments smaller steps are
required because the field generally varies more with range. 
These limits are implemented in the broadband version of
{\sf TPEM} and are significantly larger that the ones used in
\cite{barrios:94}.  

In {\sf SAGA} the range steps are
increased by a factor 5, i.e.\ to $50 \lambda$ for range-dependent
and $1000 \lambda$ for range-independent environments.  The
step size in meters are written out during execution of the code.  A
doubling in either step size causes roughly a halving in CPU time
and, therefore, a significant CPU-time saving can be obtained by
changing these default values.

The default step sizes can be changed by specifying a \underline{TPEM
option {\bf u}} as indicated below.

The maximum height is specified in the input file (either as antenna
height or maximum refractivity profile height). This
height combined with $\Delta z$ will determine the number of points
needed in the Fourier transform. Therefore, in order to reduce CPU-time
these heights should be as
small as possible. The program is also much faster if running in
a range-independent mode, which is specified
by using ``0'' terrain points. This is partly because larger range
steps can then be taken.

The magnitude of the field is best computed by using the {\sf SAGA}
\underline{option {\bf G}}. If the magnitude of the field is required in
dB, then use \underline{option {\bf l}}.

\subsubsection{Options in TPEM}
\begin{itemize}
\item[\bf u]  (itpem\_opt(1)=1)user defined step sizes for sampling of the field. 
An extra line should
then be inserted below the ``center frequency line''.

{\tt dr dz ln}

\noindent
{\tt dr dz} is specified in meters and {\tt ln} is the FFT-power for
the Fourier transform in height. The maximum height of the
computational domain is {\tt dz}$\cdot
2^{\tt ln}$.
 \item[\bf E] (itpem\_opt(2)=1) Reading shifted  EOF functions for the refractivity profile.    
The next lines should then contain

{\tt Neof}  \hspace{1in} The number of EOFs used. \\
\noindent
{\tt Base-height Coef$_1$ ... Coef$_{Neof}$} 
\item[\bf m] (itpem\_opt(3)=1) Magnitude of field

\item[\bf c]  (itpem\_opt(4)=1) Clutter return is modeled. The formula is
\begin{equation}
p_c(r, {\bf m})= -40 \log f(r, {\bf m})+ 10 \log(r)+ c({\bf m}) +\sigma (r)
\end{equation}
where $c$ is an unknown range-independent constant. $f$ is the 1-way
modeled propagation loss as modeled by 2-D PE TPEM.  $\sigma (r)$
represents the variation in
the clutter cross section. Usually we assume  $\sigma (r)$ to be
constant,but range dependent is also possible (see Sect XX). The
assumption constant  $\sigma (r)$ breaks down when there is rain or
interfering ships. These must first be removed from the clutter map.

Further, the coefficient $ c({\bf m})$ is adjusted so that the mean of
the modeled clutter $ p_c(r, {\bf m})$ is the same as the observed
clutter. The clutter points with negative $p_c(r, {\bf m})$ is truncated.

The clutter return, $\sigma (r)$ is modeled as a using a linear
variation between the value of the clutter cross section $\sigma_i$, $i=1
\cdots N_{\rm clut} $ at
control points at range $r_i$, where  $N_{\rm clut} $ is the number
of clutter points.

In the input file the following parameter must be specified before 
the line with  ``refractivity profile points'' 

{\tt              znoise}\\
{\tt number-of-clutter-points     }\\
{\tt Xclut-1  Xclut-2  Xclut-3 ...}\\
{\tt Cclut-1  Cclut-2 Cclut-3  ... }\\

 \item[\bf p]  (itpem\_opt(5)=1) A parametric profile. Instead of specifying the M-profile
 for each altitude a set of parameters is used to describe the
 profile. the input format is (replacing the M-profile section\\
{\tt base-height thickness M-offset M-deficit max-height  }\\
{\tt slope1 slope2 delta}\\
\\
For example,\\
{\tt 90 20 330 50 400 : base-height, thick, offset deficit, zmax}\\
{\tt 0.13 0.118 0 0  : slope mix, slope top, delta}\\

The lower line is described as the coefficients for the M-profile.

\item[\bf a] (itpem\_opt(6)=1)
The range dependence in base height is described by use of a set of
polynomials. These polynomials is described in the  {\tt markov.in}
file. We have determined these coefficients as eigenvalues of a Markov
process.
The coefficients to these polynomials is specified after the
refractivity profiles with the following format:\\
{\tt 3                   : polynomial for base height}\\
{\tt 100 -50 100  0 0 0 0   : factors for base height shape function.}\\

\item[\bf d] (itpem\_opt(7)=1) `` Multiple beam inversion''
\item[\bf r] (itpem\_opt(8)=1) `` Maximum M-deficit inversion''
\item[\bf e] (itpem\_opt(9)=1) `` Meteorologic constrain inversion''

\end{itemize}

\subsubsection{Pointers in TPEM}
\label{se:tpempoint}

{\sf TPEM} uses three pointers to specify a variable.
The pointer {\tt parm} is used to map between the optimization variable and the
environmental parameter to be optimized. The second parameter, {\tt index}, points to the
layer; for some parameters {\tt index} is not important (e.g. source height).  
The pointer {\tt parm} can take the following values:


  \begin{itemize}
    \item[\bf 1] 
 ({\tt rf.refmsl})    Refractivity points in M-units;
                 {\tt index} indicates at which height and {\tt index2} at which range.
\vspace{-0.3cm}
    \item[\bf 2]  ({\tt rf.hmsl})  Height corresponding to a refractivity point;
                 {\tt index} indicates at which height and {\tt index2} at which range.
\vspace{-0.3cm}
    \item[\bf 3]  ({\tt tr.terx})  Terrain x-coordinates.
\vspace{-0.3cm}
    \item[\bf 4]  ({\tt tr.tery})  Terrain y-coordinates.
\vspace{-0.3cm}
    \item[\bf 5]  Source height.
\vspace{-0.3cm}
    \item[\bf 6]  ({\tt sv.antht})   Antenna height.
\vspace{-0.3cm}
    \item[\bf 9]  Source-receiver range.
\vspace{-0.3cm}
    \item[\bf 11] Shape-function coefficient; {\tt index} points to the number.
\vspace{-0.3cm}
    \item[\bf 12] base-height {\tt par2lay} points to range.
\vspace{-0.3cm}
    \item[\bf 13]  thickness,  {\tt par2lay} points to range.
\vspace{-0.3cm}
    \item[\bf 14]  offset,     {\tt par2lay} points to range.
\vspace{-0.3cm}
    \item[\bf 15]  m-deficit,  {\tt par2lay} points to range.
\vspace{-0.3cm}
    \item[\bf 16]  noise-floor  for TPEM option \underline{option {\bf c}}.
\vspace{-0.3cm}
    \item[\bf 17] coefficient(type, range)  for TPEM option
    \underline{option {\bf p}} for describing the tri-linear profile{\tt par3} points to range.
\vspace{-0.3cm}
    \item[\bf 18] Clutter cross section ccs(range) for TPEM option \underline{option {\bf c}},  {\tt par2lay} points to range.
\vspace{-0.3cm}
    \item[\bf 19] factor({\tt par2lay}) for TPEM option \underline{option {\bf c}}.
\end{itemize}

\subsubsection{TPEM example. File: {\bf tpem\_ex} }
\label{se:tpem-ex}
This example has been used in paper \cite{gingras:ieee97}.
First  the data from the initial model is written to the *.obs file,
\underline{option {\bf W}}. This file can then be copied to the *.in file
and be used in subsequent inversions.
 The data format is the complex-valued field on a vertical array, 
\underline{option {\bf e}}.
The objective function is incoherent Bartlett, \underline{option {\bf f}}.
This type of environment is efficiently described using a tri-linear
profile, see Fig.~\ref{fig:em_env}, where the refractivity profile is
described in terms of M-deficit, base height and thickness. 
This type of profile is efficiently described using
 shape functions and read from the *.eof file, \underline{option {\bf E}}.
When running {\sf POST}, a plot of the observed 
data and the synthetic data for the best environment is produced, \underline{option {\bf E}}.
We are optimizing over the three environmental parameters: M-deficit, base height and thickness. 


\small
\begin{verbatim}
TPEM optimizing for the tri-linear profiles 
 W f e  p  E          ! options 

  2000  64  20		! niter, q, npop
  0.8 0.5 0.05		! px, pu, pm
                 
                : Tpem-options
1000.           : Frequency in MHz (100 to 20000)
1               : Field type ( 1:complex field, 0:magnitude )
50.           	: Transmitter height in meters
0             	: Ant pattern(0=Omni, Gaussian, Sin(x)/x, Csc-Sq, Ht-finder)
30            	: Beamwidth in degrees (full 3 dB to 3 dB width)
0             	: Elevation angle in degrees
100          	: Maximum receiver height in meters
90000.          : Maximum receiver range in meters
1  50         	: Number of range, height points to output
1   4           ! refractivity profile points (Range, Height)

0                	!First profile is at range zero
0.         339.         ! Refractivity
250.       368.5
300.       319.
400.       330.8

 0              	! terrain points => range-independent env.

 3 				! nparm                 
 11 2 1   1    100   128	! refraction deficit
 11 3 1   1    400   128	! base height
 11 4 1   1    100   128	! thickness
\end{verbatim}
\normalsize
\begin{figure}
\epsfxsize=10cm
\centerline{\epsfbox{figures/em_environment.eps}}
\caption{Modified vertical refractivity profile for a tri-linear profile.}
\label{fig:em_env}
\end{figure}
\begin{figure}
\epsfxsize=12cm
\centerline{\epsfbox{figures/tpem_ex_ppd.art}}
\caption{The {\it a posteriori} distributions for the {\bf tpem{\_}ex}
case. The red line indicates the true value.}
\label{fig:tpem_ppd}
\end{figure}
The shape function file contains the three basic parameters  used
to describe the atmospheric profile in Fig.\ \ref{fig:em_env}, see Ref. 
\cite{gingras:ieee97}.

\small
\begin{verbatim}
! shape function file for the TPEM 
5  7  1       ! No. of shape functions, No. of points, No. of blocks
1 1  1        ! refractivity 1 (bottom)
1 2  1        ! refractivity 2
1 3  1        ! refractivity 3
1 4  1        ! refractivity 4 (top)
2 2  1        ! height
2 3  1        ! height
2 4  1        ! height (top)
! Block 1: coupling of all parameters using the tri-linear profiles
! c(1) Deficit base thick top
5 7
   1      0     0      0    0        ! first refractivity point
   1      0   0.118    0    0        ! second
   1     -1   0.118    0    0        ! third
   1     -1     0   -0.118 .118      ! fourth
   0      0     1      0    0        ! second height
   0      0     1      1    0        ! third 
   0      0     0      0    1        ! fourth
! Now comes the starting values
  339   49.5   250    50  1000        ! starting values
\end{verbatim}
\normalsize

The {\it a posteriori} distributions for this inversion are shown in Fig.\
\ref{fig:tpem_ppd}. When the distributions cluster around a
certain value it is an indication that a parameter is well determined.
%
The best obtained fit is shown in Fig.\ \ref{fig:tpem_fit}.
Since there is no noise in the observed data  the match is quite good.
 
It is also of interest to plot the ambiguity surface between two
parameters. This will illustrate the relative importance of the two
parameters. The contour plot is produced by introducing
\underline{option {\bf C}} in the option line.
When running {\sf SAGA} it will then produce a contour plot of the
objective function between the first two specified optimization
parameters. In order to reduce the number of forward modeling
runs, it is advisable to reduce the discretization for each of the
two parameters to about 40. An example of an ambiguity surface is given in 
Fig.\ \ref{fig:tpem_con}. The ambiguity surface is shown using either
complex-valued received signal or just using the magnitude.  The
magnitude is produced by introducing  \underline{option {\bf G}}
in the option-line.



\begin{figure}
\epsfxsize=12cm
\centerline{\epsfbox{figures/tpem_ex_fit.eps}}
\caption{The fit for the {\bf tpem{\_}ex} case. The  magnitude of the observed data
(green line), and the magnitude of the synthetic 
data (blue line) with  the best set of parameters. } 
\label{fig:tpem_fit}
\end{figure}

\begin{figure}
\epsfxsize=9cm
\centerline{\epsfbox{figures/tpem_ex_con.art}}
\caption{Contour plot of the ambiguity function between base height
and M-deficit for the {\bf tpem\_ex} case. Phase (a)  or magnitude (b)
of the received signal are used in the processing.}
\label{fig:tpem_con}
\end{figure}

\section{ 3D array localization using SNAP}
\label{se:snap3d}
The purpose of this section is to describe how {\sf SAGA} can be
combined with {\sf SNAP} to provide an ability to determine  the shape
of a receiver array in 3D. This ability can be combined with
determination of environmental parameters.
Snap only works in a plane geometry. The out of plane array is then
projected into this plane. The vertical plane is defined by  the
source and the first receiver. 


\subsection{Geometry}
Two coordinate systems are used for describing the geometry, see Fig.\
\ref{covertcoord}. As is
usual, the propagation code uses a global coordinate system with the $z$-axis
pointing downwards and $z=0$ at the surface, and the range $r=0$ at the
source.
%
In order to describe the receiver array,
a local right handed coordinate system is defined with origin at the first
array element and the $x$-axis horizontal and pointing away from the source,
the  $z$-axis pointing vertically downwards.
%
A positive rotation around each axis is defined as being
clockwise when looking from  the origin along the positive axis.
   \begin{figure}
      \epsfxsize=10cm \centerline{\epsfbox{figures/covertcoord.eps}}
      \caption{The used coordinate systems. The local coordinate
system has origin in the first receiver and is a simple translation of
the global coordinate system. The y-axis is pointing out of the plane.}  
\label{covertcoord}  
\end{figure}

First, the arrays deviation from a straight line is computed 
in the $xz$-plane with the axis of the array located along the
$z$-axis and the deviation in the $x$-axis. 
Here the array is defined in terms of a parabola.
Then this shape is rotated in 3D using the Eulerian angles\cite{marrion}; 
first around the $z$-axis, then
the $y$-axis and finally the $z$-axis again.

 

\subsubsection{Parabola}

The parabola is specified in terms of the bow  $a$ at the midpoint of the array and the length of the straight
array $L_{\rm s}$.
It is specified along the $z$-axis and the deflection is given along the
$x$-axis, as follows:
\begin{equation}
x= \frac{4 a}{L_{\rm p}^2}(L_{\rm p}-z_{\rm p})z_{\rm p}
\label{eq:parab}
\end{equation}
Here $L_{\rm p}$ is the length along the z-axis and $z_p$ is the local
z-coordinate.

The arc length $L_{\rm s}$ of the
parabola is (this is also the length of the straight array)
\begin{eqnarray}
L_{\rm s} &=& \int_{z=0}^{L_{\rm p}} \sqrt{ 1+\left( \frac{\partial
 x}{\partial z}\right)^2} {\rm d} z=
 \frac{L_{\rm p}}{2}\left[\sqrt{1+b^2}+
 \frac{1}{2b}{\rm ln} \frac{\sqrt{1+b^2}+b}{\sqrt{1+b^2}-b}\right]
\nonumber \\ 
&\approx&  \frac{L_{\rm p}}{2}\left[ (1+b^2/2) +
 \frac{1}{2b}(2b-\frac{b^3}{3})\right]
\approx L_{\rm p}+\frac{8}{3}\frac{a^2}{L_{\rm p}}
\end{eqnarray}
where $b=\frac{4 |a|}{L_{\rm p}}$ .
To second order in $a$ the length of the array along the $z$-axis is given by
\begin{equation}
L_{\rm p}= L_{\rm s} ( 1-\frac{8}{3} a^2/L_{\rm s}),
\end{equation}


The original $z$-coordinates for a straight array $z_s$ is then modified
due to the bow of the parabola.
\begin{equation}
z_{\rm p}=z_{\rm s} L_{\rm p}/L_{\rm s}
\label{eqzz}
\end{equation}

For a given array, the element positions are known for the undeflected
shape, $z_s$. 
Using the approximation above, Eq.~(\ref{eqzz}), the $z$-coordinates of
the element positions for a bowed array are calculated. 
The local $x$-coordinate is then calculated from Eq.~(\ref{eq:parab}).


\subsubsection{Rotation}

For a given shape of the array, the orientation in 3D is then determined from  rotations of the
array. The array has its  axis defined as the
$z$-axis and the shape defined in terms of $(x,y,z)$ coordinates.
When using the parabola as defined above $ y=0$. 
 This is done by the three rotations as defined by the three Euler angles\cite{marrion}:\\ 
{\bf Rotation-1} the array is rotated $\theta_1$ around z-axis,\\ 
{\bf Rotation-2} the array is rotated $\theta_2$ around y-axis, and \\
{\bf Rotation-3} the array is rotated $\theta_3$ around z-axis. \\
%Second the array is tilted in xz plane
%$\theta_t$  (rotation around y-axis), and third 
%the array is rotated in azimuth $\theta_a$ (rotation around z-axis).
%
The rotations must be performed in this order. Performing the three
rotations we obtain the following expression for the rotated array 
$ (x'\; y'\; z')^{\rm T}$
\begin{equation}
\left[ \begin{array}{c} x' \\ y' \\z' \end{array}\right]
\hspace{-1mm}= \hspace{-1mm} 
\overbrace{
\left[ \begin{array}{ccc} \cos \theta_3 & \hspace{-1mm} -\sin \theta_3 &0\\
 \sin \theta_3 & \cos \theta_3 & 0\\
0 &0 & 1 \end{array}\right	]
}^{\mbox{rotation-3}}
\hspace{-1mm}
\overbrace{
\left[ \begin{array}{ccc} 
\cos \theta_2 &0 & \sin \theta_2\\
          0   &1 & 0\\
\hspace{-1mm} -\sin \theta_2& 0& \cos \theta_2 \end{array}\right	]
}^{\mbox{rotation-2}}
\hspace{-1mm}
\overbrace{
\left[ \begin{array}{ccc} \cos \theta_1 & \hspace{-1mm} -\sin \theta_1 & 0\\
 \sin \theta_1 & cos \theta_1 & 0\\
0 & 0 & 1 \end{array}\right	]
}^{\mbox{rotation-1}}
\hspace{-1mm} \left[ \begin{array}{c}	 x \\ y \\z \end{array}\right]
\end{equation}

Examples of the rotation are shown in Figs.\ \ref{hor45} and
\ref{tilted}.
In Fig.\ \ref{hor45}, the rotation $(\theta_1, \theta_2,
\theta_3 ) = (90^o, 90^o , 45^o)$ gives a horizontal array pointing
with a 45$^o$ angle to the source-receiver line.

A horizontal array is obtained by rotating $(\theta_1, \theta_2,
\theta_3 ) = (90^o, 90^o , -)$.\\
A vertical array is obtained by   rotating  $(\theta_1, \theta_2,
\theta_3 ) = (-, 0^o , -)$ or $(-, 180^o , -)$.\\
A positive bow $a$ points towards the
source when rotation3 is $0-180^o$. \\
The bow and rotation3 shows
negative symmetry.

\figcap{hor45}{A horizontal array  with a 45$^o$ angle to the
source-receiver line. The rotation are $(\theta_1, \theta_2,
\theta_3 ) = (90^o, 90^o , 45^o)$.
a) The parabola is calculated in the $xz$-plane,
b) The parabola then is rotated $\theta_1$ around the $z$-axis,
c) The parabola then is rotated $\theta_2$ around the $y$-axis,
d) The parabola then is rotated $\theta_3$ around the $z$-axis.
}
\figcap{tilted}{A tilted array. The rotation are $(\theta_1, \theta_2,
\theta_3 ) = (180^o, 45^o , 45^o)$.
a) The parabola is calculated in the $xz$-plane,
b) The parabola then is rotated $\theta_1$ around the $z$-axis,
c) The parabola then is rotated $\theta_2$ around the $y$-axis,
d) The parabola then is rotated $\theta_3$ around the $z$-axis.
}

The total horizontal range from the source to each receiver element is:
\begin{equation}
r=\sqrt{ (r_0 + x')^2 + {y'}^2  }
\end{equation}

where $r_0$ is the range from the first array element.
The global $z$ coordinate used in the propagation code is found by
adding the first receiver depth $z_r$ to the local $z$-coordinate.

\clearpage
\subsection{Visualization of the rotations}
It can be quite difficult to understand the rotations in 3D. In order to
visualize these rotations, it is useful to try the {\sc MATLAB} program 
{\tt rotation3d.m} in the {\sc MATLAB} directory. It was used to create the
Figures \ref{hor45} and \ref{tilted}.

\subsection{Additional Options in SNAP}
All of the options below define that out of plane geometry is used.
The array can be defined in 4 ways:
\begin{itemize}
\item[\bf o] Equidistant receivers; the deflection modeled as a
parabola. The array is rotated.
\item[\bf x] The  local $z$ coordinates of each receiver are read from input file; the deflection modeled as a parabola.  The array is rotated.
\item[\bf x2] The  local $z$ and $x$ coordinates of each receiver are read
from input file. The array is rotated.
\item[\bf x3]  The $(x,y,z)$ coordinates of each receiver are read
from input file (global $z$ and local $x$ and $y$); No rotation is carried out.
\end{itemize}

The array shape is specified in slightly different ways depending on
the snap-option used. For each option they are explained in Sect. \ref{se:snap3dex}.


\subsection{Additional Pointers in SNAP}
A new set of pointers are introduced in order to address the additional
pointers to the array geometry variables:

21  1 \hspace{1cm}   length of the array [only used with opt {\bf o}]\\
21  2 \hspace{1cm}   bow of the parabola for the array [not with opt
{\bf x2} or {\bf x3}]\\
21  3  \hspace{1cm}  rotation-1 (deg) [not with opt {\bf x3}]\\
21  4  \hspace{1cm}  rotation-2 (deg) [not with opt {\bf x3}]\\
21  5  \hspace{1cm}  rotation-3 (deg) [not with opt {\bf x3}]

\subsubsection{Examples of SNAP3D files}
\label{se:snap3dex}
The examples here are in the snap3d directory in the examples
directory.
They are all for a horizontal array used in the SWellEx experiment.

{\large \bf Option o}\\
This is the simplest option. 
Each receiver is uniformly distributed along the length of the array from
``first receiver depth'' (for $a=0$) , i.e., for an equivalent straight array. The deflection of the
array ($x$-coordinate) is then computed using a parabola along with
the actual $z$-coordinates. 
For this option the ``last receiver depth'' 
in the receiver depth line are dummy.

For a simplified SWellEx environment the input file has the following
format. The array is at 212.9 m depth and has 11 receivers uniformly
spread over a length of 100 m with a
bow of 15 m. The rotation angles are specified so that the array is
horizontal. The SAGA option {\bf C} defines that we are computing an
ambiguity surface and are searching over the azimuth (rotation3) angle and the bow
of the parabola.
\small
\begin{verbatim}
TEST, opt o
C  c               ! options 

 2000  64  10      ! niter, q, npop
 0.8 0.5 0.05  0   ! px,pu,pm
 o                 ! snap options
 13 500            ! freq  max_no_modes
49 64 79 94 112 130 148 166 201 235 283 338 388 100 200 388
 213.,0.,0.,0      ! water depth scatt(1),scatt(2),beta(0)
      0   1522 
     10   1519 
     20   1500 
     30   1495 
     61   1491 
    213   1488 
 30 1.76 0.2       ! sediment thickness, r1, beta(1)
 0   1572
 30  1593
 2.1, 0.06, 1880   ! bottom r2 beta(2),c2
 0,0               ! bottom shear beta(3) c2s
 60                ! source depth
 212.9 212.9 11    ! rec depth: first, last, Nrec

100  15            ! array param: length[only with o], bow[not with x2,x3]
90 90 0            ! angles: rotation-1, rotation-2, rotation-3
 1                 ! number of ranges
 2140              ! receiver range

2                  ! nparm                 
 21 5 -50 100 150  ! azimuth [deg]
 21 2 -20  20  80  ! bow of parabola [m]
\end{verbatim}
\normalsize

{\large \bf Option x}\\
For this option the local $z$-coordinates of each receiver (for $a=0$) are
specified, i.e., for an equivalent straight array. The deflection of the
array ($x$-coordinate) is then computed using a parabola along with
the actual $z$-coordinates. The array is then rotated using the three Euler angles.
For this option the array parameter [length] is
dummy, as is the ``last receiver depth'' and in
the receiver line. The $x$-coordinate in the input file is not used either.

The receiver block of the input file from {\it option o} is now
modified so that 11 receivers are spread unevenly over a 74 m array.
It has the following format for this option:
\small
\begin{verbatim}
 212.9 212.9 11  0 ! rec depth

   0  0  ! z and x, the first element must be at (0,0) 
   3  0
   7  0
  11  0
  15  0
  26  0
  32  0
  46  0
  54  0
  64  0
  74  0
100  15       ! array param: length[only with o], bow [not with x2, x3]
90 90 0             ! angles: rotation 1, rotation 2, rotation 3
\end{verbatim}
\normalsize


{\large \bf Option x2}\\
For this option, the local $x$ and $z$ coordinates of each receiver are
specified. The array is then rotated using the three Euler angles.
For this option the array parameters [length and bow ] are
dummy, as is the ``last receiver depth'' in the receiver line.

 The receiver block of the input file from {\it option o} is now
modified so that 11 receivers are spread unevenly over a 74 m array
and the $x$-coordinate is also specified.
It has the following format for this option:
\small
\begin{verbatim}
 212.9 212.9 11  0 ! rec depth

   0  0        ! z and x, the first element must be at (0,0) 
   3  3
   7  4
  11  5
  15  5
  26  6
  32  6
  46  5
  54  3
  64  2
  74  0
100  15       ! array param: length[only with o], bow [not with x2, x3]
90 90 0             ! angles: rotation 1, rotation 2, rotation 3
\end{verbatim}
\normalsize


{\large \bf Option x3}\\
All the three coordinates of each element are directly specified
(global $z$ and local $x$ and $y$).
For this option, all the array parameters [length, bow, angles] are
dummy. The receiver depths can be uniformly spaced or unevenly
spaced. Individual receiver depths are specified by
specifying a $-$ Nrec in the receiver-depth-line.

The receiver block of the input file from {\it option o} is then
modified so that first the depth of the array elements is specified
from 10 to 170 m.  The local $x$ and $y$ coordinates are then specified,
here the array is at an angle of about $45^0$ to the source-receiver
line.
It has the
following format:
\small
\begin{verbatim}
 212.9 212.9 -11  0 ! rec depth

10 20 40 60 90 100 110 130 140 150 170  ! the z depth
   0  0        ! x and y, the first element must be at (0,0) 
   3  3
   7  8
  10  11
  15  16
  26  27
  32  33
  46  46
  54  53
  64  63
  74  73

100  15       ! array param: length[only with o], bow [not with x2, x3]
90 90 0             ! angles: rotation 1, rotation 2, rotation 3
\end{verbatim}
\normalsize



\begin{thebibliography}{11}

\bibitem{snap}
F.B.~Jensen and M.C.~Ferla,
\newblock ``{S}{N}{A}{P}: The SACLANTCEN normal-mode acoustic
propagation model,''
\newblock SM-121, SACLANT Undersea Research Centre, La Spezia, Italy (1979).

\bibitem{hs:saf}
H.~Schmidt,
\newblock ``{S}{A}{F}{A}{R}{I}: Seismo-acoustic fast field algorithm for range
  independent environments. User's guide,''
\newblock SR-113, SACLANT Undersea Research Centre, La Spezia, Italy (1987).

\bibitem{hs:saf2}
H.~Schmidt,
\newblock ``{O}{A}{S}{E}{S} Version 1.6: Application and upgrade notes,''
\newblock Massachusetts Institute of Technology, Cambridge, MA (1993).

\bibitem{ellis:asa95}
 D.D.\ Ellis, ``A shallow water normal mode reverberation model,''
{ J.\ Acoust.\ Soc.\ Am.\ } {\bf 97}, 2804--2814 (1995).

\bibitem{prosim}
F.\ Bini-Verona, P.L.\ Nielsen and F.B.~Jensen, ``PROSIM broadband
normal-mode model: A user's guide,'' 
SM-358, SACLANT Undersea Research Centre, La Spezia, Italy, (1999).

\bibitem{levinson:asa95}
S.J. Levinson, E.K. Westwood, R.A.\ Koch, S.K.\ Mitchell and C.V.\
Sheppard, ``An efficient and robust method for underwater acoustic 
 normal mode computations,''
{ J.\ Acoust.\ Soc.\ Am.\ } {\bf 97}, 1576--1585 (1995).

\bibitem{westwood:asa96}
E.K. Westwood, C.T.\ Tindle and N.R.\ Chapman, ``A normal mode model for acousto-elastic ocean environments,''
{ J.\ Acoust.\ Soc.\ Am.\ } {\bf 100}, 3631--3645 (1996).

\bibitem{tollefsen02}
Dag Tollefsen, ``User interface to ASSA and FGS with ORCA90''
Norwegian Defence Research Establishment,  FFI/NOTAT-2002/04824, Kjeller, Norge 2002.
\bibitem{westwood03}
E.K. Westwood, ``ORCA Guide v3.0'', ARL Texas,2003.
\bibitem{westwood:asa87}
E.K. Westwood, and P.J.Vidmar, ``Eigenray finding and timeseries
simulation in a layered-bottom ocean ,''
{ J.\ Acoust.\ Soc.\ Am.\ } {\bf 81}, 912--924 (1987).
\bibitem{westwood:asa87b}
E.K. Westwood, and C.T.\ Tindle, ``Shallow water time series
simulation using ray theory,''
{ J.\ Acoust.\ Soc.\ Am.\ } {\bf 81}, 1752--1761 (1987).

\bibitem{colins:ram} M.D. Collins ``Users guide for RAM versions 1.0
and 1.0p'', (ftp://ram.nrl.navy.mil/pub/RAM/), (2001)
\bibitem{colins:asa93}
M.D. Collins, ``A split-step Pad\'{e} solution for parabolic equation method,''
{ J.\ Acoust.\ Soc.\ Am.\ } {\bf 93}, 1726--1742 (1993).

\bibitem{barrios:92}
 A.E.\ Barrios, ``Parabolic equation modeling in horizontally
inhomogeneous environments,'' 
IEEE Trans.\ on Ant.\ and Prop.\ {\bf 36}, 791--797 (1992).

\bibitem{barrios:94}
 A.E.\ Barrios, ``A terrain parabolic equation model for propagation in the
   troposphere,'' IEEE Trans.\ on Ant.\ and Prop.\ {\bf 42}, 90--98
(1994).

\bibitem{gerstoft:asa94}
P.~Gerstoft, ``Inversion of seismoacoustic data using genetic algorithms and
{\it a posteriori} probability distributions,''
{ J.~Acoust.~Soc.~Am.} {\bf 95}, 770--782 (1994).


\bibitem{purnima98e}
 Purnima Ratilal, P.\ Gerstoft J.T.\ Goh and Keng Pong Yeo, ``Inversion
of pressure data on a vertical array to determine the seafloor
geoacoustic properties,'' {J.\ of Computational
Acoustics} (June 1998). % {\bf }, --x (1998).

\bibitem{gerstoft:asa95}
P.~Gerstoft, ``Inversion of acoustic data using a combination of 
genetic algorithms 
and the Gauss--Newton approach,'' {J.\ Acoust.\ Soc. Am.\ } {\bf 97},
2181--2190 (1995).


\bibitem{collins:asa92}
M.D.\ Collins, W.A.\ Kuperman and H.~Schmidt,
\newblock ``Nonlinear inversion for ocean-bottom properties,''
\newblock { J.\ Acoust.\ Soc.\ Am.\ } {\bf 92}, 2770--2783 (1992).


\bibitem{ingber:89}
L. Ingber, ``Very fast simulated reannealing,'' {Mathematical Computer
Modeling} {\bf 12}, 967--973 (1989).

\bibitem{ingber:93}
L. Ingber, ``Simulated annealing: Practice versus theory,''
{Mathematical Computer Modeling} {\bf 18}, 29--57 (1993).

\bibitem{caiti:ieee94}
A.~Caiti, T.~Akal and R.D.~Stoll, ``Estimation of shear wave velocity
in shallow marine sediments,''
IEEE J.~Oceanic~Eng. {\bf 19}, 58--72  (1994).

\bibitem{pg:cop94}
 P.~Gerstoft and  A.~Caiti, ``Acoustic estimation of bottom parameters:
error bounds by local and global methods,'' in 
{\it Second European
Conference on Underwater Acoustics}, edited by L.~Bj{\o}rn{\o}
(European Commission, Luxembourg, 1994), pp. 887--892.

\bibitem{jensen}  F.B.\ Jensen, W.A.\ Kuperman, M.B.\ Porter and H.\
Schmidt, {\it Computational Ocean Acoustics}
(American Institute of Physics, New York, 1994).

\bibitem{tolstoy}  A.\ Tolstoy, {\it Matched Field Processing for Underwater
Acoustics} (World Scientific, Singapore, 1993).

\bibitem{kay} 
S.M.\ Kay, {\it Fundamentals of Statistical Signal Processing: Estimation Theory}
(Prentice Hall, Englewood Cliffs, NJ, 1993).

\bibitem{bard}  Y.\ Bard, {\it Nonlinear Parameter Estimation}
(Academic Press, San Diego, CA, 1974).

\bibitem{menke}  W.\ Menke, {\it Geophysical Data Analysis: Discrete Inverse 
Theory} (Academic Press, San Diego, CA, 1989).

\bibitem{parker} R.A.\ Parker, 
{\it Geophysical Inverse
Theory} (Princeton University Press, Princeton, NJ, 1994).

\bibitem{tarantola}
A.~Tarantola,
{\em Inverse Problem Theory: Methods for Data Fitting and Model
  Parameter Estimation} (Elsevier, Amsterdam, 1987).

\bibitem{sen95}
M.K.\ Sen and P.L.\ Stoffa, {\it Global Optimization in Geophysical
Inversion} (Elsevier, Amsterdam, 1995).

\bibitem{collins:asa91}
M.D.\ Collins and W.A.\ Kuperman,
\newblock ``Focalization: Environmental focusing and source localization,''
\newblock { J.\ Acoust.\ Soc.\ Am.\ } {\bf 90}, 1910--1922 (1991).

\bibitem{lindsay:ieee93}
C.E.~Lindsay and N.R.~Chapman,
``Matched field inversion for geophysical parameters using 
adaptive simulated annealing,''
IEEE J.~Oceanic~Eng. {\bf 18}, 224--231 (1993).

\bibitem{dosso:ieee93}
S.E.~Dosso, M.L.~Yeremy, J.M.~Ozard and N.R.~Chapman,
``Estimation of ocean bottom properties by matched-field 
inversion of acoustic field data,''
IEEE J.~Oceanic~Eng. {\bf 18}, 232--239 (1993).

\bibitem{gerstoft:ecua98} Peter Gerstoft and Zoi-Heleni Michalopoulou
``Global Optimization in Matched-Field Inversion''
{\it Fourth European conference on underwater acoustics}, pp 27--32, Rome 1998.

\bibitem{scales:jcp92}
J.A.\ Scales, M.L.\ Smith and T.L.\ Fisher,
``Global optimization methods for highly nonlinear inverse problems,''
{J. Comp. Phys.} {\bf 103}, 258--268 (1992).

\bibitem{sambrigde:gji92}
M.~Sambrigde and G.~Drijkoningen,
``Genetic algorithms in seismic waveform inversion,''
{ Geophys. J. Int.} {\bf 109}, 323--343 (1992).

\bibitem{stoffa:g91}
P.L.\ Stoffa and M.K.\ Sen,
``Multiparameter optimization using genetic algorithms:
  Inversion of plane wave seismograms,''
{ Geophysics} {\bf 56}, 1794--1810 (1991).

\bibitem{sen:gji92}
M.K. Sen and P.L. Stoffa,
``Rapid sampling of model space using genetic algorithms: examples from
  seismic waveform inversion,''
{ Geophys. J. Int.} {\bf 108}, 281--292 (1992).

\bibitem{jesus:jca96}
S.M.\ Jesus and A.~Caiti,  ``Estimating geoacoustic bottom properties
from towed array data,'' {J.\ Comp.\ Acoust.} 
  {\bf 4}, 273--290 (1996).

\bibitem{eliza:ecua3}
Z.-H.\ Michalopoulou, H.\ Martynov and M.B.\ Porter,
``Simulated annealing and genetic algorithms for broadband source
localization,'' in 
{\it Third European Conference
on Underwater Acoustics}, 
edited by J.S.\ Papadakis (Crete University Press, Crete,
1996), pp. 409--414.

\bibitem{lotsberg:ecua3}
O.\ Lotsberg and S.M.\ Jesus,
``Matched field inversion of geoacoustic properties from towed array
data in shallow water,'' in {\it Third European Conference
on Underwater Acoustics}, 
edited by J.S.\ Papadakis (Crete University Press, Crete,
1996), pp. 601--606.

\bibitem{rendas:icassp97}
M.J.\ Rendas and G.\ Bienvenu,
``Tuning genetic algorithms for underwater acoustics using {\it a  priori}
statistical information,'' Proc.~IEEE ICASSP-97, Munich (1997).

\bibitem{heitkoetter}
J. Heitk\"otter, D.\ Beasley, ``The hitch hikers guide to evolutionary computing'' (FAQ for comp.ai.genetic) (2000)

\bibitem{gerstoft:asa98}
 P.~Gerstoft and  C.F.\ Mecklenbr\"auker, ``Ocean acoustic
inversion with estimation of {\it a posteriori} probability distributions,''
{J.~Acoust.~Soc.~Am.}  {\bf 104 } 808--819 (1998).

\bibitem{porter:jca94}
M.B.~Porter and A.\ Tolstoy,  ``The matched field processing benchmark problems,'' {J.\ Comp.\ Acoust.} {\bf 2}, 161--185 (1994).

\bibitem{gingras:asa95}
 D.F.\ Gingras and P.~Gerstoft, ``Inversion for geometric and geoacoustic 
parameters in shallow water: Experimental results,'' 
{J.\ Acoust.\ Soc.\ Am.} {\bf 97}, 3589--3598 (1995).

\bibitem{gingras:ieee97}
 D.F.~Gingras, P.~Gerstoft and N.L.~Gerr, ``Electromagnetic
matched field processing: Basic concepts and tropospheric
simulations,''   to appear {IEEE Trans.\ on
Ant.\ and Prop.\ }  (1997).

\bibitem{schneider}
H.G.\ Schneider, ``Acoustic models at SACLANTCEN,'' 
SM-285, SACLANT Undersea Research Centre, La Spezia, Italy (1995).

\bibitem{baggeroer:asa89}  A.B. Baggeroer, W.A. Kuperman, and H.
Schmidt, ``Matched field processing: Source localization in
correlated noise as an optimum parameter estimation problem,''
J.\ Acoust.\ Soc.\ Am.\ {\bf 83}, 571-587 (1988).

\bibitem{ottersten}
B.\ Ottersten, M.\ Viberg, P.\ Stoica and A.\ Nehorai, ``Exact and
Large sample maximum likelihood estimation and detection in Array
processing,'' in {\it Radar array processing} 
edited by Haykin, Litva and Shepherd  (Springer Verlag, Berlin, 1993).


\bibitem{gerstoft:jca94}
P.~Gerstoft,  ``Global inversion by genetic algorithms for both source
position and environmental parameters,'' {J.\ Comp.\ Acoust.} 
  {\bf 2}, 251--266 (1994).

\bibitem{harrison:asa95}
C.H.\ Harrison and J.A.\ Harrison, ``A simple relationship between
frequency and range averages for broadband sonar,'' 
{J. Acoust. Soc. Am.} {\bf 97}, 1314--1317 (1995).

\bibitem{lambert} M.\ Lambert, 
``Inversion of seismo-acoustic real data using genetic algorithms,'' 
SM-276, SACLANT Undersea Research Centre, La Spezia, Italy (1994).

\bibitem{gerstoft:ica98}
 P.\ Gerstoft and J.T.\ Goh, ``Performance evaluation of horizontal and vertical
vector sensor arrays in shallow water environments,'' Proceedings 16th International Conference on Acoustics,  p 1643--1644 (1998).

\bibitem{hermand:ieee96}
 J.-P.~Hermand and P.~Gerstoft, ``Inversion of broadband multitone
acoustic data from the Yellow Shark summer experiments,''
{IEEE J.\ Oceanic Eng.\ } {\bf 21}, 324--346 (1996).

\bibitem{thompson:icassp94} 
D.J.\ Thompson, ``Jacknifing using multiple-window spectra,''
Proc. IEEE ICASSP-94, Adelaide (1994).

\bibitem{meckl:icassp95} 
C.F.\ Mecklenbr\"auker, D.\ Maiwald and  J.F.\ B\"ohme,
    ``F-test in matched field processing: 
       identifying multimode propagation'', Proc. IEEE ICASSP-95,
       Detroit (1995).

\bibitem{gerstoft:asa96} 
P.~Gerstoft and D.F.~Gingras, ``Parameter estimation using
 multi-frequency range-dependent acoustic data in shallow water,'' {
 J.~Acoust.~Soc.~Am.\ } {\bf 99}, 2839--2850 (1996).

\bibitem{haralabus:96} G.~Haralabus and P.~Gerstoft, ``Stability of
parameter estimates using multi-frequency inversion techniques,'' 
{SR--253, SACLANT Undersea Research Centre, La Spezia, Italy} (1996).

\bibitem{haralabus:ecua3} G.~Haralabus and P.~Gerstoft, ``Variability
of multi-frequency parameter estimates in shallow water,'' in 
{\it Third European Conference on Underwater Acoustics}, 
edited by J.S. Papadakis (Crete University Press, Crete,
1996), pp. 355--360.

\bibitem{chapman}
N.R.\ Chapman and A.\ Tolstoy, {\it Geoacoustic Benchmark Inversion Workshop},
 {J.\ of Computational
Acoustics} (Oct 1998)


\bibitem{siderius:97}
M.\ Siderius, P.\ Gerstoft and P.L.~Nielsen, ``Broadband acoustic
inversion using a sparse array,'' {J.\ of Computational
Acoustics} (Oct 1998)

\bibitem{ellis:ecua3}
D.D.~Ellis and P.~Gerstoft, ``Using inversion techniques to
extract bottom scattering strengths and sound speed from shallow water
reverberation data,'' in
{\it Third European Conference on Underwater Acoustics}, 
edited by J.S. Papadakis (Crete University Press, Crete,
1996), pp. 887--892.

\bibitem{agard94}
H.V. Hitney, ``Refractive effects from VHF to EHF: Part A, Propagation
mechanisms,''   AGARD Lecture Series, LS--196 (1994).

\bibitem{marrion}
J.B.~Marion and S.T. Thornton, ``Classical dynamics of particles and systems,''
(Harcourt Brace Jovanovich, San Diego, 1988)


\bibitem{duijndam:gp88}
A.~J.~W. Duijndam,
\newblock ``Bayesian estimation in seismic inversion. Part I: Principles,''
\newblock { Geophysical Prospecting} {\bf 36}, 878--898 (1988).


\bibitem{Lefebvre96}
 J.\ Lefebvre,  H.~Roussel,  E.\ Walter, 
 D.\ Lecointe and  W.\ Tabbara,  ``Prediction from wrong models: 
The Kriging approach,''  {IEEE Ant.\ Prop.\ Magazine}, {\bf 38}(4), 
35--45 (1996).

\bibitem{maiwald:icassp94}
D.~Maiwald and J.F.~B\"ohme,
``Multiple testing for seismic data using bootstrap,''
      Proc.~IEEE ICASSP-94, {\bf 6}, Adelaide (1994), pp. 89--92.

\bibitem{hinich:asa79} 
M.L.\ Hinich, ``Maximum likelihood estimation of a radiating source in
a waveguide'', 
{J.~Acoust.~Soc.~Am.\ } {\bf 66}, 480--483 (1977).

\bibitem{shang:asa85} 
E.C.\ Shang, ``Source depth estimation in wave guides,'' 
{J.~Acoust.~Soc.~Am.\ } {\bf 86}, 1960--1964 (1985).


\bibitem{rajan:asa92}
S.~Rajan, ``Waveform inversion of geoacoustic parameters 
in the ocean bottom,'' { J.~Acoust.~Soc.~Am.} {\bf 91}, 3228--3241 (1992).
\bibitem{gerstoft:ieee00}
 P.~Gerstoft, D.F.\ Gingras, L.T.\ Rogers and W.S.\ Hodgkiss, ``Estimation or radio
refractivity structure using matched field array processing,''  
{\ IEEE antenna and
Propagation},   {\bf 48} 345--356 (2000).

\bibitem{gerstoft03ph}
Peter Gerstoft, William S. Hodgkiss,  W.A.~Kuperman and  Heechun Song
``Phenomenological and global optimization inversion,'' IEEE oceanic
Eng. Special issue geoacoustic inversion,{\bf 28}(3),342-354, July 2003. 
\bibitem{park03}
C. Park, W. Seong, P.Gerstoft, M.Siderius ``Timedomain geoacoustic
inversion of high frequency chirps using a towed system''
IEEE oceanic Eng.  Special issue geoacoustic inversion. 
{\bf 28}(3),468-478, July 2003. 
\bibitem{hamilton80}
Edwin L. Hamilton, ``Geoacoustic modeling of the sea floor,''
{J.~Acoust.~Soc.~Am.\ } {\bf 68},
Issue 5, pp. 1313-1340 (1980)
\bibitem{bachman89}
Richard T. Bachman,
``Estimating velocity ratio in marine sediment,''
{J.~Acoust.~Soc.~Am.\ } {\bf 86}, Issue 5, 2029--2032 (1989)
\bibitem{thode05} Aaron M. Thode, Peter Gerstoft, William C. Burgess,
 Karim Sabra, Melania Guerra, M. Dale Stokes, Michael Noad, and
 Douglas C. Cato ``A potable matched-field processing system using Passive Acoustic Time Synchronization,''
submitted IEEE oceanic Eng. 2004.
\bibitem{mecklennbrauker2000}  C.F.\ Mecklenbr{\"a}uker and P.~Gerstoft , ``Objective functions for ocean
acoustic inversions derived by likelihood methods,''
Journal of Computational Acoustics, {\bf 8} 259--270 (2000).
%***********************************************************

\end{thebibliography}

%\input{appendix.tex}
%\setcounter{subsection}{0}
\annex{Likelihood functions for a vertical array}
\label{se:like}

Depending on the model  used for the error or
noise distribution of the data, a specific likelihood function must 
be used. Thus prior knowledge about the error function is
required.
Usually this is not directly available and some simple and reasonable
models must be used. Two special cases are considered for
multi-frequency  vertical array data. The noise distribution on each
phone is assumed complex Gaussian.
First, in Sect.\ \ref{se:mfp} it is assumed that the
noise is independent on each phone and, second, in 
Sect.\ \ref{se:mmp} it is assumed independent 
for each {\it significant} mode. 

Often, a distinction is made between errors due to noise in the data
and errors due to an incomplete forward model,  because neither the
theory  nor the environmental model is  adequate.
If both error types belong to the same distribution, there is
no reason to consider them separately \cite{duijndam:gp88}. 
Here only one error term is considered.

Recently, there has been  progress in describing both errors using 
Kriging  \cite{Lefebvre96}, in which 
 errors due to noise and incomplete forward
modeling are considered separately. 
Both noise and modeling errors are assumed
zero-mean Gaussian and independent.
The modeling errors are assumed to possess a given correlation structure
depending on the ``distance'' between two  environmental models. 
This correlation structure is chosen empirically.
Clearly,  the same value of the model parameters should
correspond to the same value of the modeling error.

%********************************
\subsection{Multi-frequency matched field processing}
\label{se:mfp}

The relation between the observed complex-valued data vector ${\bf q}(\omega)$ 
on an $N$-element hydrophone antenna and the predicted data
${\bf p}({\bf m}, \omega)$ at an angular frequency $\omega $ 
is described by the model
\begin{equation}
 {\bf q}(\omega) = {\bf p}( {\bf m}, \omega )+ {\bf e}(\omega)\;,
\end{equation}
where $ {\bf e}(\omega)$ is  the error term. The predicted data is
given by ${\bf p}(\omega )= {\bf w}( {\bf m}, \omega)S(\omega) $, where the
complex deterministic source term $S(\omega)$ is unknown.  The
transfer function $ {\bf w}( {\bf m}, \omega)$ 
is obtained using an acoustic propagation model and
an environmental model $\bf m $.

The errors are  assumed to be additive;  they
 stem from many sources: errors in describing the
environment, errors in the forward model, instrument and
measurements errors, and noise in the data.  For the predicted
acoustic field
``reasonably close'' to the true field, this error term is
assumed complex Gaussian distributed, stationary
 with zero mean and diagonal covariance matrix
$\nu (\omega ){\bf I}$, where the error  power spectrum $\nu $ is unknown.
Or written compactly ${\bf e}(\omega) \sim {\rm CN}(0,{\nu (\omega
){\bf I}})$, where $ {\rm CN}$ symbolizes the Complex Gaussian distribution.
 Thus, the data ${\bf q}(\omega)$ on the receiving array are also 
complex Gaussian distributed,
${\bf q}(\omega) \sim {\rm CN}\left({\bf p}(\omega,{\bf m}),
                   \nu (\omega){\bf I}\right)$. 
For the derivation of a maximum likelihood estimate, it is further
assumed that the data for each frequency bin are uncorrelated across
frequency and time snapshot and that for each time snapshot the source term
$S( \omega)$ can vary whereas the error power $\nu (\omega )$ is constant.


In the following, we will often abbreviate
${\bf q}_l={\bf q}(\omega_l)$, where 
$\{ \omega_l| l=1,\ldots,L\} $ is a suitable set of frequency bins.
We have $\E {\bf q}_l{\bf q}_l^\dagger = 
  {\bf R}_l = {\bf p}_l{\bf p}_l^{\dagger} + \nu_l{\bf I}$.
Under these assumptions the  likelihood  function 
evaluates to
\begin{equation}
 {\cal L} \propto \prod_{l=1}^{L} \frac{1}{\nu_l^N}
      \exp \left(-\frac{\phi_l}{\nu_l} \right)~,
\end{equation}
where\footnote{$\dagger$ refers to the Hermitian transpose}
\begin{equation}
\phi_l= \mbox{tr} \hat{\bf R}_l- 
\frac{{\bf w}_l^\dagger \hat{\bf R}_l{\bf w}_l}
      {{\bf w}_l^\dagger {\bf w}_l}~.
\label{eq:ml}
\end{equation}
Optimization for $\nu_l$ yields the closed form ML solution
\begin{equation}
\hat{\nu_l}= \frac{1}{N} \phi_l^{}~.
 \label{eq:mlnoise}
\end{equation}
The $N\times N$ Hermitian matrix $\hat{\bf R}_l$ denotes the estimated
cross-spectral density matrix of the observed data ``in phone-space'', 
see Sect.~\ref{se:cov}. With these definitions,
the ML objective function can be written as
\begin{equation} 
 \phi=\prod^L_{l=1} \phi_l= 
 \prod^L_{l=1}\left( \mbox{tr} \hat{\bf R}_l- 
\frac{{\bf w}_l^\dagger \hat{\bf R}_l{\bf w}_l}
      {{\bf w}_l^\dagger {\bf w}_l} \right) ~.
\label{eq:mfp}
\end{equation}

Using a global optimization procedure, the minimum $\ML{\phi}$ for the ML
solution $\ML{\bf m}$ is estimated. 
The estimate, Eq.~(\ref{eq:mlnoise}), is biased. The bias stems from the degrees
    of freedom in the estimated parameters: source signal $S$ and
    nonlinear parameters ${\bf m}$, see \cite{maiwald:icassp94}.
For simplicity this bias is neglected here.
As the noise power spectral density  now is estimated,
Eq.~(\ref{eq:mlnoise}), 
the likelihood function is given by
\begin{eqnarray}
 {\cal L}({\bf m}) &=& p({\bf m} |{\bf q})  \nonumber \\
 &\propto &
  \prod_{l=1}^{L} (\ML{\nu_l})^{-N} \exp 
       \left( -\frac{\phi_l({\bf m})}{\ML{\nu}_l}\right) \nonumber \\
&\propto& 
  \prod_{l=1}^{L}
       \exp \left( -N\frac{\phi_l({\bf m})-\ML{\phi}_l}
        {\ML{\phi}_l}\right)~.
\label{eq:mlmfp}
\end{eqnarray}

The problem, as addressed above, is then to integrate this 
multi-dimensional probability distribution.  Often this integral can be
evaluated with sufficient accuracy using the information from the
global search. In some cases it might be necessary to increase the
sampling of the model space in order to obtain convergence.

According to Eq.~(\ref{eq:mlmfp}), the likelihood function has a
stronger maximum when more hydrophones are used.  When inverting observed data,
there is a limit to how much useful information can be obtained by
adding additional hydrophones, 
as they  then become strongly correlated.  At high SNR 
it is expected that
the main error contribution is due to inadequate forward modeling. 
Further, the number of uncorrelated hydrophones is approximately the same
as the number of propagating modes, because this limits the degrees of
freedom in the random part of the acoustic wave field.
The number of  uncorrelated hydrophones is estimated as the rank of the
covariance matrix.

\subsection{Multi-frequency matched mode processing}
\label{se:mmp}

Normal modes provide a complete description of the field at long
ranges, and thus one can equivalently process the data in 
phone-space or in mode-space.
The matched mode approach is described by  Tolstoy
\cite{tolstoy}, Hinich \cite{hinich:asa79}, and
Shang \cite{shang:asa85}.
Modal processing is discussed here as an alternative noise 
estimate when there are more hydrophones than propagating modes.

We assume that the observed field of $N$ sensors can be approximately expressed via 
a set of $J$ {\it significant\/} modes, expressed in a 
$N\times J$ matrix ${\bf V}(\omega)=({\bf v}_1,\ldots,{\bf v}_J)$, 
and the corresponding complex valued modal 
amplitudes\footnote{ The symbol $\modespace{~}$ refers to the mode-space.} 
$\modespace{\bf q}(\omega)=(\modespace{q}_1,\ldots,\modespace{q}_J)'$ are:
\begin{equation}
  {\bf q}(\omega) \approx 
  \sum\limits^J_{j=1}{\bf v}_j \modespace{q}_j =
  {\bf V}(\omega) \modespace{\bf q}(\omega)~.
  \label{eq:modes}
\end{equation}
It is assumed that we have more hydrophones than modes.
We can invert this relationship in a least-squares sense and estimate
the vector of modal amplitudes 
$\modespace{\bf q}_l=\modespace{\bf q}(\omega_l)$ in mode-space from the 
observation ${\bf q}_l={\bf q}(\omega_l)$ in phone-space,
\begin{equation}
   \modespace{{\bf q}}_l = 
   ({\bf V}^{\dagger}_l{\bf V}_l)^{-1}{\bf V}^{\dagger}_l
        {\bf q}_l~.
\end{equation}
Note that the modes and modal amplitudes depend on the
environment. When optimizing the environment ${\bf m} $, the modal
amplitudes will change with the environment.


We assume a simple  relationship between the observed modal amplitudes
$ \modespace{\bf q}_l$  and synthetic generated modal amplitudes, 
\begin{equation}
 \modespace{\bf q}_l = \modespace{\bf p}_l({\bf m}) + 
 \modespace{\bf e}_l({\bf m})~,
\end{equation}
where $\modespace{\bf p}_l({\bf m})=S_l \modespace{\bf w}_l({\bf m})$ is the
complex-valued modal amplitudes of
the synthetic data  and $ \modespace{\bf e}_l$ represents the error term for
each mode.
%
It is assumed that the noise covariance matrix is diagonal for the $J$ 
significant modes and the  noise power $\modespace{\nu}$ is identical 
for all $J$ modes.

Using a similar approach to that in Sect.~\ref{se:mfp}, the objective function is
\begin{equation}
  \modespace{\phi}_l = \mbox{tr} \hat{\modespace{\bf R}}_l - 
  \frac{{\modespace{\bf w}_l}^\dagger \hat{\modespace{\bf R}}_l
        \modespace{\bf w}_l}
       {{\modespace{\bf w}_l}^\dagger \modespace{\bf w}_l}~, 
  \label{eq:ml_mode}
\end{equation}
where $\hat{\modespace{\bf R}}_l$ is the estimated covariance matrix between
the modes. But  using the expression for the modes,
Eq.~(\ref{eq:modes}), the objective function in mode-space, 
Eq.~(\ref{eq:ml_mode}), is  seen to be equivalent to the objective
function in  phone-space, i.e.\,  Eq.(\ref{eq:ml})
expressed in phone-space, 
\begin{equation}
 \modespace{\phi}_l \approx \phi_l~. 
\end{equation}

The noise estimate is obtained using the approximation in Eq.~(\ref{eq:modes}),

\begin{equation}
   \hat{\modespace{\nu}}_l = 
       \frac{1}{J}{\ML{\modespace{\phi}}_l} \approx \frac{1}{J}\ML{\phi_l}~.
\end{equation}
The likelihood function becomes
\begin{eqnarray}
 {\cal L}({\bf m}) = p({\bf m} |{\bf q}) 
 &\propto &
  \prod_{l=1}^{L} (\ML{\modespace{\nu}}_l)^{-J} \exp 
       \left( -\frac{\modespace{\phi}_l({\bf m})}
                    {\ML{\modespace{\nu}_l}}\right) \nonumber \\
&\propto & 
  \prod_{l=1}^{L}
       \exp \left( -J\frac{\phi_l({\bf m})-\ML{\phi}_l}
        {\ML{\phi}_l}\right)~.
\label{eq:mlmfp_mode}
\end{eqnarray}

The advantage of this formulation is that it does not depend directly
on the number of hydrophones, but only on the number of propagating modes. 
For many hydrophones ($N\gg J$) this likelihood function seems more realistic. 
The precise value of $J$ is not yet clear. For simplicity,
$J$ is assumed to be independent of frequency.
% 
Only the objective function is affected by the choice of $J$. All the
propagating modes are incorporated in the forward model.


\subsection{Estimation of the covariance matrix}
\label{se:cov}
In order to estimate the covariance matrix ${\bf R}_l$, the received
time signal is divided into $K$ time frames. 
Each frame was short-time Fourier transformed using the multiple-windows
technique described in Refs.~\cite{thompson:icassp94,meckl:icassp95},
\begin{equation}
 \label{eq:multiple-win-ft}
 {\mathbf{q}}_{k,p}(\omega) = \sum\limits_{t=0}^{T-1}
      \nu^{p}_t {\mathbf{q}}(t+kT) {\rm e}^{-j\omega t}, \;
 \quad\quad\mbox{for}\quad \!\left\{\begin{array}{l}
       \! \!   k=0,\ldots,K\! - \! 1 \\
       \! \!   p=0, \! \ldots,P\! - \! 1 \\ \end{array} \right. 
\end{equation}
where $\nu^{p}$ is a special set of $P$ orthonormal 
data tapers \cite{thompson:icassp94,meckl:icassp95}.
% the resulting bandwidth was $W=2.25/T=3.3$~Hz.
The correlation matrix $\mathbf{R}$ was estimated at each selected frequency
$\omega_l$ as the ensemble average, i.e.
\begin{equation}
\hat{\mathbf{R}} (\omega_l)=
\frac{1}{KP} \sum_{k=0}^{K-1} \sum_{p=0}^{P-1}
     {\mathbf{q}}_{k,p}(\omega_l) {\mathbf{q}}^\dagger_{k,p}(\omega_l).
\label{eq:R-ensemble-avg}
\end{equation}
In order to obtain a good estimation of the noise, it is required that 
$KP\gg N$, where $N$ is the number of hydrophones. In order to
``just'' estimate the signal and the unknown parameters $\bf m$, the
number of averages, $KP$, can be much smaller for a received signal with
sufficient SNR. 



\annex{Regularization}

 \label{se:reg}

Regularization was originally associated with the
Thikhonov technique
for filtering out the high frequencies of a solution. Today it is used in a
wider sense; here we will understand it as an approach that restricts
parts of the inverse solution.

It is well-known that the numerical solutions to inverse problems are
often ill-conditioned. 
One remedy to  ill-conditioning is 
regularization. The idea of regularization is to introduce {\it a priori}
knowledge on the physical solution. This can be done in several ways:

1) Reparameterization -- shape functions, see Sect. \ref{se:eof}.\\
2) Thikhonov regularization. See Sect.\ \ref{se:tik} below.\\
3) Weighting the likelihood function with the {\it a priori} distribution.
 See Sect.\ \ref{se:prior}.

\subsection{Thikhonov regularization}
\label{se:tik}

Given the {\it a priori} estimate ${\bf m}_0$ of the solution it seems
natural to minimize the difference between the solution ${\bf m}$
 and the estimate  ${\bf m}_0$
\begin{equation}
\phi_{\rm reg} = \| L({\bf m}_0 -{\bf m}) \| \; .
\end{equation}
Normally, $ L $ would be the identity matrix or a discrete approximation to
a derivative operator. Due to different physical dimensions of the parameters,
an {\it ad hoc} regularization could be
\begin{equation}
\phi_{\rm reg} = 1 / N_{\rm parm}
         \sum \frac{|m_i - m_i^{apri}|^\gamma}
                 {|m_i^{\rm max} - m_i^{\rm min}|^{\gamma}}\; ,
\label{eq:reg}
\end{equation}
where $m_i^{apri}$  is the {\it a priori} expected value,
$m_i^{\rm max} - m_i^{\rm min}$ is the search interval, and the exponent
$\gamma$ controls the shape of the penalization. %, see fig. XXXX.
 We use $ \gamma =1$.

The objective function combining the {\it a priori} knowledge and the data is then
\begin{equation}
\phi = \phi_B + \lambda \phi_{\rm reg},
\label{eq:reg1}
\end{equation}
where 
$ \lambda$ is a Lagrange multiplier.  We use $ \lambda=1$ and thus place 
equal emphasis on the data and the {\it a priori} information.

For \underline{option {\bf L}} we have implemented Eq.\ (\ref{eq:reg1}) with  $ \lambda=1$
  and $ \gamma=1$.

\subsection{Including the  {\it a priori} probability distribution}
\label{se:prior}


Usually, when solving inverse problems, the question is ``What is the
environmental model  for this given data set?'' This is normally an ill-posed
question. 
%due to the large number of unknowns. 
A better question is ``What can be inferred from the
data about the environmental model given some environmental
information?'' Thus 
 some {\it a priori} information should be included in the inverse problem. 
{\it A priori} information is always used in global inversion
schemes. The
model structure is selected based on {\it a
priori} knowledge and uniform {\it a priori}
distributions are used between the minimum and maximum bounds for the
parameters.

One possibility is to include the {\it a priori}  model in the objective
function, see e.g. \cite{tarantola,rajan:asa92}. This has the
disadvantage that the distribution must be known explicitly. 
For Gaussian {\it a priori} distribution  the objective function
consists of two terms, one measuring the match between observed and
 synthetic data and the second 
penalizing  the deviation from the {\it a priori} model. This approach
is  used in linearized inversions in order to regularize the solution.

%For global inversion approached it is not common to introduce 
%detailed {\it a priori} information into the inversion.   
%Recently, it has been described how to sample the {\it  a posteriori}
%distribution using a random walker in an approach similar to
%simulated annealing, see Ref.~\cite{mosegaard:jgr95}. 
%The new moves are determined in accordance with
%the {\it a priori} distribution. As normal in simulated
%annealing,  the moves are rejected or accepted
%based on the match between  data and replica. 

Here  a  simple approach is used: the obtained likelihood function
is multiplied with the {\it a priori} distribution, according to
Eq.~(\ref{eq:bayes}). This
distribution can be arbitrary, for example a smoothed distribution obtained
from inversion of other data. 
A simple triangular distribution is often used:
\begin{equation}
\rho( m^i) \propto
\left\{ 
 \begin{array}{ll}
 ({m^i - m^i_u})/({m^i_m - m^i_u})  & \mbox{for $m^i_m < m^i < m^i_u$}\\ 
 ({m^i - m^i_l})/({m^i_m - m^i_l})  & \mbox{for $m^i_l < m^i < m^i_m$}\\ 
 0 & \mbox{otherwise} 
 \end{array}
\right. 
\label{eq:apri}
\end{equation}
where $m^i_l < m^i_u < m^i_m$ are the abscissa of 
lower bound, maximum, and upper bound of the {\it a
     priori\/} distribution, respectively.

{\it A priori} information is also used in the parameterization of the
forward model. The choices made when doing this have a significant influence on
the inverse solution, probably more than including {\it a priori}
information for each parameter. In discretizing the environment, the
physics should be carefully considered and described efficiently.
Shape functions \cite{gerstoft:asa95}
is a useful method to obtain an efficient
description which provide a mapping between the environmental model
and the numerical forward model. This could, for example, be used to limit the
search to only positive gradients in the sediment, or to obtain a
more efficient description of the environment. 

It is assumed that there is
    vanishing correlation between the {\it a priori} distributions
  of the individual parameters.
     Thus, $\rho({\bf m}) = \rho_1(m^1)\rho_2(m^2)\cdots $.
Otherwise the distributions become too
complicated.
If  parameters are correlated, the search can be limited by using 
a correlated  {\it a priori} distribution. 
%
However, this seems too complicated and shape functions
are used instead to map a correlated  model vector to another representation with a
lower degree of correlation.
  
%It is quite complicated to have a correlated {\it a priori}
%distribution, therefore shape functions are used to map the
%model vector from one representation to another where they are less correlated.


%*********************************************************

\annex{Updating SAGA}
It is expected that the user may  wish to update the {\sf SAGA} program
to invert other types of data. This may require  inclusion of
other forward modeling codes into the {\sf SAGA} package, or a change in
the objective function. 
This appendix provides guidance on the implementation of some of these changes.
The author is also willing to help in this process.
 
\subsection{Porting a forward model into SAGA}
The following steps are necessary for porting a 
forward code (here called {\tt fm}) to {\sf SAGA}:
\begin{enumerate}
\item In order to do inversion with a new program it should be reliable. The
dimensions of the matrices should be automatically checked. It should not
crash.
It should have an execution time of around one second.

\item Change the forward code to a subroutine.
 It should have the following structure, using the same subroutine
names:

\small
\begin{verbatim}
    program sagaporting
    call input
    call forwardinit
    do i=1,10
         call forw2
    enddo
    end
\end{verbatim}
\normalsize

\item All the input should be read in one subroutine. 
    The variables should be transferred to a computational 
    subroutine via common blocks that are located in one include
    file.
    (For {\sf SAGA}, it is useful that this routine only contains a few
    variables, so that the declared variables in {\tt fm} do not 
    interfere with {\sf SAGA} variables).

\item The computational subroutine should not have any internal
    read/write statements.  
    Informational write statements are useful, but these should be
    lumped together and surrounded by an   {\tt if (flagpu .gt.\ number)
then }
    statement [{\tt flagpu} is an integer variable in a common block 
that is updated at each call].  

\item  It should be possible to call the computational subroutine several
    times.
    Some initialization of the forward program might only be 
    necessary once, provided the variables are stored in common
    blocks. These initializations should be moved to the start of the
    subroutine {\tt forwardinit}.  An entry call {\tt forw2} 
    can then be inserted below these lines
    for subsequent calls.
\item The output of the program should be stored to a variable
    {\tt resp}. It has the following structure:
\small
\begin{verbatim}
do i_freq=1,M_freq
    do i_depth=1,M_depth
        i_pointer=(i_depth-1+ (i_freq-1)*M_depth)*M_range
        do i_range=1,M_range
            resp(i_range+i_pointer)=press(i_range,i_depth,i_freq)
        enddo
    enddo
enddo
\end{verbatim}
\normalsize

\item  Check that {\tt resp} contains precisely the same results when the forward model
    is called twice. 

\end{enumerate}

Only when the stand-alone version is working well is it time to 
interface it with the {\sf SAGA} modules. 
It is much easier to work with the forward model alone, so
it is important that all of the above works well before
interfacing with {\sf SAGA}.

The interface between {\sf SAGA} and the forward model is done through two
subroutines, {\tt fm\_init} that contains the {\tt input} subroutine and the
{\tt forwardinit} subroutine, and {\tt fm\_inter} that transfer the
{\sf SAGA}-pointers to physical variables in the forward model.


\begin{enumerate}
\item
 Make a list of the variables that could be optimized and assign
     a number to each variable.
     During the optimization the variables are addressed through a
     pointer called {\tt par2phy}.
     If the variable is a vector then the {\tt index} is addressed by the
one pointer {\tt par2lay}.
     If the variable is a matrix it is indexed by two 
     pointers, {\tt par2lay} and {\tt par3}, for the first and second
     index, respectively.     
\item
 Copy one of the *inter.f files from  one of the other forward
models  in /src to /src/fm\_inter.f and modify this 
     file according to the list of variables.

\item Now the forward model is ready to be ported into {\sf SAGA}:
 copy the program in a directory below the saga/src directory, i.e.\ /fm.
\item
   Copy one of the *init.f files from  one of the other forward
models  in /src to /src/fm\_init.f and modify this 
     file.   The input subroutine should be called {\tt input}.
     The main forward subroutine is called {\tt forwardinit}.
     The entry statement is called {\tt forw2}.
     Carefully change the copied file into the one used for the present
forward model.

\item Update the {\tt makefile} and compile.
\end{enumerate}

\subsection{Introducing a new option}
It is quite easy to introduce a new option into {\sf SAGA}. First find the 
subroutine  {\tt gaoptions} in file {\tt gasub.f}. Find an unused letter
and a corresponding value of the pointer {\tt iopt}. Most new options
will probably only require modification in a particular subroutine. 
All computations related to the objective function are done in
subroutine {\tt cost.f}.
\end{document}
